# Spark, overview

sbin/spark-master.sh  # Starts the master on the machine this script is executed on.
	. "${SPARK_HOME}/sbin/spark-config.sh"
	. "${SPARK_HOME}/bin/load-spark-env.sh"
	"${SPARK_HOME}/sbin"/spark-daemon.sh start org.apache.spark.deploy.master.Master 1 \
	  --host $SPARK_MASTER_HOST \
	  --port $SPARK_MASTER_PORT \
	  --webui-port $SPARK_MASTER_WEBUI_PORT \
	  $ORIGINAL_ARGS

sbin/start-workers.sh  # Starts a worker instance on each machine specified in the conf/workers file.
	. "${SPARK_HOME}/sbin/spark-config.sh"
	. "${SPARK_HOME}/bin/load-spark-env.sh"
	"${SPARK_HOME}/sbin/workers.sh" cd "${SPARK_HOME}" \; "${SPARK_HOME}/sbin/start-worker.sh" "spark://$SPARK_MASTER_HOST:$SPARK_MASTER_PORT"

sbin/workers.sh  # run a shell command on all worker hosts
	. "${SPARK_HOME}/sbin/spark-config.sh"
	HOSTLIST=...
	for host in hosts; do
		ssh "$host" "$@"
	done

sbin/start-worker.sh  # Starts a worker on the machine this script is executed on.
	. "${SPARK_HOME}/sbin/spark-config.sh"
	. "${SPARK_HOME}/bin/load-spark-env.sh"
	"${SPARK_HOME}/sbin"/spark-daemon.sh start org.apache.spark.deploy.worker.Worker $WORKER_NUM \
	     --webui-port "$WEBUI_PORT" \
	     $PORT_FLAG $PORT_NUM \
	     $MASTER \
	     "$@"

sbin/spark-daemon.sh  # Runs a Spark command as a daemon.
	. "${SPARK_HOME}/sbin/spark-config.sh"
	. "${SPARK_HOME}/bin/load-spark-env.sh"
      execute_command nice -n "$SPARK_NICENESS" "${SPARK_HOME}"/bin/spark-class "$command" "$@"

bin/spark-class.sh  #
	. "${SPARK_HOME}"/bin/load-spark-env.sh
	RUNNER=...  # JAVA_HOME/bin/java etc
	SPARK_JARS_DIR=...  # SPARK_HOME/jars etc
	LAUNCH_CLASSPATH="$SPARK_JARS_DIR/*"
	"$RUNNER" -Xmx128m $SPARK_LAUNCHER_OPTS -cp "$LAUNCH_CLASSPATH" org.apache.spark.launcher.Main "$@"
	exec "${CMD[@]}"


## Entry-point for both master and worker seem to be org.apache.spark.launcher.Main

Produces a 'command list' that the shell is then exec'ing.
> Master: About to exec /root/.asdf/installs/java/corretto-22.0.2.9.1//bin/java -cp /mnt/mac/conf/:/mnt/mac/assembly/target/scala-2.13/jars/slf4j-api-2.0.13.jar:/mnt/mac/assembly/target/scala-2.13/jars/* -Xmx1g org.apache.spark.deploy.master.Master --host 10a1dd18eca0 --port 7077 --webui-port 8080
> Worker: About to exec /root/.asdf/installs/java/corretto-22.0.2.9.1//bin/java -cp /mnt/mac/conf/:/mnt/mac/assembly/target/scala-2.13/jars/slf4j-api-2.0.13.jar:/mnt/mac/assembly/target/scala-2.13/jars/* -Xmx1g org.apache.spark.deploy.worker.Worker --webui-port 8081 spark://localhost:7077
> Spark-shell: About to exec /root/.asdf/installs/java/corretto-22.0.2.9.1//bin/java -cp hive-jackson/*:/mnt/mac/conf/:/mnt/mac/assembly/target/scala-2.13/jars/slf4j-api-2.0.13.jar:/mnt/mac/assembly/target/scala-2.13/jars/* -Dscala.usejavacp=true -Xmx1g -XX:+IgnoreUnrecognizedVMOptions --add-modules=jdk.incubator.vector --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false -Dio.netty.tryReflectionSetAccessible=true -Dderby.connection.requireAuthentication=false org.apache.spark.deploy.SparkSubmit --class org.apache.spark.repl.Main --name Spark shell spark-shell

scala> spark.read.text("file:///tmp/data.csv").collect()
val res3: Array[org.apache.spark.sql.Row] = Array([foo,bar], [10,"Apple"])b

bin/spark-shell --master spark://spark01:7077
"connection refused"
sbin/start-master.sh (but no workers)
connection refused
root@10a1dd18eca0:/mnt/mac# bin/spark-shell --master spark://10a1dd18eca0:7077
scala> spark.read.text("file:///tmp/data.csv").collect()
24/08/02 12:44:58 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
root@10a1dd18eca0:/mnt/mac# sbin/start-worker.sh spark://10a1dd18eca0:7077
shell again:
scala> spark.read.text("file:///tmp/data.csv").collect()
val res0: Array[org.apache.spark.sql.Row] = Array([foo,bar], [10,"Apple"])

Success!

What is listening on 7077?


### org.apache.spark.deploy.master.Master

core/src/main/scala/org.apache.spark.deploy.master.Master
	parse args and do conf
	startRpcEnvAndEndpoint(args.host, args.port, args.webUiPort, conf)
	val rpcEnv = RpcEnv.create(SYSTEM_NAME, host, port, conf, securityMgr)
		val config = RpcEnvConfig(conf, name, bindAddress, advertiseAddress, port, securityManager, numUsableCores, clientMode)
		new NettyRpcEnvFactory().create(config)
	    	NettySerializer (currently java serializable)
	    		 * Provides a utility for transforming from a SparkConf inside a Spark JVM (e.g., Executor,
				 * Driver, or a standalone shuffle service) into a TransportConf with details on our environment
				 * like the number of cores that are allocated to this JVM.
				 private[netty] val transportConf = SparkTransportConf.fromSparkConf(
				 private val dispatcher: Dispatcher = new Dispatcher(this, numUsableCores)  // rpc msg dispatch
				 private val streamManager = new NettyStreamManager(this)
				 * StreamManager implementation for serving files (jars etc) from a NettyRpcEnv.
				 private val streamManager = new NettyStreamManager(this)
				 RpcHandler // Handler for sendRPC() messages sent by {@link org.apache.spark.network.client.TransportClient}s.
				 private val outboxes = new ConcurrentHashMap[RpcAddress, Outbox]()
				 nettyEnv.startServer // 
				 	   server = transportContext.createServer(bindAddress, port, bootstraps)
				 	   dispatcher.registerRpcEndpoint(
							RpcEndpointVerifier.NAME, new RpcEndpointVerifier(this, dispatcher))
				val endpointRef = new NettyRpcEndpointRef(nettyEnv.conf, addr, nettyEnv)
				endpointRefs.put(endpoint, endpointRef)
		val masterEndpoint = rpcEnv.setupEndpoint(ENDPOINT_NAME,
	      new Master(rpcEnv, rpcEnv.address, webUiPort, securityMgr, conf))
	      	// lots of maps, idToApp, idToWorker, completedApps, etc
	      	// also: drivers, completedDrivers, etc...
	      	masterMetricSystem
	      	applicationMetricSystem
	   masterEndpoint.askSync[BoundPortsResponse](BoundPortsRequest)

	   MessageLoop.scala
			receiveLoop: while true, new LinkedBlockingQueue[Inbox]().take() | dispatch
		NettyUtils.frameDecoder
			TransportContext.initializePipeline
				'ChannelInboundHandlerAdapter'...
					void channelRegistered(ChannelHandlerContext var1) throws Exception;
					void channelUnregistered(ChannelHandlerContext var1) throws Exception;
					void channelActive(ChannelHandlerContext var1) throws Exception;
					void channelInactive(ChannelHandlerContext var1) throws Exception;
					void channelRead(ChannelHandlerContext var1, Object var2) throws Exception;
					void channelReadComplete(ChannelHandlerContext var1) throws Exception;
					void userEventTriggered(ChannelHandlerContext var1, Object var2) throws Exception;
					void channelWritabilityChanged(ChannelHandlerContext var1) throws Exception;
					void exceptionCaught(ChannelHandlerContext var1, Throwable var2) throws Exception;



	Master.receive
		case RegisterApplication
			persistenceEngine.addApplication(app)
			Master.schedule // Schedule the currently available resources among waiting apps. This method will be called every time a new app joins or resource availability changes.			
			startExecutorsOnWorkers()

	SparkSubmit.runMain
		// Note that this main class will not be the one provided by the user if we're running cluster deploy mode or python applications.
		inside driver.main, SparkSessionBuilder.getOrCreate
			loadExtensions(extensions)
			applyExtensions(sparkContext, extensions)
			new SQLContext
			setDefaultSession(session)
			setActiveSession(session)
			registerContextListener(sparkContext)
			org.apache.spark.sql.execution.datasources.v2.parquet.ParquetDataSourceV2
				failed, going V1
			DataSource.resolveRelation // Create a resolved [[BaseRelation]] that can be used to read data from or write data into this [[DataSource]]
				val globbedPaths = checkAndGlobPathIfNecessary()
				val index = createInMemoryFileIndex(globbedPaths)
				getOrInferFileFormatSchema(format, () => index)
					CSVDataSource.infer

	sqlDF.show -> getRows
		DataSet.getRows



	deploy-mode client -> debug breakpoints in the Submit VM
	deploy-mode cluster -> debug breakpoints in the Worker VM
		but this fails...
		./work/driver-20240806215335-0002/stderr
			Caused by: java.lang.IllegalAccessError: class org.apache.spark.storage.StorageUtils$ (in unnamed module @0x55e80483) cannot access class sun.nio.ch.DirectBuffer (in module java.base) because modu
			--add-opens=java.base/sun.nio.ch=ALL-UNNAMED to worker vm
			not enough, is launching other VM...
			Going back to client mode

	Sort [priciest#60 DESC NULLS LAST], true
+- Aggregate [VendorName#56], [VendorName#56 AS vendor#59, max(fare_amount#10) AS priciest#60]
   +- Join LeftOuter, (VendorID#0 = cast(VendorID#55 as int))
      :- SubqueryAlias yellow
      :  +- View (`yellow`, [VendorID#0,tpep_pickup_datetime#1,tpep_dropoff_datetime#2,passenger_count#3L,trip_distance#4,RatecodeID#5L,store_and_fwd_flag#6,PULocationID#7,DOLocationID#8,payment_type#9L,fare_amount#10,extra#11,mta_tax#12,tip_amount#13,tolls_amount#14,improvement_surcharge#15,total_amount#16,congestion_surcharge#17,Airport_fee#18])
      :     +- Relation [VendorID#0,tpep_pickup_datetime#1,tpep_dropoff_datetime#2,passenger_count#3L,trip_distance#4,RatecodeID#5L,store_and_fwd_flag#6,PULocationID#7,DOLocationID#8,payment_type#9L,fare_amount#10,extra#11,mta_tax#12,tip_amount#13,tolls_amount#14,improvement_surcharge#15,total_amount#16,congestion_surcharge#17,Airport_fee#18] parquet
      +- SubqueryAlias names
         +- View (`names`, [VendorID#55,VendorName#56])
            +- Relation [VendorID#55,VendorName#56] csv

   Optimized:
   Sort [priciest#60 DESC NULLS LAST], true
	+- Aggregate [VendorName#56], [VendorName#56 AS vendor#59, max(fare_amount#10) AS priciest#60]
	   +- Project [fare_amount#10, VendorName#56]
	      +- Join LeftOuter, (VendorID#0 = cast(VendorID#55 as int))
	         :- Project [VendorID#0, fare_amount#10]
	         :  +- Relation [VendorID#0,tpep_pickup_datetime#1,tpep_dropoff_datetime#2,passenger_count#3L,trip_distance#4,RatecodeID#5L,store_and_fwd_flag#6,PULocationID#7,DOLocationID#8,payment_type#9L,fare_amount#10,extra#11,mta_tax#12,tip_amount#13,tolls_amount#14,improvement_surcharge#15,total_amount#16,congestion_surcharge#17,Airport_fee#18] parquet
	         +- Filter isnotnull(VendorID#55)
	            +- Relation [VendorID#55,VendorName#56] csv

AdaptiveSparkPlanExec.withFinalPlanUpdate
	getFinalPhysicalPlan()



#### Step through driver code

SparkSession.getOrCreate()
	new SparkConf
	SparkContext.getOrCreate(sparkConf)
	loadExtensions
	applyExtensions
	new SparkSession(sparkContext, None, None, extensions, options.toMap)
	registerContextListener(sparkContext)

spark.read() // new DataFrameReader(self)
	.parquet() // format = "parquet"
	.load()
		// find in DataSourceRegister, service loader
		// org.apache.spark.sql.execution.datasources.v2.parquet.ParquetDataSourceV2
		// configured to use V1 sources, so do not use V2
		// "avro,csv,json,kafka,orc,parquet,text"
		.loadV1Source()
			DataSource.apply(...)
				// The main class responsible for representing a pluggable Data Source in Spark SQL.
				// In addition to acting as the canonical set of parameters that can describe a Data Source, this class is used to resolve a description to a concrete implementation that can be used in a query plan.
				// 
	.createOrReplaceTempView()
		// CreateViewCommand
		// Create or replace a view with given query plan. This command will generate some view-specific properties(e.g. view default database, view query output column names) and store them as properties in metastore, if we need to create a permanent view.
		// abstract class QueryPlan[PlanType <: QueryPlan[PlanType]]
		// CreateViewCommand
		// 	RunnableCommand
		//			Command
		//				LogicalPlan
		//					QueryPlan
		//						TreeNode
		//							Product (scala) = record
		.withPlan = Dataset.ofRows(spark, logicalPlan)
			.executePlan(logicalPlan)
				new QueryExecution()
					// The primary workflow for executing relational queries using Spark.  Designed to allow easy access to the intermediate phases of query execution for developers.
					QueryPlanningTracker
					// queryExecution.commandExecuted
					// HadoopFSRelation
					// 

					.parsePlan() // AbstractSqlParser, SQL -> plan


			.assertAnalyzed
			new Dataset[Row](qe, ExpressionEncoder(eq.analyzed.schema))


// fetchAndRunExecutor
// [/Users/folkol/.asdf/installs/java/corretto-17.0.12.7.1/bin/java, -cp, /Users/folkol/code/spark/./conf/:/Users/folkol/code/spark/./assembly/target/scala-2.12/jars/*, -Xmx1024M, -Dspark.driver.port=53834, -Djava.net.preferIPv6Addresses=false, -XX:+IgnoreUnrecognizedVMOptions, --add-opens=java.base/java.lang=ALL-UNNAMED, --add-opens=java.base/java.lang.invoke=ALL-UNNAMED, --add-opens=java.base/java.lang.reflect=ALL-UNNAMED, --add-opens=java.base/java.io=ALL-UNNAMED, --add-opens=java.base/java.net=ALL-UNNAMED, --add-opens=java.base/java.nio=ALL-UNNAMED, --add-opens=java.base/java.util=ALL-UNNAMED, --add-opens=java.base/java.util.concurrent=ALL-UNNAMED, --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED, --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED, --add-opens=java.base/sun.nio.ch=ALL-UNNAMED, --add-opens=java.base/sun.nio.cs=ALL-UNNAMED, --add-opens=java.base/sun.security.action=ALL-UNNAMED, --add-opens=java.base/sun.util.calendar=ALL-UNNAMED, --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED, -Djdk.reflect.useDirectMethodHandle=false, org.apache.spark.executor.CoarseGrainedExecutorBackend, --driver-url, spark://CoarseGrainedScheduler@192.168.8.166:53834, --executor-id, 0, --hostname, 192.168.8.166, --cores, 8, --app-id, app-20240807142219-0013, --worker-url, spark://Worker@192.168.8.166:53729, --resourceProfileId, 0]



### Spark Series

#### Hadoop + YARN concepts

https://luminousmen.com/post/hadoop-yarn-spark

"Apache Spark is an open-source cloud computing framework for batch and stream processing which was designed for fast in-memory data processing."

"Spark is framework and is mainly used on top of other systems. You can run Spark using its standalone cluster mode on EC2, on Hadoop YARN, on Mesos, or on Kubernetes. I will tell you about the most popular build — Spark with Hadoop Yarn."

"So, before we go deeper into Apache Spark, let's take a quick look at the Hadoop platform and what YARN does there."

Hadoop: storage (HDFS) + Execute/schedule (YARN)

Hadoop components:
- ResourceManager: ultimate authority for allocating resources between applications on the cluster
- runs NodeManagers on all nodes in the cluster
- allocation made by the plugin 'scheduler'
- containers on each node is controlled by their 'NodeManager'

- ApplicationMaster for each application is a framework-specific entity that is tasked with negotiating resources with ResourceManager and working with NodeManager(s) to perform and monitor component tasks.
- ResourceManager, NodeManager and the container do not care about the type of application or task. All application framework code is simply transferred to the ApplicationMaster so that any distributed framework can be supported by YARN — as long as someone implements a suitable ApplicationMaster for it. With this common approach, the dream of a Hadoop YARN cluster with many various workloads comes true.

- Example application submission in YANR
1. A client program submits the application, including necessary specification, to run the applicatin-specific ApplicationMaster
2. ResourceManager allocates the necessary container and starts the ApplicationMaster in it
3. ApplicationMaster registers itself in the ResourceManager. Registration allows the Customer program to request specific information from ResourceManager that allows it to directly intract with its ApplicationMaster
4. ApplicationMaster asks ResourceManager for suitable containers to run tasks
5. ApplicationMaster launches the Containers and registers them with the NodeManager
6. Inside the containers, the user application code is executed. The NodeManagers then provides the information for the ApplicationMaster
7. During execution, the client interacts with the ApplicationMaster to obtain application status
8. The application complets and all necessary work is completed. ApplicationMaster registers from the ResourceManager and terminates, releasing the container for other purposes.

- small tasks can be run directly inside the ApplicationMaster ('Uberization')
- application-generated log files no longer remain on the individual nodes, but are transferred to HDFS

#### Spark Core Concepts explained

https://luminousmen.com/post/spark-core-concepts-explained

Two main abstractions: RDDs and DAGs

RDD: Resilient Distributed Dataset
- arbitrary collection of objects
- distributed among the cluster nodes so that they can be processed in parallel
- Physically, RDD is stored as an object in the JVM driver and refers to data stored either in permanent storage (HDFS, Cassandra, HBase, etc.) or in a cache (memory, memory+disks, disk only, etc.), or on another RDD.

RDD Metadata:
- partitions: data splits associated with this RDD, they are located on cluster nodes. One partition is the minimum data batch that can be processed by each node of the cluster
- dependencies: a list of parent RDDs involved in the calculation, the so-called lineage graph
- computation: a function to calculate child RDDs from parent RDDs
- preferred locations: where it is best to place computation by partitions (data locality)
partitioner: how data is divided into partitions (default=HashPartitioner)

- RDDs can be cached
- transformation: create new RDD from old RDD
- Transformations by their nature are lazy, i.e. when we call some operation on RDD, it is not executed immediately. Spark keeps a record of which operation is called (via DAG, we will talk about it later).
- transformations are lazy
- narrow transformations (=within node)
- wide transformations (=needs reshuffle)

- actions (eager/materializing): actions consume RDD and produce non-RDD values, such as .collect or save data to storage or reduce data

- DAG: Directed Acyclic Graph
- Unlike Hadoop, where the user has to break down all the operations into smaller tasks and chain them together in order to use MapReduce, Spark defines tasks that can be computed in parallel with the partitioned data on the cluster. With these defined tasks, Spark builds a logical flow of operations that can be represented as a directional and acyclic graph, also known as DAG (Directed Acyclic Graph), where the node represents an RDD partition and the edge represents a data transformation. Spark builds the execution plan implicitly from the application provided by Spark.
- General execution:
	- RDD objects (rdd1.join(rdd2).groupBy)...
	- DAGScheduler: split graph into stages of tasks
	- TaskScheduler: launch individual tasks via cluster manager
	- Worker: threads+blockmanager, executes indivudal tasks

- The end result of DAGScheduler is a 'TaskSet', then the stages are passed on to the TaskSCheduler


#### Anatomy of a Spark application

https://luminousmen.com/post/spark-anatomy-of-spark-application


1. Spark Submit (Master node+YARN ResourceManager)
2. N x WorkerNodes (YARN NodeManager / Container / SparkExecutor)
3. 1 x WorkerNode (YARN NodeManager Container / AppMaster / Driver / SparkContext

The components of a spark application are:
- Driver
- ApplicationMaster (YARN)
- Spark Context
- Cluster Resource Manager (=Cluster Manager)
- Executors

Spark uses master/slave architecture with a central coordinator called Driver and a ser of executable workflows called Executors that are located at various nodes in the cluster.

Driver: "driver program" is responsible for converting user program into 'tasks', and then schedule them to run with a cluster manager on executors.
Driver: DAGScheduler, TaskScheduler, BackendScheduler, BlockManager
Driver: can run in an independent process or on one of the worker nodes
- stores RDD metadata
- is created after the user sends the Spark Application to the cluster manager (YARN, in our case)
- runs on its own JVM
- optimizes logical DAG transformations and, if possible, combines them into stages and determines the best location for execution of this DAG
- creates Spark WebUI with detailed information about the application

ApplicationMaster (YARN concept): framework-specific entity charged with negotiating resources with the ResourceManager and working with the NodeManagers to perform and monitor application tasks.
- each application has its own ApplicationMaster
- ApplicationMaster is created simiultaneously with the Driver when user 'submits' application

SparkContext: main entrypoint into Spark Functionality
- allows the driver to access the cluster manager, and create RDDs, accumulators and broadcast variables on the cluster
- also tracks executors through heartbeats
- the spark context is created by ther driver for each Spark application, and it lives for the whole job
- spark context stops working after the application is finished. Can be one per JVM, you must call .stop before creating a new one

ClusterResourceManager: a process that controls, governs and reserves computing resources in the form of containers on the clusters
- notes: what Borg calls 'slots'
- containers are reserved by request of ApplicationMasteres and are allocated to ApplicationMaster when they are released or available
- SparkContext can connect to different types of Cluster Managers, for example YARN, Mesos, Kubernetes or Nomad. There is also Spark's own Standalone cluster manager.

- Mesos was also developed by the creator of Spark

Executors: Executors are the processes at the worker's nodes, their job is to complete the assigned tasks. These tasks are executed on ther worker nodes and then return the result to the Spark Driver.
- Executors are started at the beginning of Spark Application and then work during all lfe of the application ("Static Allocation of Executors").
- Performers provide storage either in-memory for RDD partitions that are cached (locally) in Spark applications (via BlockManager) or on disk while using localCheckpoint.
- performs:
	- stores data in cache (heap or disk)
	- reads data from external sources
	- writes data to external sources
	- performs data processing


Spark application running steps:
- When we send the Spark application in cluster mode, the spark-submit utility communicates with the Cluster Resource Manager to start the Application Master.
- The Resource Manager is then held responsible for selecting the necessary container in which to run the Application Master. The Resource Manager then tells a specific Node Manager to launch the Application Master.
- The Application Master registers with the Resource Manager. Registration allows the client program to request information from the Resource Manager, that information allows the client program to communicate directly with its own Application Master.
- The Spark Driver then runs on the Application Master container (in case of cluster mode).
- The driver implicitly converts user code containing transformations and actions into a logical plan called a DAG. All RDDs are created in the driver and do nothing until the action is called. At this stage, the driver also performs optimizations such as pipelining narrow transformations.
- It then converts the DAG into a physical execution plan. After conversion to a physical execution plan, the driver creates physical execution units called tasks at each stage.
- The Application Master now communicates with the Cluster Manager and negotiates resources. Cluster Manager allocates containers and asks the appropriate NodeManagers to run the executors on all selected containers. When executors run, they register with the Driver. This way, the Driver has a complete view of the artists.
- At this point, the Driver will send tasks to executors via Cluster Manager based on the data placement.
- The code of the user application is launched inside the container. It provides information (stage of execution, status) to the Application Master.
- At this stage, we will start to execute our code. Our first RDD will be created by reading data in parallel from HDFS to different partitions on different nodes based on HDFS InputFormat. Thus, each node will have a subset of data.
- After reading the data we have two map transformations which will be executed in parallel on each partition.
- Next, we have a reduceByKey transformation, it is not a narrow transformation like map, so it will create an additional stage. It combines records with the same keys, then moves data between nodes (shuffle) and partitions to combine the keys of the same record.
- We then perform an action — write back to HDFS which will trigger the entire DAG execution.
- During the execution of the user application, the client communicates with the Application Master to obtain the application status.
- When the application finishes executing and all of the necessary work is done, the Application Master disconnects itself from the Resource Manager and stops, freeing up its container for other purposes.


-Xrunjdwp:transport=dt_socket,address=8000,server=y,suspend=y








Things that can't be streamed:
- count distinct?
- top N? (there can always be a new top 1 scattered, so need to keep history?)
- others?
- 


https://luminousmen.com/post/spark-anatomy-of-spark-application






### Netty hello world (chat program)

- netty-all
- javassist

Client.main = new ChatClient(localhost, 8080).run();
Client.run
	EventLoopGroup group = new NioEventLoopGroup();
	try {
		Bootstrap bootstrap = new Bootstrap()
			.group(group)
			.channel(NiosocketChannel.class)
			.handler(new ChatClientInitializer())
		Channel channel = bootstrap.connect(host, port).sync().channel()
		BufferedReader in = new BufferedReader(new InputStremaRaeder(System.in));
		while (true) {
			channel.write(in.readLine() + "\r\n")
		}
	} finally {
		group.shutdownGracefully()
	}
ChannelClientInitializer (either impl interface or extend ChannelInitializer<SocketChannel>)
	initChannel()
		ChannelPipeline pipeline = ss.pipelie();
		pipeline.addLast("framer", new DelimisterBasedDecoder(8192, Delimited.lineDelimiter()));
		pipeline.addLast("decoder", new StringDecoder());
		pipeline.addLast("encoder", new StringEncoder());
		pipeline.addLast("handler", new ChatClientHandler())
ChatClientHandler()
	messageReceived(channelHandlerContext, String)
		System.out.println(...)


Server.main
	new ChatServer(...).run()
Server.run
	bossGroup = new NioEventLoopGroup();
	workerGroup = new NioEventLoopGroup();
	try {
		ServerBootstrap bootstrap = new ServerBootstrap()
			.group(bossGroup, workerGroup)
			.channel(NioServerSocketChannel.class)
			.childHandler(new ChatServerInitializer())

		bootstrap.bind(port).sync().channel().closeFuture().sync();
	} finally {
		...
	}



Added logging and:
scala> spark.read.text("file:///tmp/data.csv").collect()

> rebuilding seems to require core and assembly
> takes 1h for whole stuff, without running tests
> maybe go to the PC?
> 


### Other software

CycloneDX: OWASP CycloneDX is a full-stack Bill of Materials (BOM) standard that provides advanced supply chain capabilities for cyber risk reduction.



### Develop Spark using an IDE

https://spark.apache.org/developer-tools.html



### New attempt, latest released version

v3.5.1

iterative
build once
then:
build/sbt clean package
SPARK_PREPEND_CLASSES=true


Using own protoc:
export SPARK_PROTOC_EXEC_PATH=/path-to-protoc-exe
./build/mvn -Puser-defined-protoc -DskipDefaultProtoc clean package

set local java 8
$ time build/mvn clean package

test failure
$ ./build/mvn -DskipTests -Dmaven.test.skip=true package

build with java 8

$ time ./build/mvn -T 8 -DskipTests package

#### External Shuffle

https://books.japila.pl/apache-spark-internals/external-shuffle-service/
External Shuffle Service is a Spark service to serve RDD and shuffle blocks outside and for Executors.
- seems to be 'one per host'?

- running from Intellij fails with ClassDefNotFound. The run configuration chose 'core' as classpath, but the start-master uses jars from 'assembly'.


[INFO] Reactor Summary for Spark Project Parent POM 3.5.1:
[INFO]
[INFO] Spark Project Parent POM ........................... SUCCESS [  3.400 s]
[INFO] Spark Project Tags ................................. SUCCESS [  4.140 s]
[INFO] Spark Project Sketch ............................... SUCCESS [ 17.298 s]
[INFO] Spark Project Local DB ............................. SUCCESS [ 20.025 s]
[INFO] Spark Project Common Utils ......................... SUCCESS [ 21.137 s]
[INFO] Spark Project Networking ........................... SUCCESS [ 19.319 s]
[INFO] Spark Project Shuffle Streaming Service ............ SUCCESS [ 26.710 s]
[INFO] Spark Project Unsafe ............................... SUCCESS [ 20.722 s]
[INFO] Spark Project Launcher ............................. SUCCESS [ 17.323 s]
[INFO] Spark Project Core ................................. SUCCESS [04:23 min]
[INFO] Spark Project ML Local Library ..................... SUCCESS [02:45 min]
[INFO] Spark Project GraphX ............................... SUCCESS [02:31 min]
[INFO] Spark Project Streaming ............................ SUCCESS [04:17 min]
[INFO] Spark Project SQL API .............................. SUCCESS [01:11 min]
[INFO] Spark Project Catalyst ............................. SUCCESS [08:15 min]
[INFO] Spark Project SQL .................................. SUCCESS [07:21 min]
[INFO] Spark Project ML Library ........................... SUCCESS [05:43 min]
[INFO] Spark Project Tools ................................ SUCCESS [ 10.780 s]
[INFO] Spark Project Hive ................................. SUCCESS [03:31 min]
[INFO] Spark Project REPL ................................. SUCCESS [ 26.213 s]
[INFO] Spark Project Assembly ............................. SUCCESS [  7.844 s]
[INFO] Kafka 0.10+ Token Provider for Streaming ........... SUCCESS [01:17 min]
[INFO] Spark Integration for Kafka 0.10 ................... SUCCESS [01:30 min]
[INFO] Kafka 0.10+ Source for Structured Streaming ........ SUCCESS [02:40 min]
[INFO] Spark Project Examples ............................. SUCCESS [01:31 min]
[INFO] Spark Integration for Kafka 0.10 Assembly .......... SUCCESS [ 11.535 s]
[INFO] Spark Avro ......................................... SUCCESS [02:28 min]
[INFO] Spark Project Connect Common ....................... SUCCESS [01:17 min]
[INFO] Spark Protobuf ..................................... SUCCESS [02:33 min]
[INFO] Spark Project Connect Server ....................... SUCCESS [01:17 min]
[INFO] Spark Project Connect Client ....................... SUCCESS [01:32 min]
[INFO] ------------------------------------------------------------------------
[INFO] BUILD SUCCESS
[INFO] ------------------------------------------------------------------------
[INFO] Total time:  28:43 min (Wall Clock)
[INFO] Finished at: 2024-08-02T18:26:51+02:00
[INFO] ------------------------------------------------------------------------



/Users/folkol/.asdf/installs/java/corretto-8.422.05.1/bin/java -cp /Users/folkol/code/spark/conf/:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/* -Xmx1g org.apache.spark.deploy.master.Master --host matte --port 7077 --webui-port 8080


Logical optimization: Spark Catalyst Optimizer applies rule-based and cost-based optimization techniques to enhance logical query plans.


[INFO] Reactor Summary for Spark Project Parent POM 3.5.1:
[INFO]
[INFO] Spark Project Parent POM ........................... SUCCESS [  3.408 s]
[INFO] Spark Project Tags ................................. SUCCESS [  6.402 s]
[INFO] Spark Project Sketch ............................... SUCCESS [ 20.059 s]
[INFO] Spark Project Local DB ............................. SUCCESS [ 19.858 s]
[INFO] Spark Project Common Utils ......................... SUCCESS [ 21.631 s]
[INFO] Spark Project Networking ........................... SUCCESS [ 16.754 s]
[INFO] Spark Project Shuffle Streaming Service ............ SUCCESS [ 15.295 s]
[INFO] Spark Project Unsafe ............................... SUCCESS [ 16.491 s]
[INFO] Spark Project Launcher ............................. SUCCESS [ 16.160 s]
[INFO] Spark Project Core ................................. SUCCESS [04:14 min]
[INFO] Spark Project ML Local Library ..................... SUCCESS [01:19 min]
[INFO] Spark Project GraphX ............................... SUCCESS [01:13 min]
[INFO] Spark Project Streaming ............................ SUCCESS [02:09 min]
[INFO] Spark Project SQL API .............................. SUCCESS [ 39.010 s]
[INFO] Spark Project Catalyst ............................. SUCCESS [05:25 min]
[INFO] Spark Project SQL .................................. SUCCESS [04:25 min]
[INFO] Spark Project ML Library ........................... SUCCESS [04:40 min]
[INFO] Spark Project Tools ................................ SUCCESS [  2.664 s]
[INFO] Spark Project Hive ................................. SUCCESS [02:42 min]
[INFO] Spark Project REPL ................................. SUCCESS [ 22.298 s]
[INFO] Spark Project Assembly ............................. SUCCESS [  8.293 s]
[INFO] Kafka 0.10+ Token Provider for Streaming ........... SUCCESS [ 47.675 s]
[INFO] Spark Integration for Kafka 0.10 ................... SUCCESS [ 44.508 s]
[INFO] Kafka 0.10+ Source for Structured Streaming ........ SUCCESS [01:59 min]
[INFO] Spark Project Examples ............................. SUCCESS [01:38 min]
[INFO] Spark Integration for Kafka 0.10 Assembly .......... SUCCESS [  4.864 s]
[INFO] Spark Avro ......................................... SUCCESS [01:51 min]
[INFO] Spark Project Connect Common ....................... SUCCESS [ 34.756 s]
[INFO] Spark Protobuf ..................................... SUCCESS [01:26 min]
[INFO] Spark Project Connect Server ....................... SUCCESS [01:32 min]
[INFO] Spark Project Connect Client ....................... SUCCESS [01:55 min]
[INFO] ------------------------------------------------------------------------
[INFO] BUILD SUCCESS
[INFO] ------------------------------------------------------------------------
[INFO] Total time:  21:45 min (Wall Clock)
[INFO] Finished at: 2024-08-02T19:12:25+02:00
[INFO] ------------------------------------------------------------------------



disable use --release option to get sun.misc.Unsafe visibl

Changed guava from provided to compiled, and it started!

24/08/02 20:43:34 WARN Master: App app-20240802204334-0001 requires more resource than any of Workers could have.



java.lang.IllegalArgumentException: requirement failed: Starting multiple workers on one host is failed because we may launch no more than one external shuffle service on each host, please set spark.shuffle.service.enabled to false or set SPARK_WORKER_INSTANCES to 1 to resolve the conflict.


scala> spark.read.format("csv").option("header", "true").load("/tmp/yellow_taxi").groupBy("VendorID").count().collect()

scala> spark.read.format("csv").option("header", "true").load("/tmp/yellow_taxi").groupBy("VendorID").count().explain()
== Physical Plan ==
AdaptiveSparkPlan isFinalPlan=false
+- HashAggregate(keys=[VendorID#596], functions=[count(1)])
   +- Exchange hashpartitioning(VendorID#596, 200), ENSURE_REQUIREMENTS, [plan_id=343]
      +- HashAggregate(keys=[VendorID#596], functions=[partial_count(1)])
         +- FileScan csv [VendorID#596] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/tmp/yellow_taxi], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<VendorID:string>

scala> spark.read.format("csv").option("header", "true").load("/tmp/yellow_taxi").groupBy("VendorID").count().explain(true)
== Parsed Logical Plan ==
Aggregate [VendorID#677], [VendorID#677, count(1) AS count#735L]
+- Relation [VendorID#677,tpep_pickup_datetime#678,tpep_dropoff_datetime#679,passenger_count#680,trip_distance#681,RatecodeID#682,store_and_fwd_flag#683,PULocationID#684,DOLocationID#685,payment_type#686,fare_amount#687,extra#688,mta_tax#689,tip_amount#690,tolls_amount#691,improvement_surcharge#692,total_amount#693,congestion_surcharge#694,Airport_fee#695] csv

== Analyzed Logical Plan ==
VendorID: string, count: bigint
Aggregate [VendorID#677], [VendorID#677, count(1) AS count#735L]
+- Relation [VendorID#677,tpep_pickup_datetime#678,tpep_dropoff_datetime#679,passenger_count#680,trip_distance#681,RatecodeID#682,store_and_fwd_flag#683,PULocationID#684,DOLocationID#685,payment_type#686,fare_amount#687,extra#688,mta_tax#689,tip_amount#690,tolls_amount#691,improvement_surcharge#692,total_amount#693,congestion_surcharge#694,Airport_fee#695] csv

== Optimized Logical Plan ==
Aggregate [VendorID#677], [VendorID#677, count(1) AS count#735L]
+- Project [VendorID#677]
   +- Relation [VendorID#677,tpep_pickup_datetime#678,tpep_dropoff_datetime#679,passenger_count#680,trip_distance#681,RatecodeID#682,store_and_fwd_flag#683,PULocationID#684,DOLocationID#685,payment_type#686,fare_amount#687,extra#688,mta_tax#689,tip_amount#690,tolls_amount#691,improvement_surcharge#692,total_amount#693,congestion_surcharge#694,Airport_fee#695] csv

== Physical Plan ==
AdaptiveSparkPlan isFinalPlan=false
+- HashAggregate(keys=[VendorID#677], functions=[count(1)], output=[VendorID#677, count#735L])
   +- Exchange hashpartitioning(VendorID#677, 200), ENSURE_REQUIREMENTS, [plan_id=375]
      +- HashAggregate(keys=[VendorID#677], functions=[partial_count(1)], output=[VendorID#677, count#740L])
         +- FileScan csv [VendorID#677] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/tmp/yellow_taxi], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<VendorID:string>


== Physical Plan ==
AdaptiveSparkPlan isFinalPlan=false
+- HashAggregate(keys=[VendorID#1649], functions=[count(1)], output=[VendorID#1649, count#1708L])
   +- Exchange hashpartitioning(VendorID#1649, 200), ENSURE_REQUIREMENTS, [plan_id=1015]
      +- HashAggregate(keys=[VendorID#1649], functions=[partial_count(1)], output=[VendorID#1649, count#1712L])
         +- Project [VendorID#1649]
            +- Filter (isnotnull(trip_distance#1653) AND (cast(trip_distance#1653 as int) > 2))
               +- FileScan csv [VendorID#1649,trip_distance#1653] Batched: false, DataFilters: [isnotnull(trip_distance#1653), (cast(trip_distance#1653 as int) > 2)], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/tmp/yellow_taxi], PartitionFilters: [], PushedFilters: [IsNotNull(trip_distance)], ReadSchema: struct<VendorID:string,trip_distance:string>


- Moved JavaSparkSQLExample to assemly, since that's where everything is 'compile'



- https://spark.apache.org/spark-connect/
	Here’s how Spark Connect works at a high level:

	A connection is established between the Client and Spark Server
	The Client converts a DataFrame query to an unresolved logical plan that describes the intent of the operation rather than how it should be executed
	The unresolved logical plan is encoded and sent to the Spark Server
	The Spark Server optimizes and runs the query
	The Spark Server sends the results back to the Client


- https://spark.apache.org/docs/latest/cluster-overview.html
	Cluster Mode Overview




### How is Spark usually deployed?

- https://www.reddit.com/r/dataengineering/comments/1ay0572/how_is_spark_really_used_and_deployed_in/

	- We use spark on private (no internet) on prem HDP Hadoop cluster (mostly just HDFS for storage and Yarn for job scheduler). Spark batch job via airflow and spark streaming for consuming data via Kafka.
	- This minus the streaming part is what I built for a biggish company as well. We started with Java Spark but switched over to Scala Spark over time which is much nicer.
	- We used java and scala spark with 1.6 version too. Since 2.4 (3.0.0 then now 3.4.1), we only kept the stream job on scala (now migrated to Java Flink). All batch jobs have been migrated to pyspark, makes it much easier for DS, DA.
	- For system admin, I as DE lead take care of all the work at this point, mostly done via ansible. Sysad/Infra team helped with installation, after that DE took over. Infra now only involved with hardwares like HDD/raid failures, network changed, etc...
	- We used an unholy combination of early airflow and Python scripting to keep things running. 
	- We have a small cluster by standard too with 44 servers including not Hadoop one. For the Hadoop site, ambari agents took care of all the jobs; but there are some tasks that need automation or things will get too boring:
		- Deploy/update binaries (some apps, not from data team), conda envs (we use Python UDF, so need to have synchronized python envs on all node managers).
		- Update iptables: this is specific to our cluster since network firewall are updated once in a while.
		- Provision new user/delete old user for member: creating linux user, manage/distribute ssh keys to server, restart sshd, etc...
		- Provision flink task managers (resides on same datanode/node managers). You can deploy flink on yarn, but we prefer flink run on only some nodes, not all. And YARN node labels are not ideal.
	- Depends. One off jobs can be manual. EMR steps may be enough for basic cases. But complex cases do tend to need an orchestrator like Airflow, Prefect, Dagster, etc.

	- Amazon EMR can run Spark jobs


#### Running spark on YARN (Hadroop resource manager, Yet Another Resource Negotiator))

- https://spark.apache.org/docs/latest/running-on-yarn.html
- resource manager accepts job submissions and schedules + monitors the application master
- there is federation where multiple sub-clusters can appear as one
- There are two deploy modes that can be used to launch Spark applications on YARN. In cluster mode, the Spark driver runs inside an application master process which is managed by YARN on the cluster, and the client can go away after initiating the application. In client mode, the driver runs in the client process, and the application master is only used for requesting resources from YARN.



#### Program entrypoints

- https://www.ksolves.com/blog/big-data/spark/sparksession-vs-sparkcontext-what-are-the-differences

- Spark 1:
	SparkContext: SparkContext is the primary point of entry for Spark capabilities. A SparkContext represents a Spark cluster’s connection that is useful in building RDDs, accumulators, and broadcast variables on the cluster. It enables your Spark Application to connect to the Spark Cluster using Resource Manager. Also, before the creation of SparkContext, SparkConf must be created. 
	SQLContext: ...
	HiveContext: ...

- Spark 2:
	+SparkSession: Frontend to the context APIs, higher level
	SparkSession vs SparkContext, as of Spark 2.0.0, it is better to use SparkSession because it provides access to all of the Spark features that the other three APIs do. Its Spark object comes by default in Spark-shell, and it can be generated programmatically using the SparkSession builder pattern.

Components:
- DRIVER: The driver is the process where the main method runs. First it converts the user program into tasks and after that it schedules the tasks on the executors.
- EXECUTORS: Executors are worker nodes' processes in charge of running individual tasks in a given Spark job. They are launched at the beginning of a Spark application and typically run for the entire lifetime of an application. Once they have run the task they send the results to the driver. They also provide in-memory storage for RDDs that are cached by user programs through Block Manager.
- Application execution flow:
	- an application is submitted to the cluster
	- the driver program is launched, instantiates and starts the SparkContext
	- the driver program asks the 'cluster manager' to launch executors
	- the cluster manager launches executors
	- the driver program runs through the user application, actions and RDD transformations are converted into tasks that gets scheduled on the executors
	- executors run the tasks and save the results
	- if any worker crashes, its tasks will be sent to a different executor to be processed again (or of slow, spark can speculatively launch a copy and .Race the results)
	- on driver crash (or SparkContext.stop), the resources will be released back to the ClusterManager



#### SparkConnect?

Thin client to the driver, basically. Requires a 'spark connect server'.




#### Speed things up

- find a test case that exercises master + worker + some client program (submit)

- If your code depends on other projects, you will need to package them alongside your application in order to distribute the code to a Spark cluster. To do this, create an assembly jar (or “uber” jar) containing your code and its dependencies. Both sbt and Maven have assembly plugins. When creating assembly jars, list Spark and Hadoop as provided dependencies; these need not be bundled since they are provided by the cluster manager at runtime. Once you have an assembled jar you can call the bin/spark-submit script as shown here while passing your jar.


[INFO] Spark Avro ......................................... SUCCESS [ 16.544 s]
[INFO] Spark Project Connect Common ....................... SUCCESS [ 49.059 s]
[INFO] Spark Protobuf ..................................... SUCCESS [ 12.567 s]
[INFO] Spark Project Connect Server ....................... SUCCESS [ 32.762 s]
[INFO] Spark Project Connect Client ....................... SUCCESS [ 28.981 s]


[WARNING] The following plugins are not marked as thread-safe in Spark Project Parent POM:
[WARNING]   org.antipathy:mvn-scalafmt_2.12:1.1.1640084764.9f463a9
[WARNING]   net.alchim31.maven:scala-maven-plugin:4.8.0




In actual Executor:
- sets up RPCendpoint and registers with master (or worker?)
- accepts 'tasks' from RPC and adds to queue
  // Deserialization happens in two parts: first, we deserialize a Task object, which
  // includes the Partition. Second, Task.run() deserializes the RDD and function to be run.
- Executor.scala::run
- 





#### DataFrames vs RDDs?

https://www.databricks.com/blog/2016/07/14/a-tale-of-three-apache-spark-apis-rdds-dataframes-and-datasets.html

> What's more, as you will note below, you can seamlessly move between DataFrame or Dataset and RDDs at will—by simple API method calls—and DataFrames and Datasets are built on top of RDDs.



### Happy-path scenario

Run Master (=ClusterManager)
Run Worker (=NodeManager)
Run SparkSubmit (client mode, points to master)
	... waits for debugger
Debug SparkExecutor



> When working with Hive, one must instantiate SparkSession with Hive support, including connectivity to a persistent Hive metastore, support for Hive serdes, and Hive user-defined functions. 


##### Trying without assembly/.../jars...

> Master: Trying without '-cp assembly/target/scala-2.12/jars/*'
> 'no output blah blah' -> change pom -> jar
> master: classpath from 'assembly'
> removed 'used provided as compile', did not work -- revert
> worker: still --add-opens=java.base/sun.nio.ch=ALL-UNNAMED, but not jars/*. Using 'assembly' as module.
> Added 'use provided'

> Worked! (submit from shell, and submit from IntelliJ, with 'addopens')
> was 'local class incompatible'




Retrying master, without 'assembly' module.
- seems to work? At least start up.
- rerunning SparkSubmit, but with core
	- NoClassDefFound: org.apache.spark.sql.SparkSession
SparkSubmit, this.getClass()...
	this.getClass().getClassLoader().ucp.path
	// loads of .m2 files
> SparkSession is in spark sql, changing module
> giving up for now, re-running with coverage and going to remove code from Master/Worker/Submit/Executor



#### Trim Master

- removed 'persistence engine'
- removed support for standalone cluster mode driver





#### Cluster Mode Overview (2 modes, cluster mode and client mode)

- cluster: driver program runs within the spark cluster
- client: driver program runs elsewhere

- who does what?
								YARNCluster YARNClient Standalone
Driver runs in					AppMaster	Client		Client
Who requests resources?			AppMaster	AppMaster	SparkSlave
Who starts executor processes?	YARNNodeMan	YARNNodeMan	SparkSlave
Persistent services				YARNMgrs	YARNMgrs	Master+Workers
Support spark shell?			No			Yes			Yes

- broadly: YARNCluster for production, Client for interactive or debug
- Understanding the difference requires an understanding of YARN’s Application Master concept. In YARN, each application instance has an Application Master process, which is the first container started for that application.
- The application is responsible for requesting resources from the ResourceManager, and, when allocated them, telling NodeManagers to start containers on its behalf.
- Application Masters obviate the need for an active client — the process starting the application can go away and coordination continues from a process managed by YARN running on the cluster.
- In yarn-cluster mode, the driver runs in the Application Master. This means that the same process is responsible for both driving the application and requesting resources from YARN, and this process runs inside a YARN container. The client that starts the app doesn’t need to stick around for its entire lifetime.

- Spark applications run as independent sets of processes on a cluster, coordinated by the SparkContext object in your main program (called the driver program).
- Specifically, to run on a cluster, the SparkContext can connect to several types of cluster managers (either Spark’s own standalone cluster manager, Mesos, YARN or Kubernetes), which allocate resources across applications. 
- Once connected, Spark acquires executors on nodes in the cluster, which are processes that run computations and store data for your application.
- Next, it sends your application code (defined by JAR or Python files passed to SparkContext) to the executors. Finally, SparkContext sends tasks to the executors to run.

- Spark gives control over resource allocation both across applications (at the level of the cluster manager) and within applications (if multiple computations are happening on the same SparkContext). The job scheduling overview describes this in more detail.

- Glossary
	Application: Driver + executors
	Application.jar: Driver code + dependencies, do not include hadoop or spark classes
	Driver: application main(), creates SparkContext
	ClusterManager: Service for requiring resources on the cluster (e.g. standalone master, Mesos, YARN, Kubernetes)
	Deploy mode: cluster or client, where the driver runs
	Worker node: any node that can run application code in the cluster
	Executor: Process launched for an application on a worker node, runs tasks and keeps data in memory or disk. Per-application.
	Task: unit of work that is scheduled on an executor
	Job: A parallel computation consisting of multiple tasks that gets spawned in response to a "Spark Action" (.save or .collect)
	Stage: Part of Job with independent tasks, stages depend on each other




#### A Deeper Understanding of Spark Internals (10y ago)

- https://www.youtube.com/watch?v=dmL0N3qfSc8
- 'Execution model' / 'Shuffle' / 'Caching'

sc.textFile("hdfs:/names")
	.map(name => (name.charAt(0), name))
	.groupByKey()
	.mapValues(names => names.toSet.size)
	.collect()

"Collect that back to the driver"

1. "Create a DAG of RDDs to represent computation" to represent computation
- RDD: partitioned dataset
- each lines in the spark program creates / describes RDDs
2. Create a logical execution plan for the DAG
3. Schedule and execute individual tasks

- "The key to making this performant is to pipeline the calculation as much as possible, 'fuse operations' so that we don't need to go over the data multiple times."
- "When the result can be computed independent of any other data, that's when we can pipeline it"
- Split into 'stages' based on need to reorganize or 'consume' all data.



## Build statistics

root@10a1dd18eca0:/mnt/mac# du -sh */ | sort -h
8.0K	binder/
40K	conf/
76K	target/
80K	hadoop-cloud/
80K	sbin/
100K	licenses/
100K	project/
120K	bin/
172K	ui-test/
188K	tools/
420K	licenses-binary/
576K	dev/
1.0M	launcher/
1.2M	data/
1.6M	R/
1.7M	repl/
1.8M	mllib-local/
2.0M	resource-managers/
4.5M	graphx/
11M	build/
15M	streaming/
18M	docs/
23M	python/
26M	common/
26M	examples/
61M	mllib/
71M	connector/
94M	connect/
120M	core/
329M	assembly/
538M	sql/

[INFO] Reactor Summary for Spark Project Parent POM 4.0.0-SNAPSHOT:
[INFO]
[INFO] Spark Project Parent POM ........................... SUCCESS [ 10.459 s]
[INFO] Spark Project Tags ................................. SUCCESS [  9.285 s]
[INFO] Spark Project Sketch ............................... SUCCESS [ 13.233 s]
[INFO] Spark Project Common Utils ......................... SUCCESS [ 36.204 s]
[INFO] Spark Project Local DB ............................. SUCCESS [ 20.744 s]
[INFO] Spark Project Networking ........................... SUCCESS [ 36.166 s]
[INFO] Spark Project Shuffle Streaming Service ............ SUCCESS [ 33.007 s]
[INFO] Spark Project Variant .............................. SUCCESS [  9.587 s]
[INFO] Spark Project Unsafe ............................... SUCCESS [ 27.563 s]
[INFO] Spark Project Launcher ............................. SUCCESS [ 14.049 s]
[INFO] Spark Project Core ................................. SUCCESS [06:55 min]
[INFO] Spark Project ML Local Library ..................... SUCCESS [01:13 min]
[INFO] Spark Project GraphX ............................... SUCCESS [ 58.542 s]
[INFO] Spark Project Streaming ............................ SUCCESS [01:56 min]
[INFO] Spark Project SQL API .............................. SUCCESS [ 59.928 s]
[INFO] Spark Project Catalyst ............................. SUCCESS [05:53 min]
[INFO] Spark Project SQL .................................. SUCCESS [10:20 min]
[INFO] Spark Project ML Library ........................... SUCCESS [05:46 min]
[INFO] Spark Project Tools ................................ SUCCESS [  5.265 s]
[INFO] Spark Project Hive ................................. SUCCESS [02:45 min]
[INFO] Spark Project REPL ................................. SUCCESS [ 39.770 s]
[INFO] Spark Project Connect Common ....................... SUCCESS [01:01 min]
[INFO] Spark Avro ......................................... SUCCESS [01:10 min]
[INFO] Spark Protobuf ..................................... SUCCESS [01:00 min]
[INFO] Spark Project Connect Server ....................... SUCCESS [02:26 min]
[INFO] Spark Project Assembly ............................. SUCCESS [ 30.788 s]
[INFO] Kafka 0.10+ Token Provider for Streaming ........... SUCCESS [ 37.010 s]
[INFO] Spark Integration for Kafka 0.10 ................... SUCCESS [ 51.242 s]
[INFO] Kafka 0.10+ Source for Structured Streaming ........ SUCCESS [01:13 min]
[INFO] Spark Project Examples ............................. SUCCESS [01:17 min]
[INFO] Spark Integration for Kafka 0.10 Assembly .......... SUCCESS [ 43.333 s]
[INFO] Spark Project Connect Client ....................... SUCCESS [01:58 min]
[INFO] ------------------------------------------------------------------------
[INFO] BUILD SUCCESS
[INFO] ------------------------------------------------------------------------
[INFO] Total time:  53:58 min
[INFO] Finished at: 2024-08-02T12:24:36Z
[INFO] ------------------------------------------------------------------------




### Basic scenario

- standalone master (From IntelliJ)
- standalone worker
- submit one jar with a basic job
	ClientExample.java
	package examples;

	import org.apache.spark.sql.AnalysisException;
	import org.apache.spark.sql.Dataset;
	import org.apache.spark.sql.Row;
	import org.apache.spark.sql.SparkSession;

	import static org.apache.spark.sql.functions.col;

	public class ClientExample {
	    public static void main(String[] args) throws AnalysisException {
	        System.out.println("wut");

	        SparkSession spark = SparkSession
	                .builder()
	//                .master("spark://192.168.8.164:7077")
	                .appName("Java Spark SQL basic example")
	                .getOrCreate();

	//        SparkContext sc = new SparkContext("spark://192.168.8.164:7077", "ClientExample");
	//        sc.

	//        new SparkContext()
	        Dataset<Row> df = spark.read().json("examples/src/main/resources/people.json");
	        df.show();
	        df.printSchema();
	        df.select("name").show();
	        df.select(col("name"), col("age").plus(1)).show();
	        df.filter(col("age").gt(21)).show();
	        df.groupBy("age").count().show();
	        df.createOrReplaceTempView("people");

	        Dataset<Row> sqlDF = spark.sql("SELECT * FROM people");
	        sqlDF.show();
	        df.createGlobalTempView("people");

	        // Global temporary view is tied to a system preserved database `global_temp`
	        spark.sql("SELECT * FROM global_temp.people").show();
	        spark.newSession().sql("SELECT * FROM global_temp.people").show();

	        spark.stop();
	    }
	}

	Compile
	jar cf ClientExample.jar ...

	Submit:
	$ bin/spark-submit --class examples.ClientExample ClientExample.jar --master spark://192.168.8.166:7077

	/Users/folkol/.asdf/installs/java/corretto-17.0.12.7.1/bin/java \
		-cp \
		/Users/folkol/code/spark/conf/:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/* \
		-Xmx1g \
		-XX:+IgnoreUnrecognizedVMOptions \
		--add-opens=java.base/java.lang=ALL-UNNAMED \
		--add-opens=java.base/java.lang.invoke=ALL-UNNAMED \
		--add-opens=java.base/java.lang.reflect=ALL-UNNAMED \
		--add-opens=java.base/java.io=ALL-UNNAMED \
		--add-opens=java.base/java.net=ALL-UNNAMED \
		--add-opens=java.base/java.nio=ALL-UNNAMED \
		--add-opens=java.base/java.util=ALL-UNNAMED \
		--add-opens=java.base/java.util.concurrent=ALL-UNNAMED \
		--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED \
		--add-opens=java.base/jdk.internal.ref=ALL-UNNAMED \
		--add-opens=java.base/sun.nio.ch=ALL-UNNAMED \
		--add-opens=java.base/sun.nio.cs=ALL-UNNAMED \
		--add-opens=java.base/sun.security.action=ALL-UNNAMED \
		--add-opens=java.base/sun.util.calendar=ALL-UNNAMED \
		--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED \
		-Djdk.reflect.useDirectMethodHandle=false \
		org.apache.spark.deploy.SparkSubmit \
		--class \
		examples.ClientExample \
		ClientExample.jar \
		--master \
		spark://192.168.8.166:7077

		Run from IntelliJ: guava missing, changed to 'compile'


				--class examples.ClientExample ClientExample.jar --master spark://192.168.8.166:7077

		Run configuration: "Add dependency with provided scope to classpath".
		Also: "Modify classpath"
		+ jar: spark sql
		+ jar: spark sql api
		+ jar: spark catalyst
		+ Add VM options: --add-opens=java.base/sun.nio.ch=ALL-UNNAMED
		+ jar: antlr runtime
		+ jar: commons-compiler

		Instead:
		--jars /Users/folkol/code/spark/assembly/target/scala-2.12/jars/* --class examples.ClientExample ClientExample.jar --master spark://192.168.8.166:7077



		Run:
		/Users/folkol/.asdf/installs/java/corretto-17.0.12.7.1/bin/java --add-opens=java.base/sun.nio.ch=ALL-UNNAMED -javaagent:/Users/folkol/Applications/IntelliJ IDEA Ultimate.app/Contents/lib/idea_rt.jar=65487:/Users/folkol/Applications/IntelliJ IDEA Ultimate.app/Contents/bin -Dfile.encoding=UTF-8 -classpath /Users/folkol/code/spark/core/target/scala-2.12/classes:/Users/folkol/.m2/repository/org/apache/avro/avro/1.11.2/avro-1.11.2.jar:/Users/folkol/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.15.2/jackson-core-2.15.2.jar:/Users/folkol/.m2/repository/org/slf4j/slf4j-api/2.0.7/slf4j-api-2.0.7.jar:/Users/folkol/.m2/repository/org/apache/avro/avro-mapred/1.11.2/avro-mapred-1.11.2.jar:/Users/folkol/.m2/repository/org/apache/avro/avro-ipc/1.11.2/avro-ipc-1.11.2.jar:/Users/folkol/.m2/repository/org/tukaani/xz/1.9/xz-1.9.jar:/Users/folkol/.m2/repository/com/google/guava/guava/14.0.1/guava-14.0.1.jar:/Users/folkol/.m2/repository/com/twitter/chill_2.12/0.10.0/chill_2.12-0.10.0.jar:/Users/folkol/.m2/repository/com/esotericsoftware/kryo-shaded/4.0.2/kryo-shaded-4.0.2.jar:/Users/folkol/.m2/repository/com/esotericsoftware/minlog/1.3.0/minlog-1.3.0.jar:/Users/folkol/.m2/repository/com/twitter/chill-java/0.10.0/chill-java-0.10.0.jar:/Users/folkol/.m2/repository/org/apache/xbean/xbean-asm9-shaded/4.23/xbean-asm9-shaded-4.23.jar:/Users/folkol/.m2/repository/org/apache/hadoop/hadoop-client-api/3.3.4/hadoop-client-api-3.3.4.jar:/Users/folkol/.m2/repository/org/apache/hadoop/hadoop-client-runtime/3.3.4/hadoop-client-runtime-3.3.4.jar:/Users/folkol/.m2/repository/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar:/Users/folkol/code/spark/launcher/target/scala-2.12/classes:/Users/folkol/code/spark/common/kvstore/target/scala-2.12/classes:/Users/folkol/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/Users/folkol/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.15.2/jackson-annotations-2.15.2.jar:/Users/folkol/.m2/repository/org/rocksdb/rocksdbjni/8.3.2/rocksdbjni-8.3.2.jar:/Users/folkol/code/spark/common/network-common/target/scala-2.12/classes:/Users/folkol/.m2/repository/com/google/crypto/tink/tink/1.9.0/tink-1.9.0.jar:/Users/folkol/.m2/repository/com/google/code/gson/gson/2.10.1/gson-2.10.1.jar:/Users/folkol/.m2/repository/joda-time/joda-time/2.12.5/joda-time-2.12.5.jar:/Users/folkol/code/spark/common/network-shuffle/target/scala-2.12/classes:/Users/folkol/code/spark/common/unsafe/target/scala-2.12/classes:/Users/folkol/code/spark/common/utils/target/scala-2.12/classes:/Users/folkol/.m2/repository/org/slf4j/jul-to-slf4j/2.0.7/jul-to-slf4j-2.0.7.jar:/Users/folkol/.m2/repository/org/slf4j/jcl-over-slf4j/2.0.7/jcl-over-slf4j-2.0.7.jar:/Users/folkol/.m2/repository/org/apache/logging/log4j/log4j-slf4j2-impl/2.20.0/log4j-slf4j2-impl-2.20.0.jar:/Users/folkol/.m2/repository/org/apache/logging/log4j/log4j-api/2.20.0/log4j-api-2.20.0.jar:/Users/folkol/.m2/repository/org/apache/logging/log4j/log4j-core/2.20.0/log4j-core-2.20.0.jar:/Users/folkol/.m2/repository/org/apache/logging/log4j/log4j-1.2-api/2.20.0/log4j-1.2-api-2.20.0.jar:/Users/folkol/.m2/repository/javax/activation/activation/1.1.1/activation-1.1.1.jar:/Users/folkol/.m2/repository/org/apache/curator/curator-recipes/2.13.0/curator-recipes-2.13.0.jar:/Users/folkol/.m2/repository/org/apache/curator/curator-framework/2.13.0/curator-framework-2.13.0.jar:/Users/folkol/.m2/repository/org/apache/curator/curator-client/2.13.0/curator-client-2.13.0.jar:/Users/folkol/.m2/repository/org/apache/zookeeper/zookeeper/3.6.3/zookeeper-3.6.3.jar:/Users/folkol/.m2/repository/org/apache/zookeeper/zookeeper-jute/3.6.3/zookeeper-jute-3.6.3.jar:/Users/folkol/.m2/repository/org/apache/yetus/audience-annotations/0.5.0/audience-annotations-0.5.0.jar:/Users/folkol/.m2/repository/org/eclipse/jetty/jetty-plus/9.4.52.v20230823/jetty-plus-9.4.52.v20230823.jar:/Users/folkol/.m2/repository/org/eclipse/jetty/jetty-webapp/9.4.52.v20230823/jetty-webapp-9.4.52.v20230823.jar:/Users/folkol/.m2/repository/org/eclipse/jetty/jetty-xml/9.4.52.v20230823/jetty-xml-9.4.52.v20230823.jar:/Users/folkol/.m2/repository/org/eclipse/jetty/jetty-jndi/9.4.52.v20230823/jetty-jndi-9.4.52.v20230823.jar:/Users/folkol/.m2/repository/org/eclipse/jetty/jetty-security/9.4.52.v20230823/jetty-security-9.4.52.v20230823.jar:/Users/folkol/.m2/repository/org/eclipse/jetty/jetty-util/9.4.52.v20230823/jetty-util-9.4.52.v20230823.jar:/Users/folkol/.m2/repository/org/eclipse/jetty/jetty-server/9.4.52.v20230823/jetty-server-9.4.52.v20230823.jar:/Users/folkol/.m2/repository/javax/servlet/javax.servlet-api/3.1.0/javax.servlet-api-3.1.0.jar:/Users/folkol/.m2/repository/org/eclipse/jetty/jetty-io/9.4.52.v20230823/jetty-io-9.4.52.v20230823.jar:/Users/folkol/.m2/repository/org/eclipse/jetty/jetty-http/9.4.52.v20230823/jetty-http-9.4.52.v20230823.jar:/Users/folkol/.m2/repository/org/eclipse/jetty/jetty-continuation/9.4.52.v20230823/jetty-continuation-9.4.52.v20230823.jar:/Users/folkol/.m2/repository/org/eclipse/jetty/jetty-servlet/9.4.52.v20230823/jetty-servlet-9.4.52.v20230823.jar:/Users/folkol/.m2/repository/org/eclipse/jetty/jetty-util-ajax/9.4.52.v20230823/jetty-util-ajax-9.4.52.v20230823.jar:/Users/folkol/.m2/repository/org/eclipse/jetty/jetty-proxy/9.4.52.v20230823/jetty-proxy-9.4.52.v20230823.jar:/Users/folkol/.m2/repository/org/eclipse/jetty/jetty-client/9.4.52.v20230823/jetty-client-9.4.52.v20230823.jar:/Users/folkol/.m2/repository/org/eclipse/jetty/jetty-servlets/9.4.52.v20230823/jetty-servlets-9.4.52.v20230823.jar:/Users/folkol/.m2/repository/jakarta/servlet/jakarta.servlet-api/4.0.3/jakarta.servlet-api-4.0.3.jar:/Users/folkol/.m2/repository/commons-codec/commons-codec/1.16.0/commons-codec-1.16.0.jar:/Users/folkol/.m2/repository/org/apache/commons/commons-compress/1.23.0/commons-compress-1.23.0.jar:/Users/folkol/.m2/repository/org/apache/commons/commons-lang3/3.12.0/commons-lang3-3.12.0.jar:/Users/folkol/.m2/repository/org/apache/commons/commons-math3/3.6.1/commons-math3-3.6.1.jar:/Users/folkol/.m2/repository/org/apache/commons/commons-text/1.10.0/commons-text-1.10.0.jar:/Users/folkol/.m2/repository/commons-io/commons-io/2.13.0/commons-io-2.13.0.jar:/Users/folkol/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/Users/folkol/.m2/repository/org/apache/commons/commons-collections4/4.4/commons-collections4-4.4.jar:/Users/folkol/.m2/repository/com/google/code/findbugs/jsr305/3.0.0/jsr305-3.0.0.jar:/Users/folkol/.m2/repository/com/ning/compress-lzf/1.1.2/compress-lzf-1.1.2.jar:/Users/folkol/.m2/repository/org/xerial/snappy/snappy-java/1.1.10.3/snappy-java-1.1.10.3.jar:/Users/folkol/.m2/repository/org/lz4/lz4-java/1.8.0/lz4-java-1.8.0.jar:/Users/folkol/.m2/repository/com/github/luben/zstd-jni/1.5.5-4/zstd-jni-1.5.5-4.jar:/Users/folkol/.m2/repository/org/roaringbitmap/RoaringBitmap/0.9.45/RoaringBitmap-0.9.45.jar:/Users/folkol/.m2/repository/org/roaringbitmap/shims/0.9.45/shims-0.9.45.jar:/Users/folkol/.m2/repository/org/scala-lang/modules/scala-xml_2.12/2.1.0/scala-xml_2.12-2.1.0.jar:/Users/folkol/.m2/repository/org/scala-lang/scala-library/2.12.18/scala-library-2.12.18.jar:/Users/folkol/.m2/repository/org/scala-lang/scala-reflect/2.12.18/scala-reflect-2.12.18.jar:/Users/folkol/.m2/repository/org/json4s/json4s-jackson_2.12/3.7.0-M11/json4s-jackson_2.12-3.7.0-M11.jar:/Users/folkol/.m2/repository/org/json4s/json4s-core_2.12/3.7.0-M11/json4s-core_2.12-3.7.0-M11.jar:/Users/folkol/.m2/repository/org/json4s/json4s-ast_2.12/3.7.0-M11/json4s-ast_2.12-3.7.0-M11.jar:/Users/folkol/.m2/repository/org/json4s/json4s-scalap_2.12/3.7.0-M11/json4s-scalap_2.12-3.7.0-M11.jar:/Users/folkol/.m2/repository/org/glassfish/jersey/core/jersey-client/2.40/jersey-client-2.40.jar:/Users/folkol/.m2/repository/jakarta/ws/rs/jakarta.ws.rs-api/2.1.6/jakarta.ws.rs-api-2.1.6.jar:/Users/folkol/.m2/repository/org/glassfish/hk2/external/jakarta.inject/2.6.1/jakarta.inject-2.6.1.jar:/Users/folkol/.m2/repository/org/glassfish/jersey/core/jersey-common/2.40/jersey-common-2.40.jar:/Users/folkol/.m2/repository/jakarta/annotation/jakarta.annotation-api/1.3.5/jakarta.annotation-api-1.3.5.jar:/Users/folkol/.m2/repository/org/glassfish/hk2/osgi-resource-locator/1.0.3/osgi-resource-locator-1.0.3.jar:/Users/folkol/.m2/repository/org/glassfish/jersey/core/jersey-server/2.40/jersey-server-2.40.jar:/Users/folkol/.m2/repository/jakarta/validation/jakarta.validation-api/2.0.2/jakarta.validation-api-2.0.2.jar:/Users/folkol/.m2/repository/org/glassfish/jersey/containers/jersey-container-servlet/2.40/jersey-container-servlet-2.40.jar:/Users/folkol/.m2/repository/org/glassfish/jersey/containers/jersey-container-servlet-core/2.40/jersey-container-servlet-core-2.40.jar:/Users/folkol/.m2/repository/org/glassfish/jersey/inject/jersey-hk2/2.40/jersey-hk2-2.40.jar:/Users/folkol/.m2/repository/org/glassfish/hk2/hk2-locator/2.6.1/hk2-locator-2.6.1.jar:/Users/folkol/.m2/repository/org/glassfish/hk2/external/aopalliance-repackaged/2.6.1/aopalliance-repackaged-2.6.1.jar:/Users/folkol/.m2/repository/org/glassfish/hk2/hk2-api/2.6.1/hk2-api-2.6.1.jar:/Users/folkol/.m2/repository/org/glassfish/hk2/hk2-utils/2.6.1/hk2-utils-2.6.1.jar:/Users/folkol/.m2/repository/org/javassist/javassist/3.29.2-GA/javassist-3.29.2-GA.jar:/Users/folkol/.m2/repository/io/netty/netty-all/4.1.96.Final/netty-all-4.1.96.Final.jar:/Users/folkol/.m2/repository/io/netty/netty-buffer/4.1.96.Final/netty-buffer-4.1.96.Final.jar:/Users/folkol/.m2/repository/io/netty/netty-codec/4.1.96.Final/netty-codec-4.1.96.Final.jar:/Users/folkol/.m2/repository/io/netty/netty-codec-http/4.1.96.Final/netty-codec-http-4.1.96.Final.jar:/Users/folkol/.m2/repository/io/netty/netty-codec-http2/4.1.96.Final/netty-codec-http2-4.1.96.Final.jar:/Users/folkol/.m2/repository/io/netty/netty-codec-socks/4.1.96.Final/netty-codec-socks-4.1.96.Final.jar:/Users/folkol/.m2/repository/io/netty/netty-common/4.1.96.Final/netty-common-4.1.96.Final.jar:/Users/folkol/.m2/repository/io/netty/netty-handler/4.1.96.Final/netty-handler-4.1.96.Final.jar:/Users/folkol/.m2/repository/io/netty/netty-transport-native-unix-common/4.1.96.Final/netty-transport-native-unix-common-4.1.96.Final.jar:/Users/folkol/.m2/repository/io/netty/netty-handler-proxy/4.1.96.Final/netty-handler-proxy-4.1.96.Final.jar:/Users/folkol/.m2/repository/io/netty/netty-resolver/4.1.96.Final/netty-resolver-4.1.96.Final.jar:/Users/folkol/.m2/repository/io/netty/netty-transport/4.1.96.Final/netty-transport-4.1.96.Final.jar:/Users/folkol/.m2/repository/io/netty/netty-transport-classes-epoll/4.1.96.Final/netty-transport-classes-epoll-4.1.96.Final.jar:/Users/folkol/.m2/repository/io/netty/netty-transport-classes-kqueue/4.1.96.Final/netty-transport-classes-kqueue-4.1.96.Final.jar:/Users/folkol/.m2/repository/io/netty/netty-transport-native-epoll/4.1.96.Final/netty-transport-native-epoll-4.1.96.Final-linux-x86_64.jar:/Users/folkol/.m2/repository/io/netty/netty-transport-native-epoll/4.1.96.Final/netty-transport-native-epoll-4.1.96.Final-linux-aarch_64.jar:/Users/folkol/.m2/repository/io/netty/netty-transport-native-kqueue/4.1.96.Final/netty-transport-native-kqueue-4.1.96.Final-osx-aarch_64.jar:/Users/folkol/.m2/repository/io/netty/netty-transport-native-kqueue/4.1.96.Final/netty-transport-native-kqueue-4.1.96.Final-osx-x86_64.jar:/Users/folkol/.m2/repository/com/clearspring/analytics/stream/2.9.6/stream-2.9.6.jar:/Users/folkol/.m2/repository/io/dropwizard/metrics/metrics-core/4.2.19/metrics-core-4.2.19.jar:/Users/folkol/.m2/repository/io/dropwizard/metrics/metrics-jvm/4.2.19/metrics-jvm-4.2.19.jar:/Users/folkol/.m2/repository/io/dropwizard/metrics/metrics-json/4.2.19/metrics-json-4.2.19.jar:/Users/folkol/.m2/repository/io/dropwizard/metrics/metrics-graphite/4.2.19/metrics-graphite-4.2.19.jar:/Users/folkol/.m2/repository/io/dropwizard/metrics/metrics-jmx/4.2.19/metrics-jmx-4.2.19.jar:/Users/folkol/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.15.2/jackson-databind-2.15.2.jar:/Users/folkol/.m2/repository/com/fasterxml/jackson/module/jackson-module-scala_2.12/2.15.2/jackson-module-scala_2.12-2.15.2.jar:/Users/folkol/.m2/repository/com/thoughtworks/paranamer/paranamer/2.8/paranamer-2.8.jar:/Users/folkol/.m2/repository/org/apache/ivy/ivy/2.5.1/ivy-2.5.1.jar:/Users/folkol/.m2/repository/oro/oro/2.0.8/oro-2.0.8.jar:/Users/folkol/.m2/repository/org/objenesis/objenesis/3.3/objenesis-3.3.jar:/Users/folkol/.m2/repository/net/razorvine/pickle/1.3/pickle-1.3.jar:/Users/folkol/.m2/repository/net/sf/py4j/py4j/0.10.9.7/py4j-0.10.9.7.jar:/Users/folkol/code/spark/common/tags/target/scala-2.12/classes:/Users/folkol/.m2/repository/org/apache/commons/commons-crypto/1.1.0/commons-crypto-1.1.0.jar:/Users/folkol/.m2/repository/com/google/protobuf/protobuf-java/3.23.4/protobuf-java-3.23.4.jar:/Users/folkol/.m2/repository/org/spark-project/spark/unused/1.0.0/unused-1.0.0.jar:/Users/folkol/code/spark/launcher/target/spark-launcher_2.12-3.5.1.jar:/Users/folkol/code/spark/common/kvstore/target/spark-kvstore_2.12-3.5.1.jar:/Users/folkol/code/spark/common/network-common/target/spark-network-common_2.12-3.5.1.jar:/Users/folkol/code/spark/common/network-shuffle/target/spark-network-shuffle_2.12-3.5.1.jar:/Users/folkol/code/spark/common/unsafe/target/spark-unsafe_2.12-3.5.1.jar:/Users/folkol/code/spark/common/utils/target/spark-common-utils_2.12-3.5.1.jar:/Users/folkol/code/spark/common/tags/target/spark-tags_2.12-3.5.1.jar org.apache.spark.deploy.SparkSubmit --jars /Users/folkol/code/spark/assembly/target/scala-2.12/jars/* --class examples.ClientExample ClientExample.jar --master spark://192.168.8.166:7077 --deploy-mode cluster


		SQL:
		Spark SQL is a Spark module for structured data processing. Unlike the basic Spark RDD API, the interfaces provided by Spark SQL provide Spark with more information about the structure of both the data and the computation being performed. Internally, Spark SQL uses this extra information to perform extra optimizations. There are several ways to interact with Spark SQL including SQL and the Dataset API. When computing a result, the same execution engine is used, independent of which API/language you are using to express the computation. This unification means that developers can easily switch back and forth between different APIs based on which provides the most natural way to express a given transformation.

		DataSet:
		- A Dataset is a distributed collection of data.
		- Dataset is a new interface added in Spark 1.6 that provides the benefits of RDDs (strong typing, ability to use powerful lambda functions) with the benefits of Spark SQL’s optimized execution engine.
		- A DataFrame is a Dataset organized into named columns.
		- It is conceptually equivalent to a table in a relational database or a data frame in R/Python, but with richer optimizations under the hood.
		- The DataFrame API is available in Scala, Java, Python, and R. In Scala and Java, a DataFrame is represented by a Dataset of Rows. In the Scala API, DataFrame is simply a type alias of Dataset[Row]. While, in Java API, users need to use Dataset<Row> to represent a DataFrame.

		Partition discovery:
		- https://spark.apache.org/docs/latest/sql-data-sources-parquet.html#partition-discovery
		- Table partitioning is a common optimization approach used in systems like Hive. In a partitioned table, data are usually stored in different directories, with partitioning column values encoded in the path of each partition directory. All built-in file sources (including Text/CSV/JSON/ORC/Parquet) are able to discover and infer partitioning information

		path
		└── to
		    └── table
		        ├── gender=male
		        │   ├── ...
		        │   │
		        │   ├── country=US
		        │   │   └── data.parquet
		        │   ├── country=CN
		        │   │   └── data.parquet
		        │   └── ...
		        └── gender=female
		            ├── ...
		            │
		            ├── country=US
		            │   └── data.parquet
		            ├── country=CN
		            │   └── data.parquet
		            └── ...



		scala> spark.sql("SELECT VendorName vendor, MAX(fare_amount) priciest FROM yellow LEFT JOIN names ON yellow.VendorID = names.VendorID GROUP BY VendorName ORDER BY priciest DESC").show()
		+-------+--------+
		| vendor|priciest|
		+-------+--------+
		|  Apple|  9792.0|
		|    IBM|  2221.3|
		|Bananas|  100.73|
		+-------+--------+

		Example run:

		/Users/folkol/.asdf/installs/java/corretto-17.0.12.7.1/bin/java --add-opens=java.base/sun.nio.ch=ALL-UNNAMED -javaagent:/Users/folkol/Applications/IntelliJ IDEA Ultimate.app/Contents/lib/idea_rt.jar=51989:/Users/folkol/Applications/IntelliJ IDEA Ultimate.app/Contents/bin -Dfile.encoding=UTF-8 -classpath /Users/folkol/code/spark/core/target/scala-2.12/classes:/Users/folkol/.m2/repository/org/apache/avro/avro/1.11.2/avro-1.11.2.jar:/Users/folkol/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.15.2/jackson-core-2.15.2.jar:/Users/folkol/.m2/repository/org/slf4j/slf4j-api/2.0.7/slf4j-api-2.0.7.jar:/Users/folkol/.m2/repository/org/apache/avro/avro-mapred/1.11.2/avro-mapred-1.11.2.jar:/Users/folkol/.m2/repository/org/apache/avro/avro-ipc/1.11.2/avro-ipc-1.11.2.jar:/Users/folkol/.m2/repository/org/tukaani/xz/1.9/xz-1.9.jar:/Users/folkol/.m2/repository/com/google/guava/guava/14.0.1/guava-14.0.1.jar:/Users/folkol/.m2/repository/com/twitter/chill_2.12/0.10.0/chill_2.12-0.10.0.jar:/Users/folkol/.m2/repository/com/esotericsoftware/kryo-shaded/4.0.2/kryo-shaded-4.0.2.jar:/Users/folkol/.m2/repository/com/esotericsoftware/minlog/1.3.0/minlog-1.3.0.jar:/Users/folkol/.m2/repository/com/twitter/chill-java/0.10.0/chill-java-0.10.0.jar:/Users/folkol/.m2/repository/org/apache/xbean/xbean-asm9-shaded/4.23/xbean-asm9-shaded-4.23.jar:/Users/folkol/.m2/repository/org/apache/hadoop/hadoop-client-api/3.3.4/hadoop-client-api-3.3.4.jar:/Users/folkol/.m2/repository/org/apache/hadoop/hadoop-client-runtime/3.3.4/hadoop-client-runtime-3.3.4.jar:/Users/folkol/.m2/repository/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar:/Users/folkol/code/spark/launcher/target/scala-2.12/classes:/Users/folkol/code/spark/common/kvstore/target/scala-2.12/classes:/Users/folkol/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/Users/folkol/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.15.2/jackson-annotations-2.15.2.jar:/Users/folkol/.m2/repository/org/rocksdb/rocksdbjni/8.3.2/rocksdbjni-8.3.2.jar:/Users/folkol/code/spark/common/network-common/target/scala-2.12/classes:/Users/folkol/.m2/repository/com/google/crypto/tink/tink/1.9.0/tink-1.9.0.jar:/Users/folkol/.m2/repository/com/google/code/gson/gson/2.10.1/gson-2.10.1.jar:/Users/folkol/.m2/repository/joda-time/joda-time/2.12.5/joda-time-2.12.5.jar:/Users/folkol/code/spark/common/network-shuffle/target/scala-2.12/classes:/Users/folkol/code/spark/common/unsafe/target/scala-2.12/classes:/Users/folkol/code/spark/common/utils/target/scala-2.12/classes:/Users/folkol/.m2/repository/org/slf4j/jul-to-slf4j/2.0.7/jul-to-slf4j-2.0.7.jar:/Users/folkol/.m2/repository/org/slf4j/jcl-over-slf4j/2.0.7/jcl-over-slf4j-2.0.7.jar:/Users/folkol/.m2/repository/org/apache/logging/log4j/log4j-slf4j2-impl/2.20.0/log4j-slf4j2-impl-2.20.0.jar:/Users/folkol/.m2/repository/org/apache/logging/log4j/log4j-api/2.20.0/log4j-api-2.20.0.jar:/Users/folkol/.m2/repository/org/apache/logging/log4j/log4j-core/2.20.0/log4j-core-2.20.0.jar:/Users/folkol/.m2/repository/org/apache/logging/log4j/log4j-1.2-api/2.20.0/log4j-1.2-api-2.20.0.jar:/Users/folkol/.m2/repository/javax/activation/activation/1.1.1/activation-1.1.1.jar:/Users/folkol/.m2/repository/org/apache/curator/curator-recipes/2.13.0/curator-recipes-2.13.0.jar:/Users/folkol/.m2/repository/org/apache/curator/curator-framework/2.13.0/curator-framework-2.13.0.jar:/Users/folkol/.m2/repository/org/apache/curator/curator-client/2.13.0/curator-client-2.13.0.jar:/Users/folkol/.m2/repository/org/apache/zookeeper/zookeeper/3.6.3/zookeeper-3.6.3.jar:/Users/folkol/.m2/repository/org/apache/zookeeper/zookeeper-jute/3.6.3/zookeeper-jute-3.6.3.jar:/Users/folkol/.m2/repository/org/apache/yetus/audience-annotations/0.5.0/audience-annotations-0.5.0.jar:/Users/folkol/.m2/repository/org/eclipse/jetty/jetty-plus/9.4.52.v20230823/jetty-plus-9.4.52.v20230823.jar:/Users/folkol/.m2/repository/org/eclipse/jetty/jetty-webapp/9.4.52.v20230823/jetty-webapp-9.4.52.v20230823.jar:/Users/folkol/.m2/repository/org/eclipse/jetty/jetty-xml/9.4.52.v20230823/jetty-xml-9.4.52.v20230823.jar:/Users/folkol/.m2/repository/org/eclipse/jetty/jetty-jndi/9.4.52.v20230823/jetty-jndi-9.4.52.v20230823.jar:/Users/folkol/.m2/repository/org/eclipse/jetty/jetty-security/9.4.52.v20230823/jetty-security-9.4.52.v20230823.jar:/Users/folkol/.m2/repository/org/eclipse/jetty/jetty-util/9.4.52.v20230823/jetty-util-9.4.52.v20230823.jar:/Users/folkol/.m2/repository/org/eclipse/jetty/jetty-server/9.4.52.v20230823/jetty-server-9.4.52.v20230823.jar:/Users/folkol/.m2/repository/javax/servlet/javax.servlet-api/3.1.0/javax.servlet-api-3.1.0.jar:/Users/folkol/.m2/repository/org/eclipse/jetty/jetty-io/9.4.52.v20230823/jetty-io-9.4.52.v20230823.jar:/Users/folkol/.m2/repository/org/eclipse/jetty/jetty-http/9.4.52.v20230823/jetty-http-9.4.52.v20230823.jar:/Users/folkol/.m2/repository/org/eclipse/jetty/jetty-continuation/9.4.52.v20230823/jetty-continuation-9.4.52.v20230823.jar:/Users/folkol/.m2/repository/org/eclipse/jetty/jetty-servlet/9.4.52.v20230823/jetty-servlet-9.4.52.v20230823.jar:/Users/folkol/.m2/repository/org/eclipse/jetty/jetty-util-ajax/9.4.52.v20230823/jetty-util-ajax-9.4.52.v20230823.jar:/Users/folkol/.m2/repository/org/eclipse/jetty/jetty-proxy/9.4.52.v20230823/jetty-proxy-9.4.52.v20230823.jar:/Users/folkol/.m2/repository/org/eclipse/jetty/jetty-client/9.4.52.v20230823/jetty-client-9.4.52.v20230823.jar:/Users/folkol/.m2/repository/org/eclipse/jetty/jetty-servlets/9.4.52.v20230823/jetty-servlets-9.4.52.v20230823.jar:/Users/folkol/.m2/repository/jakarta/servlet/jakarta.servlet-api/4.0.3/jakarta.servlet-api-4.0.3.jar:/Users/folkol/.m2/repository/commons-codec/commons-codec/1.16.0/commons-codec-1.16.0.jar:/Users/folkol/.m2/repository/org/apache/commons/commons-compress/1.23.0/commons-compress-1.23.0.jar:/Users/folkol/.m2/repository/org/apache/commons/commons-lang3/3.12.0/commons-lang3-3.12.0.jar:/Users/folkol/.m2/repository/org/apache/commons/commons-math3/3.6.1/commons-math3-3.6.1.jar:/Users/folkol/.m2/repository/org/apache/commons/commons-text/1.10.0/commons-text-1.10.0.jar:/Users/folkol/.m2/repository/commons-io/commons-io/2.13.0/commons-io-2.13.0.jar:/Users/folkol/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/Users/folkol/.m2/repository/org/apache/commons/commons-collections4/4.4/commons-collections4-4.4.jar:/Users/folkol/.m2/repository/com/google/code/findbugs/jsr305/3.0.0/jsr305-3.0.0.jar:/Users/folkol/.m2/repository/com/ning/compress-lzf/1.1.2/compress-lzf-1.1.2.jar:/Users/folkol/.m2/repository/org/xerial/snappy/snappy-java/1.1.10.3/snappy-java-1.1.10.3.jar:/Users/folkol/.m2/repository/org/lz4/lz4-java/1.8.0/lz4-java-1.8.0.jar:/Users/folkol/.m2/repository/com/github/luben/zstd-jni/1.5.5-4/zstd-jni-1.5.5-4.jar:/Users/folkol/.m2/repository/org/roaringbitmap/RoaringBitmap/0.9.45/RoaringBitmap-0.9.45.jar:/Users/folkol/.m2/repository/org/roaringbitmap/shims/0.9.45/shims-0.9.45.jar:/Users/folkol/.m2/repository/org/scala-lang/modules/scala-xml_2.12/2.1.0/scala-xml_2.12-2.1.0.jar:/Users/folkol/.m2/repository/org/scala-lang/scala-library/2.12.18/scala-library-2.12.18.jar:/Users/folkol/.m2/repository/org/scala-lang/scala-reflect/2.12.18/scala-reflect-2.12.18.jar:/Users/folkol/.m2/repository/org/json4s/json4s-jackson_2.12/3.7.0-M11/json4s-jackson_2.12-3.7.0-M11.jar:/Users/folkol/.m2/repository/org/json4s/json4s-core_2.12/3.7.0-M11/json4s-core_2.12-3.7.0-M11.jar:/Users/folkol/.m2/repository/org/json4s/json4s-ast_2.12/3.7.0-M11/json4s-ast_2.12-3.7.0-M11.jar:/Users/folkol/.m2/repository/org/json4s/json4s-scalap_2.12/3.7.0-M11/json4s-scalap_2.12-3.7.0-M11.jar:/Users/folkol/.m2/repository/org/glassfish/jersey/core/jersey-client/2.40/jersey-client-2.40.jar:/Users/folkol/.m2/repository/jakarta/ws/rs/jakarta.ws.rs-api/2.1.6/jakarta.ws.rs-api-2.1.6.jar:/Users/folkol/.m2/repository/org/glassfish/hk2/external/jakarta.inject/2.6.1/jakarta.inject-2.6.1.jar:/Users/folkol/.m2/repository/org/glassfish/jersey/core/jersey-common/2.40/jersey-common-2.40.jar:/Users/folkol/.m2/repository/jakarta/annotation/jakarta.annotation-api/1.3.5/jakarta.annotation-api-1.3.5.jar:/Users/folkol/.m2/repository/org/glassfish/hk2/osgi-resource-locator/1.0.3/osgi-resource-locator-1.0.3.jar:/Users/folkol/.m2/repository/org/glassfish/jersey/core/jersey-server/2.40/jersey-server-2.40.jar:/Users/folkol/.m2/repository/jakarta/validation/jakarta.validation-api/2.0.2/jakarta.validation-api-2.0.2.jar:/Users/folkol/.m2/repository/org/glassfish/jersey/containers/jersey-container-servlet/2.40/jersey-container-servlet-2.40.jar:/Users/folkol/.m2/repository/org/glassfish/jersey/containers/jersey-container-servlet-core/2.40/jersey-container-servlet-core-2.40.jar:/Users/folkol/.m2/repository/org/glassfish/jersey/inject/jersey-hk2/2.40/jersey-hk2-2.40.jar:/Users/folkol/.m2/repository/org/glassfish/hk2/hk2-locator/2.6.1/hk2-locator-2.6.1.jar:/Users/folkol/.m2/repository/org/glassfish/hk2/external/aopalliance-repackaged/2.6.1/aopalliance-repackaged-2.6.1.jar:/Users/folkol/.m2/repository/org/glassfish/hk2/hk2-api/2.6.1/hk2-api-2.6.1.jar:/Users/folkol/.m2/repository/org/glassfish/hk2/hk2-utils/2.6.1/hk2-utils-2.6.1.jar:/Users/folkol/.m2/repository/org/javassist/javassist/3.29.2-GA/javassist-3.29.2-GA.jar:/Users/folkol/.m2/repository/io/netty/netty-all/4.1.96.Final/netty-all-4.1.96.Final.jar:/Users/folkol/.m2/repository/io/netty/netty-buffer/4.1.96.Final/netty-buffer-4.1.96.Final.jar:/Users/folkol/.m2/repository/io/netty/netty-codec/4.1.96.Final/netty-codec-4.1.96.Final.jar:/Users/folkol/.m2/repository/io/netty/netty-codec-http/4.1.96.Final/netty-codec-http-4.1.96.Final.jar:/Users/folkol/.m2/repository/io/netty/netty-codec-http2/4.1.96.Final/netty-codec-http2-4.1.96.Final.jar:/Users/folkol/.m2/repository/io/netty/netty-codec-socks/4.1.96.Final/netty-codec-socks-4.1.96.Final.jar:/Users/folkol/.m2/repository/io/netty/netty-common/4.1.96.Final/netty-common-4.1.96.Final.jar:/Users/folkol/.m2/repository/io/netty/netty-handler/4.1.96.Final/netty-handler-4.1.96.Final.jar:/Users/folkol/.m2/repository/io/netty/netty-transport-native-unix-common/4.1.96.Final/netty-transport-native-unix-common-4.1.96.Final.jar:/Users/folkol/.m2/repository/io/netty/netty-handler-proxy/4.1.96.Final/netty-handler-proxy-4.1.96.Final.jar:/Users/folkol/.m2/repository/io/netty/netty-resolver/4.1.96.Final/netty-resolver-4.1.96.Final.jar:/Users/folkol/.m2/repository/io/netty/netty-transport/4.1.96.Final/netty-transport-4.1.96.Final.jar:/Users/folkol/.m2/repository/io/netty/netty-transport-classes-epoll/4.1.96.Final/netty-transport-classes-epoll-4.1.96.Final.jar:/Users/folkol/.m2/repository/io/netty/netty-transport-classes-kqueue/4.1.96.Final/netty-transport-classes-kqueue-4.1.96.Final.jar:/Users/folkol/.m2/repository/io/netty/netty-transport-native-epoll/4.1.96.Final/netty-transport-native-epoll-4.1.96.Final-linux-x86_64.jar:/Users/folkol/.m2/repository/io/netty/netty-transport-native-epoll/4.1.96.Final/netty-transport-native-epoll-4.1.96.Final-linux-aarch_64.jar:/Users/folkol/.m2/repository/io/netty/netty-transport-native-kqueue/4.1.96.Final/netty-transport-native-kqueue-4.1.96.Final-osx-aarch_64.jar:/Users/folkol/.m2/repository/io/netty/netty-transport-native-kqueue/4.1.96.Final/netty-transport-native-kqueue-4.1.96.Final-osx-x86_64.jar:/Users/folkol/.m2/repository/com/clearspring/analytics/stream/2.9.6/stream-2.9.6.jar:/Users/folkol/.m2/repository/io/dropwizard/metrics/metrics-core/4.2.19/metrics-core-4.2.19.jar:/Users/folkol/.m2/repository/io/dropwizard/metrics/metrics-jvm/4.2.19/metrics-jvm-4.2.19.jar:/Users/folkol/.m2/repository/io/dropwizard/metrics/metrics-json/4.2.19/metrics-json-4.2.19.jar:/Users/folkol/.m2/repository/io/dropwizard/metrics/metrics-graphite/4.2.19/metrics-graphite-4.2.19.jar:/Users/folkol/.m2/repository/io/dropwizard/metrics/metrics-jmx/4.2.19/metrics-jmx-4.2.19.jar:/Users/folkol/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.15.2/jackson-databind-2.15.2.jar:/Users/folkol/.m2/repository/com/fasterxml/jackson/module/jackson-module-scala_2.12/2.15.2/jackson-module-scala_2.12-2.15.2.jar:/Users/folkol/.m2/repository/com/thoughtworks/paranamer/paranamer/2.8/paranamer-2.8.jar:/Users/folkol/.m2/repository/org/apache/ivy/ivy/2.5.1/ivy-2.5.1.jar:/Users/folkol/.m2/repository/oro/oro/2.0.8/oro-2.0.8.jar:/Users/folkol/.m2/repository/org/objenesis/objenesis/3.3/objenesis-3.3.jar:/Users/folkol/.m2/repository/net/razorvine/pickle/1.3/pickle-1.3.jar:/Users/folkol/.m2/repository/net/sf/py4j/py4j/0.10.9.7/py4j-0.10.9.7.jar:/Users/folkol/code/spark/common/tags/target/scala-2.12/classes:/Users/folkol/.m2/repository/org/apache/commons/commons-crypto/1.1.0/commons-crypto-1.1.0.jar:/Users/folkol/.m2/repository/com/google/protobuf/protobuf-java/3.23.4/protobuf-java-3.23.4.jar:/Users/folkol/.m2/repository/org/spark-project/spark/unused/1.0.0/unused-1.0.0.jar:/Users/folkol/code/spark/launcher/target/spark-launcher_2.12-3.5.1.jar:/Users/folkol/code/spark/common/kvstore/target/spark-kvstore_2.12-3.5.1.jar:/Users/folkol/code/spark/common/network-common/target/spark-network-common_2.12-3.5.1.jar:/Users/folkol/code/spark/common/network-shuffle/target/spark-network-shuffle_2.12-3.5.1.jar:/Users/folkol/code/spark/common/unsafe/target/spark-unsafe_2.12-3.5.1.jar:/Users/folkol/code/spark/common/utils/target/spark-common-utils_2.12-3.5.1.jar:/Users/folkol/code/spark/common/tags/target/spark-tags_2.12-3.5.1.jar org.apache.spark.deploy.SparkSubmit --jars /Users/folkol/code/spark/assembly/target/scala-2.12/jars/* --class examples.ClientExample ClientExample.jar --master spark://192.168.8.166:7077 --deploy-mode cluster
		24/08/05 15:42:15 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
		24/08/05 15:42:15 INFO SparkContext: Running Spark version 3.5.1
		24/08/05 15:42:15 INFO SparkContext: OS info Mac OS X, 11.7.10, x86_64
		24/08/05 15:42:15 INFO SparkContext: Java version 17.0.12
		24/08/05 15:42:15 INFO ResourceUtils: ==============================================================
		24/08/05 15:42:15 INFO ResourceUtils: No custom resources configured for spark.driver.
		24/08/05 15:42:15 INFO ResourceUtils: ==============================================================
		24/08/05 15:42:15 INFO SparkContext: Submitted application: Java Spark SQL basic example
		24/08/05 15:42:15 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
		24/08/05 15:42:15 INFO ResourceProfile: Limiting resource is cpu
		24/08/05 15:42:15 INFO ResourceProfileManager: Added ResourceProfile id: 0
		24/08/05 15:42:16 INFO SecurityManager: Changing view acls to: folkol
		24/08/05 15:42:16 INFO SecurityManager: Changing modify acls to: folkol
		24/08/05 15:42:16 INFO SecurityManager: Changing view acls groups to: 
		24/08/05 15:42:16 INFO SecurityManager: Changing modify acls groups to: 
		24/08/05 15:42:16 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: folkol; groups with view permissions: EMPTY; users with modify permissions: folkol; groups with modify permissions: EMPTY
		24/08/05 15:42:16 INFO Utils: Successfully started service 'sparkDriver' on port 51992.
		24/08/05 15:42:16 INFO SparkEnv: Registering MapOutputTracker
		24/08/05 15:42:16 INFO SparkEnv: Registering BlockManagerMaster
		24/08/05 15:42:16 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
		24/08/05 15:42:16 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
		24/08/05 15:42:16 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
		24/08/05 15:42:16 INFO DiskBlockManager: Created local directory at /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/blockmgr-5c95e79d-df5c-4ab5-9a89-69ccc73fb2fa
		24/08/05 15:42:16 INFO MemoryStore: MemoryStore started with capacity 2.2 GiB
		24/08/05 15:42:16 INFO SparkEnv: Registering OutputCommitCoordinator
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/JLargeArrays-1.5.jar at spark://192.168.8.166:51992/jars/JLargeArrays-1.5.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/JTransforms-3.1.jar at spark://192.168.8.166:51992/jars/JTransforms-3.1.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/RoaringBitmap-0.9.45.jar at spark://192.168.8.166:51992/jars/RoaringBitmap-0.9.45.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/activation-1.1.1.jar at spark://192.168.8.166:51992/jars/activation-1.1.1.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/aircompressor-0.26.jar at spark://192.168.8.166:51992/jars/aircompressor-0.26.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/algebra_2.12-2.0.1.jar at spark://192.168.8.166:51992/jars/algebra_2.12-2.0.1.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/annotations-17.0.0.jar at spark://192.168.8.166:51992/jars/annotations-17.0.0.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/antlr4-runtime-4.9.3.jar at spark://192.168.8.166:51992/jars/antlr4-runtime-4.9.3.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/aopalliance-repackaged-2.6.1.jar at spark://192.168.8.166:51992/jars/aopalliance-repackaged-2.6.1.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/arpack-3.0.3.jar at spark://192.168.8.166:51992/jars/arpack-3.0.3.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/arpack_combined_all-0.1.jar at spark://192.168.8.166:51992/jars/arpack_combined_all-0.1.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/arrow-format-12.0.1.jar at spark://192.168.8.166:51992/jars/arrow-format-12.0.1.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/arrow-memory-core-12.0.1.jar at spark://192.168.8.166:51992/jars/arrow-memory-core-12.0.1.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/arrow-memory-netty-12.0.1.jar at spark://192.168.8.166:51992/jars/arrow-memory-netty-12.0.1.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/arrow-vector-12.0.1.jar at spark://192.168.8.166:51992/jars/arrow-vector-12.0.1.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/audience-annotations-0.5.0.jar at spark://192.168.8.166:51992/jars/audience-annotations-0.5.0.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/avro-1.11.2.jar at spark://192.168.8.166:51992/jars/avro-1.11.2.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/avro-ipc-1.11.2.jar at spark://192.168.8.166:51992/jars/avro-ipc-1.11.2.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/avro-mapred-1.11.2.jar at spark://192.168.8.166:51992/jars/avro-mapred-1.11.2.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/blas-3.0.3.jar at spark://192.168.8.166:51992/jars/blas-3.0.3.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/breeze-macros_2.12-2.1.0.jar at spark://192.168.8.166:51992/jars/breeze-macros_2.12-2.1.0.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/breeze_2.12-2.1.0.jar at spark://192.168.8.166:51992/jars/breeze_2.12-2.1.0.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/cats-kernel_2.12-2.1.1.jar at spark://192.168.8.166:51992/jars/cats-kernel_2.12-2.1.1.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/chill-java-0.10.0.jar at spark://192.168.8.166:51992/jars/chill-java-0.10.0.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/chill_2.12-0.10.0.jar at spark://192.168.8.166:51992/jars/chill_2.12-0.10.0.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/commons-codec-1.16.0.jar at spark://192.168.8.166:51992/jars/commons-codec-1.16.0.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/commons-collections-3.2.2.jar at spark://192.168.8.166:51992/jars/commons-collections-3.2.2.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/commons-collections4-4.4.jar at spark://192.168.8.166:51992/jars/commons-collections4-4.4.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/commons-compiler-3.1.9.jar at spark://192.168.8.166:51992/jars/commons-compiler-3.1.9.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/commons-compress-1.23.0.jar at spark://192.168.8.166:51992/jars/commons-compress-1.23.0.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/commons-crypto-1.1.0.jar at spark://192.168.8.166:51992/jars/commons-crypto-1.1.0.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/commons-io-2.13.0.jar at spark://192.168.8.166:51992/jars/commons-io-2.13.0.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/commons-lang3-3.12.0.jar at spark://192.168.8.166:51992/jars/commons-lang3-3.12.0.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/commons-logging-1.1.3.jar at spark://192.168.8.166:51992/jars/commons-logging-1.1.3.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/commons-math3-3.6.1.jar at spark://192.168.8.166:51992/jars/commons-math3-3.6.1.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/commons-text-1.10.0.jar at spark://192.168.8.166:51992/jars/commons-text-1.10.0.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/compress-lzf-1.1.2.jar at spark://192.168.8.166:51992/jars/compress-lzf-1.1.2.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/curator-client-2.13.0.jar at spark://192.168.8.166:51992/jars/curator-client-2.13.0.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/curator-framework-2.13.0.jar at spark://192.168.8.166:51992/jars/curator-framework-2.13.0.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/curator-recipes-2.13.0.jar at spark://192.168.8.166:51992/jars/curator-recipes-2.13.0.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/datasketches-java-3.3.0.jar at spark://192.168.8.166:51992/jars/datasketches-java-3.3.0.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/datasketches-memory-2.1.0.jar at spark://192.168.8.166:51992/jars/datasketches-memory-2.1.0.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/flatbuffers-java-1.12.0.jar at spark://192.168.8.166:51992/jars/flatbuffers-java-1.12.0.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/gson-2.10.1.jar at spark://192.168.8.166:51992/jars/gson-2.10.1.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/guava-14.0.1.jar at spark://192.168.8.166:51992/jars/guava-14.0.1.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/hadoop-client-api-3.3.4.jar at spark://192.168.8.166:51992/jars/hadoop-client-api-3.3.4.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/hadoop-client-runtime-3.3.4.jar at spark://192.168.8.166:51992/jars/hadoop-client-runtime-3.3.4.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/hive-storage-api-2.8.1.jar at spark://192.168.8.166:51992/jars/hive-storage-api-2.8.1.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/hk2-api-2.6.1.jar at spark://192.168.8.166:51992/jars/hk2-api-2.6.1.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/hk2-locator-2.6.1.jar at spark://192.168.8.166:51992/jars/hk2-locator-2.6.1.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/hk2-utils-2.6.1.jar at spark://192.168.8.166:51992/jars/hk2-utils-2.6.1.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/istack-commons-runtime-3.0.8.jar at spark://192.168.8.166:51992/jars/istack-commons-runtime-3.0.8.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/ivy-2.5.1.jar at spark://192.168.8.166:51992/jars/ivy-2.5.1.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/jackson-annotations-2.15.2.jar at spark://192.168.8.166:51992/jars/jackson-annotations-2.15.2.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/jackson-core-2.15.2.jar at spark://192.168.8.166:51992/jars/jackson-core-2.15.2.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/jackson-databind-2.15.2.jar at spark://192.168.8.166:51992/jars/jackson-databind-2.15.2.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/jackson-datatype-jsr310-2.15.2.jar at spark://192.168.8.166:51992/jars/jackson-datatype-jsr310-2.15.2.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/jackson-module-scala_2.12-2.15.2.jar at spark://192.168.8.166:51992/jars/jackson-module-scala_2.12-2.15.2.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/jakarta.annotation-api-1.3.5.jar at spark://192.168.8.166:51992/jars/jakarta.annotation-api-1.3.5.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/jakarta.inject-2.6.1.jar at spark://192.168.8.166:51992/jars/jakarta.inject-2.6.1.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/jakarta.servlet-api-4.0.3.jar at spark://192.168.8.166:51992/jars/jakarta.servlet-api-4.0.3.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/jakarta.validation-api-2.0.2.jar at spark://192.168.8.166:51992/jars/jakarta.validation-api-2.0.2.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/jakarta.ws.rs-api-2.1.6.jar at spark://192.168.8.166:51992/jars/jakarta.ws.rs-api-2.1.6.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/jakarta.xml.bind-api-2.3.2.jar at spark://192.168.8.166:51992/jars/jakarta.xml.bind-api-2.3.2.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/janino-3.1.9.jar at spark://192.168.8.166:51992/jars/janino-3.1.9.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/javassist-3.29.2-GA.jar at spark://192.168.8.166:51992/jars/javassist-3.29.2-GA.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/jaxb-runtime-2.3.2.jar at spark://192.168.8.166:51992/jars/jaxb-runtime-2.3.2.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/jcl-over-slf4j-2.0.7.jar at spark://192.168.8.166:51992/jars/jcl-over-slf4j-2.0.7.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/jersey-client-2.40.jar at spark://192.168.8.166:51992/jars/jersey-client-2.40.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/jersey-common-2.40.jar at spark://192.168.8.166:51992/jars/jersey-common-2.40.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/jersey-container-servlet-2.40.jar at spark://192.168.8.166:51992/jars/jersey-container-servlet-2.40.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/jersey-container-servlet-core-2.40.jar at spark://192.168.8.166:51992/jars/jersey-container-servlet-core-2.40.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/jersey-hk2-2.40.jar at spark://192.168.8.166:51992/jars/jersey-hk2-2.40.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/jersey-server-2.40.jar at spark://192.168.8.166:51992/jars/jersey-server-2.40.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/joda-time-2.12.5.jar at spark://192.168.8.166:51992/jars/joda-time-2.12.5.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/json4s-ast_2.12-3.7.0-M11.jar at spark://192.168.8.166:51992/jars/json4s-ast_2.12-3.7.0-M11.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/json4s-core_2.12-3.7.0-M11.jar at spark://192.168.8.166:51992/jars/json4s-core_2.12-3.7.0-M11.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/json4s-jackson_2.12-3.7.0-M11.jar at spark://192.168.8.166:51992/jars/json4s-jackson_2.12-3.7.0-M11.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/json4s-scalap_2.12-3.7.0-M11.jar at spark://192.168.8.166:51992/jars/json4s-scalap_2.12-3.7.0-M11.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/jsr305-3.0.0.jar at spark://192.168.8.166:51992/jars/jsr305-3.0.0.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/jul-to-slf4j-2.0.7.jar at spark://192.168.8.166:51992/jars/jul-to-slf4j-2.0.7.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/kryo-shaded-4.0.2.jar at spark://192.168.8.166:51992/jars/kryo-shaded-4.0.2.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/lapack-3.0.3.jar at spark://192.168.8.166:51992/jars/lapack-3.0.3.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/leveldbjni-all-1.8.jar at spark://192.168.8.166:51992/jars/leveldbjni-all-1.8.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/log4j-1.2-api-2.20.0.jar at spark://192.168.8.166:51992/jars/log4j-1.2-api-2.20.0.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/log4j-api-2.20.0.jar at spark://192.168.8.166:51992/jars/log4j-api-2.20.0.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/log4j-core-2.20.0.jar at spark://192.168.8.166:51992/jars/log4j-core-2.20.0.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/log4j-slf4j2-impl-2.20.0.jar at spark://192.168.8.166:51992/jars/log4j-slf4j2-impl-2.20.0.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/lz4-java-1.8.0.jar at spark://192.168.8.166:51992/jars/lz4-java-1.8.0.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/metrics-core-4.2.19.jar at spark://192.168.8.166:51992/jars/metrics-core-4.2.19.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/metrics-graphite-4.2.19.jar at spark://192.168.8.166:51992/jars/metrics-graphite-4.2.19.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/metrics-jmx-4.2.19.jar at spark://192.168.8.166:51992/jars/metrics-jmx-4.2.19.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/metrics-json-4.2.19.jar at spark://192.168.8.166:51992/jars/metrics-json-4.2.19.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/metrics-jvm-4.2.19.jar at spark://192.168.8.166:51992/jars/metrics-jvm-4.2.19.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/minlog-1.3.0.jar at spark://192.168.8.166:51992/jars/minlog-1.3.0.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/netty-all-4.1.96.Final.jar at spark://192.168.8.166:51992/jars/netty-all-4.1.96.Final.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/netty-buffer-4.1.96.Final.jar at spark://192.168.8.166:51992/jars/netty-buffer-4.1.96.Final.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/netty-codec-4.1.96.Final.jar at spark://192.168.8.166:51992/jars/netty-codec-4.1.96.Final.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/netty-codec-http-4.1.96.Final.jar at spark://192.168.8.166:51992/jars/netty-codec-http-4.1.96.Final.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/netty-codec-http2-4.1.96.Final.jar at spark://192.168.8.166:51992/jars/netty-codec-http2-4.1.96.Final.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/netty-codec-socks-4.1.96.Final.jar at spark://192.168.8.166:51992/jars/netty-codec-socks-4.1.96.Final.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/netty-common-4.1.96.Final.jar at spark://192.168.8.166:51992/jars/netty-common-4.1.96.Final.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/netty-handler-4.1.96.Final.jar at spark://192.168.8.166:51992/jars/netty-handler-4.1.96.Final.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/netty-handler-proxy-4.1.96.Final.jar at spark://192.168.8.166:51992/jars/netty-handler-proxy-4.1.96.Final.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/netty-resolver-4.1.96.Final.jar at spark://192.168.8.166:51992/jars/netty-resolver-4.1.96.Final.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/netty-transport-4.1.96.Final.jar at spark://192.168.8.166:51992/jars/netty-transport-4.1.96.Final.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/netty-transport-classes-epoll-4.1.96.Final.jar at spark://192.168.8.166:51992/jars/netty-transport-classes-epoll-4.1.96.Final.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/netty-transport-classes-kqueue-4.1.96.Final.jar at spark://192.168.8.166:51992/jars/netty-transport-classes-kqueue-4.1.96.Final.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/netty-transport-native-epoll-4.1.96.Final-linux-aarch_64.jar at spark://192.168.8.166:51992/jars/netty-transport-native-epoll-4.1.96.Final-linux-aarch_64.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/netty-transport-native-epoll-4.1.96.Final-linux-x86_64.jar at spark://192.168.8.166:51992/jars/netty-transport-native-epoll-4.1.96.Final-linux-x86_64.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/netty-transport-native-kqueue-4.1.96.Final-osx-aarch_64.jar at spark://192.168.8.166:51992/jars/netty-transport-native-kqueue-4.1.96.Final-osx-aarch_64.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/netty-transport-native-kqueue-4.1.96.Final-osx-x86_64.jar at spark://192.168.8.166:51992/jars/netty-transport-native-kqueue-4.1.96.Final-osx-x86_64.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/netty-transport-native-unix-common-4.1.96.Final.jar at spark://192.168.8.166:51992/jars/netty-transport-native-unix-common-4.1.96.Final.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/objenesis-3.3.jar at spark://192.168.8.166:51992/jars/objenesis-3.3.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/opencsv-2.3.jar at spark://192.168.8.166:51992/jars/opencsv-2.3.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/orc-core-1.9.2-shaded-protobuf.jar at spark://192.168.8.166:51992/jars/orc-core-1.9.2-shaded-protobuf.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/orc-mapreduce-1.9.2-shaded-protobuf.jar at spark://192.168.8.166:51992/jars/orc-mapreduce-1.9.2-shaded-protobuf.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/orc-shims-1.9.2.jar at spark://192.168.8.166:51992/jars/orc-shims-1.9.2.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/oro-2.0.8.jar at spark://192.168.8.166:51992/jars/oro-2.0.8.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/osgi-resource-locator-1.0.3.jar at spark://192.168.8.166:51992/jars/osgi-resource-locator-1.0.3.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/paranamer-2.8.jar at spark://192.168.8.166:51992/jars/paranamer-2.8.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/parquet-column-1.13.1.jar at spark://192.168.8.166:51992/jars/parquet-column-1.13.1.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/parquet-common-1.13.1.jar at spark://192.168.8.166:51992/jars/parquet-common-1.13.1.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/parquet-encoding-1.13.1.jar at spark://192.168.8.166:51992/jars/parquet-encoding-1.13.1.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/parquet-format-structures-1.13.1.jar at spark://192.168.8.166:51992/jars/parquet-format-structures-1.13.1.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/parquet-hadoop-1.13.1.jar at spark://192.168.8.166:51992/jars/parquet-hadoop-1.13.1.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/parquet-jackson-1.13.1.jar at spark://192.168.8.166:51992/jars/parquet-jackson-1.13.1.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/pickle-1.3.jar at spark://192.168.8.166:51992/jars/pickle-1.3.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/py4j-0.10.9.7.jar at spark://192.168.8.166:51992/jars/py4j-0.10.9.7.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/rocksdbjni-8.3.2.jar at spark://192.168.8.166:51992/jars/rocksdbjni-8.3.2.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/scala-collection-compat_2.12-2.7.0.jar at spark://192.168.8.166:51992/jars/scala-collection-compat_2.12-2.7.0.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/scala-compiler-2.12.18.jar at spark://192.168.8.166:51992/jars/scala-compiler-2.12.18.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/scala-library-2.12.18.jar at spark://192.168.8.166:51992/jars/scala-library-2.12.18.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/scala-parser-combinators_2.12-2.3.0.jar at spark://192.168.8.166:51992/jars/scala-parser-combinators_2.12-2.3.0.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/scala-reflect-2.12.18.jar at spark://192.168.8.166:51992/jars/scala-reflect-2.12.18.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/scala-xml_2.12-2.1.0.jar at spark://192.168.8.166:51992/jars/scala-xml_2.12-2.1.0.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/shims-0.9.45.jar at spark://192.168.8.166:51992/jars/shims-0.9.45.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/slf4j-api-2.0.7.jar at spark://192.168.8.166:51992/jars/slf4j-api-2.0.7.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/snappy-java-1.1.10.3.jar at spark://192.168.8.166:51992/jars/snappy-java-1.1.10.3.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/spark-catalyst_2.12-3.5.1.jar at spark://192.168.8.166:51992/jars/spark-catalyst_2.12-3.5.1.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/spark-common-utils_2.12-3.5.1.jar at spark://192.168.8.166:51992/jars/spark-common-utils_2.12-3.5.1.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/spark-core_2.12-3.5.1.jar at spark://192.168.8.166:51992/jars/spark-core_2.12-3.5.1.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/spark-graphx_2.12-3.5.1.jar at spark://192.168.8.166:51992/jars/spark-graphx_2.12-3.5.1.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/spark-kvstore_2.12-3.5.1.jar at spark://192.168.8.166:51992/jars/spark-kvstore_2.12-3.5.1.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/spark-launcher_2.12-3.5.1.jar at spark://192.168.8.166:51992/jars/spark-launcher_2.12-3.5.1.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/spark-mllib-local_2.12-3.5.1.jar at spark://192.168.8.166:51992/jars/spark-mllib-local_2.12-3.5.1.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/spark-mllib_2.12-3.5.1.jar at spark://192.168.8.166:51992/jars/spark-mllib_2.12-3.5.1.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/spark-network-common_2.12-3.5.1.jar at spark://192.168.8.166:51992/jars/spark-network-common_2.12-3.5.1.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/spark-network-shuffle_2.12-3.5.1.jar at spark://192.168.8.166:51992/jars/spark-network-shuffle_2.12-3.5.1.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/spark-repl_2.12-3.5.1.jar at spark://192.168.8.166:51992/jars/spark-repl_2.12-3.5.1.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/spark-sketch_2.12-3.5.1.jar at spark://192.168.8.166:51992/jars/spark-sketch_2.12-3.5.1.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/spark-sql-api_2.12-3.5.1.jar at spark://192.168.8.166:51992/jars/spark-sql-api_2.12-3.5.1.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/spark-sql_2.12-3.5.1.jar at spark://192.168.8.166:51992/jars/spark-sql_2.12-3.5.1.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/spark-streaming_2.12-3.5.1.jar at spark://192.168.8.166:51992/jars/spark-streaming_2.12-3.5.1.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/spark-tags_2.12-3.5.1.jar at spark://192.168.8.166:51992/jars/spark-tags_2.12-3.5.1.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/spark-unsafe_2.12-3.5.1.jar at spark://192.168.8.166:51992/jars/spark-unsafe_2.12-3.5.1.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/spire-macros_2.12-0.17.0.jar at spark://192.168.8.166:51992/jars/spire-macros_2.12-0.17.0.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/spire-platform_2.12-0.17.0.jar at spark://192.168.8.166:51992/jars/spire-platform_2.12-0.17.0.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/spire-util_2.12-0.17.0.jar at spark://192.168.8.166:51992/jars/spire-util_2.12-0.17.0.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/spire_2.12-0.17.0.jar at spark://192.168.8.166:51992/jars/spire_2.12-0.17.0.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/stream-2.9.6.jar at spark://192.168.8.166:51992/jars/stream-2.9.6.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/threeten-extra-1.7.1.jar at spark://192.168.8.166:51992/jars/threeten-extra-1.7.1.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/tink-1.9.0.jar at spark://192.168.8.166:51992/jars/tink-1.9.0.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/univocity-parsers-2.9.1.jar at spark://192.168.8.166:51992/jars/univocity-parsers-2.9.1.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/xbean-asm9-shaded-4.23.jar at spark://192.168.8.166:51992/jars/xbean-asm9-shaded-4.23.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/xz-1.9.jar at spark://192.168.8.166:51992/jars/xz-1.9.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/zookeeper-3.6.3.jar at spark://192.168.8.166:51992/jars/zookeeper-3.6.3.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/zookeeper-jute-3.6.3.jar at spark://192.168.8.166:51992/jars/zookeeper-jute-3.6.3.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/assembly/target/scala-2.12/jars/zstd-jni-1.5.5-4.jar at spark://192.168.8.166:51992/jars/zstd-jni-1.5.5-4.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO SparkContext: Added JAR file:/Users/folkol/code/spark/ClientExample.jar at spark://192.168.8.166:51992/jars/ClientExample.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO Executor: Starting executor ID driver on host 192.168.8.166
		24/08/05 15:42:16 INFO Executor: OS info Mac OS X, 11.7.10, x86_64
		24/08/05 15:42:16 INFO Executor: Java version 17.0.12
		24/08/05 15:42:16 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
		24/08/05 15:42:16 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@26844abb for default.
		24/08/05 15:42:16 INFO Executor: Fetching spark://192.168.8.166:51992/jars/jackson-annotations-2.15.2.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO TransportClientFactory: Successfully created connection to /192.168.8.166:51992 after 37 ms (0 ms spent in bootstraps)
		24/08/05 15:42:16 INFO Utils: Fetching spark://192.168.8.166:51992/jars/jackson-annotations-2.15.2.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp14133621658300980722.tmp
		24/08/05 15:42:16 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/jackson-annotations-2.15.2.jar to class loader default
		24/08/05 15:42:16 INFO Executor: Fetching spark://192.168.8.166:51992/jars/scala-parser-combinators_2.12-2.3.0.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO Utils: Fetching spark://192.168.8.166:51992/jars/scala-parser-combinators_2.12-2.3.0.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp9373801545293740517.tmp
		24/08/05 15:42:16 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/scala-parser-combinators_2.12-2.3.0.jar to class loader default
		24/08/05 15:42:16 INFO Executor: Fetching spark://192.168.8.166:51992/jars/chill_2.12-0.10.0.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO Utils: Fetching spark://192.168.8.166:51992/jars/chill_2.12-0.10.0.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp11882574062382543136.tmp
		24/08/05 15:42:16 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/chill_2.12-0.10.0.jar to class loader default
		24/08/05 15:42:16 INFO Executor: Fetching spark://192.168.8.166:51992/jars/pickle-1.3.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO Utils: Fetching spark://192.168.8.166:51992/jars/pickle-1.3.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp3832945657495341014.tmp
		24/08/05 15:42:16 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/pickle-1.3.jar to class loader default
		24/08/05 15:42:16 INFO Executor: Fetching spark://192.168.8.166:51992/jars/arrow-vector-12.0.1.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO Utils: Fetching spark://192.168.8.166:51992/jars/arrow-vector-12.0.1.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp11896580503190539754.tmp
		24/08/05 15:42:16 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/arrow-vector-12.0.1.jar to class loader default
		24/08/05 15:42:16 INFO Executor: Fetching spark://192.168.8.166:51992/jars/jersey-container-servlet-core-2.40.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO Utils: Fetching spark://192.168.8.166:51992/jars/jersey-container-servlet-core-2.40.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp10670708197032363157.tmp
		24/08/05 15:42:16 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/jersey-container-servlet-core-2.40.jar to class loader default
		24/08/05 15:42:16 INFO Executor: Fetching spark://192.168.8.166:51992/jars/commons-crypto-1.1.0.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO Utils: Fetching spark://192.168.8.166:51992/jars/commons-crypto-1.1.0.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp6990232039361446955.tmp
		24/08/05 15:42:16 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/commons-crypto-1.1.0.jar to class loader default
		24/08/05 15:42:16 INFO Executor: Fetching spark://192.168.8.166:51992/jars/commons-compress-1.23.0.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO Utils: Fetching spark://192.168.8.166:51992/jars/commons-compress-1.23.0.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp16557395649182981446.tmp
		24/08/05 15:42:16 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/commons-compress-1.23.0.jar to class loader default
		24/08/05 15:42:16 INFO Executor: Fetching spark://192.168.8.166:51992/jars/RoaringBitmap-0.9.45.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO Utils: Fetching spark://192.168.8.166:51992/jars/RoaringBitmap-0.9.45.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp12472131600326189780.tmp
		24/08/05 15:42:16 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/RoaringBitmap-0.9.45.jar to class loader default
		24/08/05 15:42:16 INFO Executor: Fetching spark://192.168.8.166:51992/jars/parquet-hadoop-1.13.1.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO Utils: Fetching spark://192.168.8.166:51992/jars/parquet-hadoop-1.13.1.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp9769615647344342531.tmp
		24/08/05 15:42:16 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/parquet-hadoop-1.13.1.jar to class loader default
		24/08/05 15:42:16 INFO Executor: Fetching spark://192.168.8.166:51992/jars/objenesis-3.3.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO Utils: Fetching spark://192.168.8.166:51992/jars/objenesis-3.3.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp15668574590645350327.tmp
		24/08/05 15:42:16 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/objenesis-3.3.jar to class loader default
		24/08/05 15:42:16 INFO Executor: Fetching spark://192.168.8.166:51992/jars/spark-graphx_2.12-3.5.1.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO Utils: Fetching spark://192.168.8.166:51992/jars/spark-graphx_2.12-3.5.1.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp360513039914368470.tmp
		24/08/05 15:42:16 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/spark-graphx_2.12-3.5.1.jar to class loader default
		24/08/05 15:42:16 INFO Executor: Fetching spark://192.168.8.166:51992/jars/datasketches-memory-2.1.0.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO Utils: Fetching spark://192.168.8.166:51992/jars/datasketches-memory-2.1.0.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp15328139043925036425.tmp
		24/08/05 15:42:16 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/datasketches-memory-2.1.0.jar to class loader default
		24/08/05 15:42:16 INFO Executor: Fetching spark://192.168.8.166:51992/jars/JLargeArrays-1.5.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO Utils: Fetching spark://192.168.8.166:51992/jars/JLargeArrays-1.5.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp13233442062791516175.tmp
		24/08/05 15:42:16 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/JLargeArrays-1.5.jar to class loader default
		24/08/05 15:42:16 INFO Executor: Fetching spark://192.168.8.166:51992/jars/spark-network-common_2.12-3.5.1.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO Utils: Fetching spark://192.168.8.166:51992/jars/spark-network-common_2.12-3.5.1.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp10747445963632960338.tmp
		24/08/05 15:42:16 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/spark-network-common_2.12-3.5.1.jar to class loader default
		24/08/05 15:42:16 INFO Executor: Fetching spark://192.168.8.166:51992/jars/breeze-macros_2.12-2.1.0.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO Utils: Fetching spark://192.168.8.166:51992/jars/breeze-macros_2.12-2.1.0.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp11201184471708556289.tmp
		24/08/05 15:42:16 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/breeze-macros_2.12-2.1.0.jar to class loader default
		24/08/05 15:42:16 INFO Executor: Fetching spark://192.168.8.166:51992/jars/zookeeper-jute-3.6.3.jar with timestamp 1722865335909
		24/08/05 15:42:16 INFO Utils: Fetching spark://192.168.8.166:51992/jars/zookeeper-jute-3.6.3.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp5295365208276056887.tmp
		24/08/05 15:42:17 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/zookeeper-jute-3.6.3.jar to class loader default
		24/08/05 15:42:17 INFO Executor: Fetching spark://192.168.8.166:51992/jars/commons-text-1.10.0.jar with timestamp 1722865335909
		24/08/05 15:42:17 INFO Utils: Fetching spark://192.168.8.166:51992/jars/commons-text-1.10.0.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp16930783739677049206.tmp
		24/08/05 15:42:17 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/commons-text-1.10.0.jar to class loader default
		24/08/05 15:42:17 INFO Executor: Fetching spark://192.168.8.166:51992/jars/oro-2.0.8.jar with timestamp 1722865335909
		24/08/05 15:42:17 INFO Utils: Fetching spark://192.168.8.166:51992/jars/oro-2.0.8.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp8588604986207772448.tmp
		24/08/05 15:42:17 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/oro-2.0.8.jar to class loader default
		24/08/05 15:42:17 INFO Executor: Fetching spark://192.168.8.166:51992/jars/netty-all-4.1.96.Final.jar with timestamp 1722865335909
		24/08/05 15:42:17 INFO Utils: Fetching spark://192.168.8.166:51992/jars/netty-all-4.1.96.Final.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp10941236250467714066.tmp
		24/08/05 15:42:17 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/netty-all-4.1.96.Final.jar to class loader default
		24/08/05 15:42:17 INFO Executor: Fetching spark://192.168.8.166:51992/jars/json4s-jackson_2.12-3.7.0-M11.jar with timestamp 1722865335909
		24/08/05 15:42:17 INFO Utils: Fetching spark://192.168.8.166:51992/jars/json4s-jackson_2.12-3.7.0-M11.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp2121914775789401920.tmp
		24/08/05 15:42:17 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/json4s-jackson_2.12-3.7.0-M11.jar to class loader default
		24/08/05 15:42:17 INFO Executor: Fetching spark://192.168.8.166:51992/jars/JTransforms-3.1.jar with timestamp 1722865335909
		24/08/05 15:42:17 INFO Utils: Fetching spark://192.168.8.166:51992/jars/JTransforms-3.1.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp9927489319794780043.tmp
		24/08/05 15:42:17 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/JTransforms-3.1.jar to class loader default
		24/08/05 15:42:17 INFO Executor: Fetching spark://192.168.8.166:51992/jars/jackson-core-2.15.2.jar with timestamp 1722865335909
		24/08/05 15:42:17 INFO Utils: Fetching spark://192.168.8.166:51992/jars/jackson-core-2.15.2.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp1579705560490778371.tmp
		24/08/05 15:42:17 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/jackson-core-2.15.2.jar to class loader default
		24/08/05 15:42:17 INFO Executor: Fetching spark://192.168.8.166:51992/jars/commons-math3-3.6.1.jar with timestamp 1722865335909
		24/08/05 15:42:17 INFO Utils: Fetching spark://192.168.8.166:51992/jars/commons-math3-3.6.1.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp2469730773936054487.tmp
		24/08/05 15:42:17 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/commons-math3-3.6.1.jar to class loader default
		24/08/05 15:42:17 INFO Executor: Fetching spark://192.168.8.166:51992/jars/curator-recipes-2.13.0.jar with timestamp 1722865335909
		24/08/05 15:42:17 INFO Utils: Fetching spark://192.168.8.166:51992/jars/curator-recipes-2.13.0.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp6235247246952241543.tmp
		24/08/05 15:42:17 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/curator-recipes-2.13.0.jar to class loader default
		24/08/05 15:42:17 INFO Executor: Fetching spark://192.168.8.166:51992/jars/jakarta.xml.bind-api-2.3.2.jar with timestamp 1722865335909
		24/08/05 15:42:17 INFO Utils: Fetching spark://192.168.8.166:51992/jars/jakarta.xml.bind-api-2.3.2.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp7437911678730185825.tmp
		24/08/05 15:42:17 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/jakarta.xml.bind-api-2.3.2.jar to class loader default
		24/08/05 15:42:17 INFO Executor: Fetching spark://192.168.8.166:51992/jars/algebra_2.12-2.0.1.jar with timestamp 1722865335909
		24/08/05 15:42:17 INFO Utils: Fetching spark://192.168.8.166:51992/jars/algebra_2.12-2.0.1.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp3714785622277689307.tmp
		24/08/05 15:42:17 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/algebra_2.12-2.0.1.jar to class loader default
		24/08/05 15:42:17 INFO Executor: Fetching spark://192.168.8.166:51992/jars/log4j-1.2-api-2.20.0.jar with timestamp 1722865335909
		24/08/05 15:42:17 INFO Utils: Fetching spark://192.168.8.166:51992/jars/log4j-1.2-api-2.20.0.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp11812350813854638794.tmp
		24/08/05 15:42:17 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/log4j-1.2-api-2.20.0.jar to class loader default
		24/08/05 15:42:17 INFO Executor: Fetching spark://192.168.8.166:51992/jars/py4j-0.10.9.7.jar with timestamp 1722865335909
		24/08/05 15:42:17 INFO Utils: Fetching spark://192.168.8.166:51992/jars/py4j-0.10.9.7.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp3978016891604173825.tmp
		24/08/05 15:42:17 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/py4j-0.10.9.7.jar to class loader default
		24/08/05 15:42:17 INFO Executor: Fetching spark://192.168.8.166:51992/jars/jcl-over-slf4j-2.0.7.jar with timestamp 1722865335909
		24/08/05 15:42:17 INFO Utils: Fetching spark://192.168.8.166:51992/jars/jcl-over-slf4j-2.0.7.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp3590907625916972119.tmp
		24/08/05 15:42:17 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/jcl-over-slf4j-2.0.7.jar to class loader default
		24/08/05 15:42:17 INFO Executor: Fetching spark://192.168.8.166:51992/jars/commons-collections-3.2.2.jar with timestamp 1722865335909
		24/08/05 15:42:17 INFO Utils: Fetching spark://192.168.8.166:51992/jars/commons-collections-3.2.2.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp10480174200550849656.tmp
		24/08/05 15:42:17 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/commons-collections-3.2.2.jar to class loader default
		24/08/05 15:42:17 INFO Executor: Fetching spark://192.168.8.166:51992/jars/opencsv-2.3.jar with timestamp 1722865335909
		24/08/05 15:42:17 INFO Utils: Fetching spark://192.168.8.166:51992/jars/opencsv-2.3.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp16836904238761096535.tmp
		24/08/05 15:42:17 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/opencsv-2.3.jar to class loader default
		24/08/05 15:42:17 INFO Executor: Fetching spark://192.168.8.166:51992/jars/metrics-jvm-4.2.19.jar with timestamp 1722865335909
		24/08/05 15:42:17 INFO Utils: Fetching spark://192.168.8.166:51992/jars/metrics-jvm-4.2.19.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp17305591293534901398.tmp
		24/08/05 15:42:17 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/metrics-jvm-4.2.19.jar to class loader default
		24/08/05 15:42:17 INFO Executor: Fetching spark://192.168.8.166:51992/jars/osgi-resource-locator-1.0.3.jar with timestamp 1722865335909
		24/08/05 15:42:17 INFO Utils: Fetching spark://192.168.8.166:51992/jars/osgi-resource-locator-1.0.3.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp11658205795895177950.tmp
		24/08/05 15:42:17 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/osgi-resource-locator-1.0.3.jar to class loader default
		24/08/05 15:42:17 INFO Executor: Fetching spark://192.168.8.166:51992/jars/snappy-java-1.1.10.3.jar with timestamp 1722865335909
		24/08/05 15:42:17 INFO Utils: Fetching spark://192.168.8.166:51992/jars/snappy-java-1.1.10.3.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp13217485802532238371.tmp
		24/08/05 15:42:17 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/snappy-java-1.1.10.3.jar to class loader default
		24/08/05 15:42:17 INFO Executor: Fetching spark://192.168.8.166:51992/jars/hadoop-client-runtime-3.3.4.jar with timestamp 1722865335909
		24/08/05 15:42:17 INFO Utils: Fetching spark://192.168.8.166:51992/jars/hadoop-client-runtime-3.3.4.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp10128334405417829377.tmp
		24/08/05 15:42:17 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/hadoop-client-runtime-3.3.4.jar to class loader default
		24/08/05 15:42:17 INFO Executor: Fetching spark://192.168.8.166:51992/jars/parquet-column-1.13.1.jar with timestamp 1722865335909
		24/08/05 15:42:17 INFO Utils: Fetching spark://192.168.8.166:51992/jars/parquet-column-1.13.1.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp13007093010234229423.tmp
		24/08/05 15:42:17 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/parquet-column-1.13.1.jar to class loader default
		24/08/05 15:42:17 INFO Executor: Fetching spark://192.168.8.166:51992/jars/jersey-client-2.40.jar with timestamp 1722865335909
		24/08/05 15:42:17 INFO Utils: Fetching spark://192.168.8.166:51992/jars/jersey-client-2.40.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp2500943908289610604.tmp
		24/08/05 15:42:17 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/jersey-client-2.40.jar to class loader default
		24/08/05 15:42:17 INFO Executor: Fetching spark://192.168.8.166:51992/jars/spark-mllib_2.12-3.5.1.jar with timestamp 1722865335909
		24/08/05 15:42:17 INFO Utils: Fetching spark://192.168.8.166:51992/jars/spark-mllib_2.12-3.5.1.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp11717825604397832693.tmp
		24/08/05 15:42:17 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/spark-mllib_2.12-3.5.1.jar to class loader default
		24/08/05 15:42:17 INFO Executor: Fetching spark://192.168.8.166:51992/jars/jakarta.inject-2.6.1.jar with timestamp 1722865335909
		24/08/05 15:42:17 INFO Utils: Fetching spark://192.168.8.166:51992/jars/jakarta.inject-2.6.1.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp13953482093981405272.tmp
		24/08/05 15:42:17 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/jakarta.inject-2.6.1.jar to class loader default
		24/08/05 15:42:17 INFO Executor: Fetching spark://192.168.8.166:51992/jars/scala-reflect-2.12.18.jar with timestamp 1722865335909
		24/08/05 15:42:17 INFO Utils: Fetching spark://192.168.8.166:51992/jars/scala-reflect-2.12.18.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp3985366997787231664.tmp
		24/08/05 15:42:17 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/scala-reflect-2.12.18.jar to class loader default
		24/08/05 15:42:17 INFO Executor: Fetching spark://192.168.8.166:51992/jars/netty-transport-classes-epoll-4.1.96.Final.jar with timestamp 1722865335909
		24/08/05 15:42:17 INFO Utils: Fetching spark://192.168.8.166:51992/jars/netty-transport-classes-epoll-4.1.96.Final.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp17519807173081455278.tmp
		24/08/05 15:42:17 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/netty-transport-classes-epoll-4.1.96.Final.jar to class loader default
		24/08/05 15:42:17 INFO Executor: Fetching spark://192.168.8.166:51992/jars/spark-tags_2.12-3.5.1.jar with timestamp 1722865335909
		24/08/05 15:42:17 INFO Utils: Fetching spark://192.168.8.166:51992/jars/spark-tags_2.12-3.5.1.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp9984073655489984735.tmp
		24/08/05 15:42:17 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/spark-tags_2.12-3.5.1.jar to class loader default
		24/08/05 15:42:17 INFO Executor: Fetching spark://192.168.8.166:51992/jars/paranamer-2.8.jar with timestamp 1722865335909
		24/08/05 15:42:17 INFO Utils: Fetching spark://192.168.8.166:51992/jars/paranamer-2.8.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp16853904689362227569.tmp
		24/08/05 15:42:17 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/paranamer-2.8.jar to class loader default
		24/08/05 15:42:17 INFO Executor: Fetching spark://192.168.8.166:51992/jars/orc-mapreduce-1.9.2-shaded-protobuf.jar with timestamp 1722865335909
		24/08/05 15:42:17 INFO Utils: Fetching spark://192.168.8.166:51992/jars/orc-mapreduce-1.9.2-shaded-protobuf.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp466910779780730118.tmp
		24/08/05 15:42:17 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/orc-mapreduce-1.9.2-shaded-protobuf.jar to class loader default
		24/08/05 15:42:17 INFO Executor: Fetching spark://192.168.8.166:51992/jars/commons-io-2.13.0.jar with timestamp 1722865335909
		24/08/05 15:42:17 INFO Utils: Fetching spark://192.168.8.166:51992/jars/commons-io-2.13.0.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp10479398799084288213.tmp
		24/08/05 15:42:17 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/commons-io-2.13.0.jar to class loader default
		24/08/05 15:42:17 INFO Executor: Fetching spark://192.168.8.166:51992/jars/jersey-server-2.40.jar with timestamp 1722865335909
		24/08/05 15:42:17 INFO Utils: Fetching spark://192.168.8.166:51992/jars/jersey-server-2.40.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp8005639062949755044.tmp
		24/08/05 15:42:17 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/jersey-server-2.40.jar to class loader default
		24/08/05 15:42:17 INFO Executor: Fetching spark://192.168.8.166:51992/jars/hk2-utils-2.6.1.jar with timestamp 1722865335909
		24/08/05 15:42:17 INFO Utils: Fetching spark://192.168.8.166:51992/jars/hk2-utils-2.6.1.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp14306715291777869085.tmp
		24/08/05 15:42:17 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/hk2-utils-2.6.1.jar to class loader default
		24/08/05 15:42:17 INFO Executor: Fetching spark://192.168.8.166:51992/jars/spark-mllib-local_2.12-3.5.1.jar with timestamp 1722865335909
		24/08/05 15:42:17 INFO Utils: Fetching spark://192.168.8.166:51992/jars/spark-mllib-local_2.12-3.5.1.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp15143517353411012150.tmp
		24/08/05 15:42:17 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/spark-mllib-local_2.12-3.5.1.jar to class loader default
		24/08/05 15:42:17 INFO Executor: Fetching spark://192.168.8.166:51992/jars/jsr305-3.0.0.jar with timestamp 1722865335909
		24/08/05 15:42:17 INFO Utils: Fetching spark://192.168.8.166:51992/jars/jsr305-3.0.0.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp146488834056447096.tmp
		24/08/05 15:42:17 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/jsr305-3.0.0.jar to class loader default
		24/08/05 15:42:17 INFO Executor: Fetching spark://192.168.8.166:51992/jars/jakarta.servlet-api-4.0.3.jar with timestamp 1722865335909
		24/08/05 15:42:17 INFO Utils: Fetching spark://192.168.8.166:51992/jars/jakarta.servlet-api-4.0.3.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp3384372416488172416.tmp
		24/08/05 15:42:17 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/jakarta.servlet-api-4.0.3.jar to class loader default
		24/08/05 15:42:17 INFO Executor: Fetching spark://192.168.8.166:51992/jars/parquet-common-1.13.1.jar with timestamp 1722865335909
		24/08/05 15:42:17 INFO Utils: Fetching spark://192.168.8.166:51992/jars/parquet-common-1.13.1.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp1056285001410116922.tmp
		24/08/05 15:42:17 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/parquet-common-1.13.1.jar to class loader default
		24/08/05 15:42:17 INFO Executor: Fetching spark://192.168.8.166:51992/jars/spark-kvstore_2.12-3.5.1.jar with timestamp 1722865335909
		24/08/05 15:42:17 INFO Utils: Fetching spark://192.168.8.166:51992/jars/spark-kvstore_2.12-3.5.1.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp6895110894999089218.tmp
		24/08/05 15:42:17 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/spark-kvstore_2.12-3.5.1.jar to class loader default
		24/08/05 15:42:17 INFO Executor: Fetching spark://192.168.8.166:51992/jars/scala-library-2.12.18.jar with timestamp 1722865335909
		24/08/05 15:42:17 INFO Utils: Fetching spark://192.168.8.166:51992/jars/scala-library-2.12.18.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp2723344138757163156.tmp
		24/08/05 15:42:17 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/scala-library-2.12.18.jar to class loader default
		24/08/05 15:42:17 INFO Executor: Fetching spark://192.168.8.166:51992/jars/audience-annotations-0.5.0.jar with timestamp 1722865335909
		24/08/05 15:42:17 INFO Utils: Fetching spark://192.168.8.166:51992/jars/audience-annotations-0.5.0.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp1494894425017492870.tmp
		24/08/05 15:42:17 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/audience-annotations-0.5.0.jar to class loader default
		24/08/05 15:42:17 INFO Executor: Fetching spark://192.168.8.166:51992/jars/avro-ipc-1.11.2.jar with timestamp 1722865335909
		24/08/05 15:42:17 INFO Utils: Fetching spark://192.168.8.166:51992/jars/avro-ipc-1.11.2.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp14569774619493227554.tmp
		24/08/05 15:42:17 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/avro-ipc-1.11.2.jar to class loader default
		24/08/05 15:42:17 INFO Executor: Fetching spark://192.168.8.166:51992/jars/spark-repl_2.12-3.5.1.jar with timestamp 1722865335909
		24/08/05 15:42:17 INFO Utils: Fetching spark://192.168.8.166:51992/jars/spark-repl_2.12-3.5.1.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp805941320069170954.tmp
		24/08/05 15:42:17 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/spark-repl_2.12-3.5.1.jar to class loader default
		24/08/05 15:42:17 INFO Executor: Fetching spark://192.168.8.166:51992/jars/zstd-jni-1.5.5-4.jar with timestamp 1722865335909
		24/08/05 15:42:17 INFO Utils: Fetching spark://192.168.8.166:51992/jars/zstd-jni-1.5.5-4.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp8546552520001717767.tmp
		24/08/05 15:42:17 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/zstd-jni-1.5.5-4.jar to class loader default
		24/08/05 15:42:17 INFO Executor: Fetching spark://192.168.8.166:51992/jars/hive-storage-api-2.8.1.jar with timestamp 1722865335909
		24/08/05 15:42:17 INFO Utils: Fetching spark://192.168.8.166:51992/jars/hive-storage-api-2.8.1.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp6945549738150152002.tmp
		24/08/05 15:42:17 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/hive-storage-api-2.8.1.jar to class loader default
		24/08/05 15:42:17 INFO Executor: Fetching spark://192.168.8.166:51992/jars/spire-util_2.12-0.17.0.jar with timestamp 1722865335909
		24/08/05 15:42:17 INFO Utils: Fetching spark://192.168.8.166:51992/jars/spire-util_2.12-0.17.0.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp14065940451279368145.tmp
		24/08/05 15:42:17 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/spire-util_2.12-0.17.0.jar to class loader default
		24/08/05 15:42:17 INFO Executor: Fetching spark://192.168.8.166:51992/jars/tink-1.9.0.jar with timestamp 1722865335909
		24/08/05 15:42:17 INFO Utils: Fetching spark://192.168.8.166:51992/jars/tink-1.9.0.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp13571388870897747799.tmp
		24/08/05 15:42:17 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/tink-1.9.0.jar to class loader default
		24/08/05 15:42:17 INFO Executor: Fetching spark://192.168.8.166:51992/jars/jul-to-slf4j-2.0.7.jar with timestamp 1722865335909
		24/08/05 15:42:17 INFO Utils: Fetching spark://192.168.8.166:51992/jars/jul-to-slf4j-2.0.7.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp2508775187136058960.tmp
		24/08/05 15:42:17 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/jul-to-slf4j-2.0.7.jar to class loader default
		24/08/05 15:42:17 INFO Executor: Fetching spark://192.168.8.166:51992/jars/netty-codec-http2-4.1.96.Final.jar with timestamp 1722865335909
		24/08/05 15:42:17 INFO Utils: Fetching spark://192.168.8.166:51992/jars/netty-codec-http2-4.1.96.Final.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp1291757231412932914.tmp
		24/08/05 15:42:17 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/netty-codec-http2-4.1.96.Final.jar to class loader default
		24/08/05 15:42:17 INFO Executor: Fetching spark://192.168.8.166:51992/jars/ivy-2.5.1.jar with timestamp 1722865335909
		24/08/05 15:42:17 INFO Utils: Fetching spark://192.168.8.166:51992/jars/ivy-2.5.1.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp9323138395828377506.tmp
		24/08/05 15:42:17 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/ivy-2.5.1.jar to class loader default
		24/08/05 15:42:17 INFO Executor: Fetching spark://192.168.8.166:51992/jars/jersey-container-servlet-2.40.jar with timestamp 1722865335909
		24/08/05 15:42:17 INFO Utils: Fetching spark://192.168.8.166:51992/jars/jersey-container-servlet-2.40.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp85092741669178384.tmp
		24/08/05 15:42:17 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/jersey-container-servlet-2.40.jar to class loader default
		24/08/05 15:42:17 INFO Executor: Fetching spark://192.168.8.166:51992/jars/hk2-locator-2.6.1.jar with timestamp 1722865335909
		24/08/05 15:42:17 INFO Utils: Fetching spark://192.168.8.166:51992/jars/hk2-locator-2.6.1.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp1046714441446010495.tmp
		24/08/05 15:42:17 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/hk2-locator-2.6.1.jar to class loader default
		24/08/05 15:42:17 INFO Executor: Fetching spark://192.168.8.166:51992/jars/blas-3.0.3.jar with timestamp 1722865335909
		24/08/05 15:42:17 INFO Utils: Fetching spark://192.168.8.166:51992/jars/blas-3.0.3.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp855205083129677401.tmp
		24/08/05 15:42:17 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/blas-3.0.3.jar to class loader default
		24/08/05 15:42:17 INFO Executor: Fetching spark://192.168.8.166:51992/jars/json4s-ast_2.12-3.7.0-M11.jar with timestamp 1722865335909
		24/08/05 15:42:17 INFO Utils: Fetching spark://192.168.8.166:51992/jars/json4s-ast_2.12-3.7.0-M11.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp473816301589235007.tmp
		24/08/05 15:42:17 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/json4s-ast_2.12-3.7.0-M11.jar to class loader default
		24/08/05 15:42:17 INFO Executor: Fetching spark://192.168.8.166:51992/jars/commons-compiler-3.1.9.jar with timestamp 1722865335909
		24/08/05 15:42:17 INFO Utils: Fetching spark://192.168.8.166:51992/jars/commons-compiler-3.1.9.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp7400427001106133184.tmp
		24/08/05 15:42:17 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/commons-compiler-3.1.9.jar to class loader default
		24/08/05 15:42:17 INFO Executor: Fetching spark://192.168.8.166:51992/jars/leveldbjni-all-1.8.jar with timestamp 1722865335909
		24/08/05 15:42:17 INFO Utils: Fetching spark://192.168.8.166:51992/jars/leveldbjni-all-1.8.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp6379464990048533932.tmp
		24/08/05 15:42:17 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/leveldbjni-all-1.8.jar to class loader default
		24/08/05 15:42:17 INFO Executor: Fetching spark://192.168.8.166:51992/jars/netty-codec-4.1.96.Final.jar with timestamp 1722865335909
		24/08/05 15:42:17 INFO Utils: Fetching spark://192.168.8.166:51992/jars/netty-codec-4.1.96.Final.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp17278180723237332072.tmp
		24/08/05 15:42:17 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/netty-codec-4.1.96.Final.jar to class loader default
		24/08/05 15:42:17 INFO Executor: Fetching spark://192.168.8.166:51992/jars/annotations-17.0.0.jar with timestamp 1722865335909
		24/08/05 15:42:17 INFO Utils: Fetching spark://192.168.8.166:51992/jars/annotations-17.0.0.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp14841393226571380728.tmp
		24/08/05 15:42:17 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/annotations-17.0.0.jar to class loader default
		24/08/05 15:42:17 INFO Executor: Fetching spark://192.168.8.166:51992/jars/univocity-parsers-2.9.1.jar with timestamp 1722865335909
		24/08/05 15:42:17 INFO Utils: Fetching spark://192.168.8.166:51992/jars/univocity-parsers-2.9.1.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp228110630091872208.tmp
		24/08/05 15:42:17 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/univocity-parsers-2.9.1.jar to class loader default
		24/08/05 15:42:17 INFO Executor: Fetching spark://192.168.8.166:51992/jars/janino-3.1.9.jar with timestamp 1722865335909
		24/08/05 15:42:17 INFO Utils: Fetching spark://192.168.8.166:51992/jars/janino-3.1.9.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp3226074882784622730.tmp
		24/08/05 15:42:17 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/janino-3.1.9.jar to class loader default
		24/08/05 15:42:17 INFO Executor: Fetching spark://192.168.8.166:51992/jars/spark-catalyst_2.12-3.5.1.jar with timestamp 1722865335909
		24/08/05 15:42:17 INFO Utils: Fetching spark://192.168.8.166:51992/jars/spark-catalyst_2.12-3.5.1.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp7796550738093768055.tmp
		24/08/05 15:42:17 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/spark-catalyst_2.12-3.5.1.jar to class loader default
		24/08/05 15:42:17 INFO Executor: Fetching spark://192.168.8.166:51992/jars/metrics-graphite-4.2.19.jar with timestamp 1722865335909
		24/08/05 15:42:17 INFO Utils: Fetching spark://192.168.8.166:51992/jars/metrics-graphite-4.2.19.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp1763767154778799446.tmp
		24/08/05 15:42:17 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/metrics-graphite-4.2.19.jar to class loader default
		24/08/05 15:42:17 INFO Executor: Fetching spark://192.168.8.166:51992/jars/kryo-shaded-4.0.2.jar with timestamp 1722865335909
		24/08/05 15:42:17 INFO Utils: Fetching spark://192.168.8.166:51992/jars/kryo-shaded-4.0.2.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp9444654726931063038.tmp
		24/08/05 15:42:17 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/kryo-shaded-4.0.2.jar to class loader default
		24/08/05 15:42:17 INFO Executor: Fetching spark://192.168.8.166:51992/jars/netty-common-4.1.96.Final.jar with timestamp 1722865335909
		24/08/05 15:42:17 INFO Utils: Fetching spark://192.168.8.166:51992/jars/netty-common-4.1.96.Final.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp14178592896649903480.tmp
		24/08/05 15:42:17 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/netty-common-4.1.96.Final.jar to class loader default
		24/08/05 15:42:17 INFO Executor: Fetching spark://192.168.8.166:51992/jars/spark-network-shuffle_2.12-3.5.1.jar with timestamp 1722865335909
		24/08/05 15:42:17 INFO Utils: Fetching spark://192.168.8.166:51992/jars/spark-network-shuffle_2.12-3.5.1.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp7912944115254181292.tmp
		24/08/05 15:42:17 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/spark-network-shuffle_2.12-3.5.1.jar to class loader default
		24/08/05 15:42:17 INFO Executor: Fetching spark://192.168.8.166:51992/jars/scala-compiler-2.12.18.jar with timestamp 1722865335909
		24/08/05 15:42:17 INFO Utils: Fetching spark://192.168.8.166:51992/jars/scala-compiler-2.12.18.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp17866274931482379794.tmp
		24/08/05 15:42:17 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/scala-compiler-2.12.18.jar to class loader default
		24/08/05 15:42:17 INFO Executor: Fetching spark://192.168.8.166:51992/jars/jakarta.ws.rs-api-2.1.6.jar with timestamp 1722865335909
		24/08/05 15:42:17 INFO Utils: Fetching spark://192.168.8.166:51992/jars/jakarta.ws.rs-api-2.1.6.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp3357542814753054213.tmp
		24/08/05 15:42:17 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/jakarta.ws.rs-api-2.1.6.jar to class loader default
		24/08/05 15:42:17 INFO Executor: Fetching spark://192.168.8.166:51992/jars/shims-0.9.45.jar with timestamp 1722865335909
		24/08/05 15:42:17 INFO Utils: Fetching spark://192.168.8.166:51992/jars/shims-0.9.45.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp15134224928754241181.tmp
		24/08/05 15:42:17 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/shims-0.9.45.jar to class loader default
		24/08/05 15:42:17 INFO Executor: Fetching spark://192.168.8.166:51992/jars/jersey-common-2.40.jar with timestamp 1722865335909
		24/08/05 15:42:17 INFO Utils: Fetching spark://192.168.8.166:51992/jars/jersey-common-2.40.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp2384876077753928760.tmp
		24/08/05 15:42:17 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/jersey-common-2.40.jar to class loader default
		24/08/05 15:42:17 INFO Executor: Fetching spark://192.168.8.166:51992/jars/log4j-core-2.20.0.jar with timestamp 1722865335909
		24/08/05 15:42:17 INFO Utils: Fetching spark://192.168.8.166:51992/jars/log4j-core-2.20.0.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp3251093507533198799.tmp
		24/08/05 15:42:17 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/log4j-core-2.20.0.jar to class loader default
		24/08/05 15:42:17 INFO Executor: Fetching spark://192.168.8.166:51992/jars/netty-transport-native-kqueue-4.1.96.Final-osx-x86_64.jar with timestamp 1722865335909
		24/08/05 15:42:17 INFO Utils: Fetching spark://192.168.8.166:51992/jars/netty-transport-native-kqueue-4.1.96.Final-osx-x86_64.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp3087489034538847517.tmp
		24/08/05 15:42:17 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/netty-transport-native-kqueue-4.1.96.Final-osx-x86_64.jar to class loader default
		24/08/05 15:42:17 INFO Executor: Fetching spark://192.168.8.166:51992/jars/guava-14.0.1.jar with timestamp 1722865335909
		24/08/05 15:42:17 INFO Utils: Fetching spark://192.168.8.166:51992/jars/guava-14.0.1.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp12533058384588880298.tmp
		24/08/05 15:42:17 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/guava-14.0.1.jar to class loader default
		24/08/05 15:42:17 INFO Executor: Fetching spark://192.168.8.166:51992/jars/netty-transport-classes-kqueue-4.1.96.Final.jar with timestamp 1722865335909
		24/08/05 15:42:17 INFO Utils: Fetching spark://192.168.8.166:51992/jars/netty-transport-classes-kqueue-4.1.96.Final.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp3027997073474999937.tmp
		24/08/05 15:42:17 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/netty-transport-classes-kqueue-4.1.96.Final.jar to class loader default
		24/08/05 15:42:17 INFO Executor: Fetching spark://192.168.8.166:51992/jars/commons-lang3-3.12.0.jar with timestamp 1722865335909
		24/08/05 15:42:17 INFO Utils: Fetching spark://192.168.8.166:51992/jars/commons-lang3-3.12.0.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp13835577167036326060.tmp
		24/08/05 15:42:17 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/commons-lang3-3.12.0.jar to class loader default
		24/08/05 15:42:17 INFO Executor: Fetching spark://192.168.8.166:51992/jars/scala-xml_2.12-2.1.0.jar with timestamp 1722865335909
		24/08/05 15:42:17 INFO Utils: Fetching spark://192.168.8.166:51992/jars/scala-xml_2.12-2.1.0.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp4161873624981163738.tmp
		24/08/05 15:42:17 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/scala-xml_2.12-2.1.0.jar to class loader default
		24/08/05 15:42:17 INFO Executor: Fetching spark://192.168.8.166:51992/jars/scala-collection-compat_2.12-2.7.0.jar with timestamp 1722865335909
		24/08/05 15:42:17 INFO Utils: Fetching spark://192.168.8.166:51992/jars/scala-collection-compat_2.12-2.7.0.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp6251839509267100060.tmp
		24/08/05 15:42:18 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/scala-collection-compat_2.12-2.7.0.jar to class loader default
		24/08/05 15:42:18 INFO Executor: Fetching spark://192.168.8.166:51992/jars/lz4-java-1.8.0.jar with timestamp 1722865335909
		24/08/05 15:42:18 INFO Utils: Fetching spark://192.168.8.166:51992/jars/lz4-java-1.8.0.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp2024615495524210223.tmp
		24/08/05 15:42:18 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/lz4-java-1.8.0.jar to class loader default
		24/08/05 15:42:18 INFO Executor: Fetching spark://192.168.8.166:51992/jars/spark-launcher_2.12-3.5.1.jar with timestamp 1722865335909
		24/08/05 15:42:18 INFO Utils: Fetching spark://192.168.8.166:51992/jars/spark-launcher_2.12-3.5.1.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp18226781353015978652.tmp
		24/08/05 15:42:18 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/spark-launcher_2.12-3.5.1.jar to class loader default
		24/08/05 15:42:18 INFO Executor: Fetching spark://192.168.8.166:51992/jars/netty-handler-proxy-4.1.96.Final.jar with timestamp 1722865335909
		24/08/05 15:42:18 INFO Utils: Fetching spark://192.168.8.166:51992/jars/netty-handler-proxy-4.1.96.Final.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp7157086142728196834.tmp
		24/08/05 15:42:18 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/netty-handler-proxy-4.1.96.Final.jar to class loader default
		24/08/05 15:42:18 INFO Executor: Fetching spark://192.168.8.166:51992/jars/hadoop-client-api-3.3.4.jar with timestamp 1722865335909
		24/08/05 15:42:18 INFO Utils: Fetching spark://192.168.8.166:51992/jars/hadoop-client-api-3.3.4.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp18197177718425465478.tmp
		24/08/05 15:42:18 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/hadoop-client-api-3.3.4.jar to class loader default
		24/08/05 15:42:18 INFO Executor: Fetching spark://192.168.8.166:51992/jars/netty-transport-native-epoll-4.1.96.Final-linux-x86_64.jar with timestamp 1722865335909
		24/08/05 15:42:18 INFO Utils: Fetching spark://192.168.8.166:51992/jars/netty-transport-native-epoll-4.1.96.Final-linux-x86_64.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp8006063673746574341.tmp
		24/08/05 15:42:18 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/netty-transport-native-epoll-4.1.96.Final-linux-x86_64.jar to class loader default
		24/08/05 15:42:18 INFO Executor: Fetching spark://192.168.8.166:51992/jars/netty-transport-4.1.96.Final.jar with timestamp 1722865335909
		24/08/05 15:42:18 INFO Utils: Fetching spark://192.168.8.166:51992/jars/netty-transport-4.1.96.Final.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp10998608667014216003.tmp
		24/08/05 15:42:18 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/netty-transport-4.1.96.Final.jar to class loader default
		24/08/05 15:42:18 INFO Executor: Fetching spark://192.168.8.166:51992/jars/orc-core-1.9.2-shaded-protobuf.jar with timestamp 1722865335909
		24/08/05 15:42:18 INFO Utils: Fetching spark://192.168.8.166:51992/jars/orc-core-1.9.2-shaded-protobuf.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp2147431593395904492.tmp
		24/08/05 15:42:18 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/orc-core-1.9.2-shaded-protobuf.jar to class loader default
		24/08/05 15:42:18 INFO Executor: Fetching spark://192.168.8.166:51992/jars/chill-java-0.10.0.jar with timestamp 1722865335909
		24/08/05 15:42:18 INFO Utils: Fetching spark://192.168.8.166:51992/jars/chill-java-0.10.0.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp14696579692149501051.tmp
		24/08/05 15:42:18 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/chill-java-0.10.0.jar to class loader default
		24/08/05 15:42:18 INFO Executor: Fetching spark://192.168.8.166:51992/jars/netty-codec-http-4.1.96.Final.jar with timestamp 1722865335909
		24/08/05 15:42:18 INFO Utils: Fetching spark://192.168.8.166:51992/jars/netty-codec-http-4.1.96.Final.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp4564010566118501706.tmp
		24/08/05 15:42:18 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/netty-codec-http-4.1.96.Final.jar to class loader default
		24/08/05 15:42:18 INFO Executor: Fetching spark://192.168.8.166:51992/jars/commons-codec-1.16.0.jar with timestamp 1722865335909
		24/08/05 15:42:18 INFO Utils: Fetching spark://192.168.8.166:51992/jars/commons-codec-1.16.0.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp2398347380005834988.tmp
		24/08/05 15:42:18 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/commons-codec-1.16.0.jar to class loader default
		24/08/05 15:42:18 INFO Executor: Fetching spark://192.168.8.166:51992/jars/antlr4-runtime-4.9.3.jar with timestamp 1722865335909
		24/08/05 15:42:18 INFO Utils: Fetching spark://192.168.8.166:51992/jars/antlr4-runtime-4.9.3.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp10661083785072699042.tmp
		24/08/05 15:42:18 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/antlr4-runtime-4.9.3.jar to class loader default
		24/08/05 15:42:18 INFO Executor: Fetching spark://192.168.8.166:51992/jars/json4s-core_2.12-3.7.0-M11.jar with timestamp 1722865335909
		24/08/05 15:42:18 INFO Utils: Fetching spark://192.168.8.166:51992/jars/json4s-core_2.12-3.7.0-M11.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp9247068252716101292.tmp
		24/08/05 15:42:18 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/json4s-core_2.12-3.7.0-M11.jar to class loader default
		24/08/05 15:42:18 INFO Executor: Fetching spark://192.168.8.166:51992/jars/spark-sql-api_2.12-3.5.1.jar with timestamp 1722865335909
		24/08/05 15:42:18 INFO Utils: Fetching spark://192.168.8.166:51992/jars/spark-sql-api_2.12-3.5.1.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp594644889784112316.tmp
		24/08/05 15:42:18 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/spark-sql-api_2.12-3.5.1.jar to class loader default
		24/08/05 15:42:18 INFO Executor: Fetching spark://192.168.8.166:51992/jars/aircompressor-0.26.jar with timestamp 1722865335909
		24/08/05 15:42:18 INFO Utils: Fetching spark://192.168.8.166:51992/jars/aircompressor-0.26.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp16877329431429609203.tmp
		24/08/05 15:42:18 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/aircompressor-0.26.jar to class loader default
		24/08/05 15:42:18 INFO Executor: Fetching spark://192.168.8.166:51992/jars/arrow-format-12.0.1.jar with timestamp 1722865335909
		24/08/05 15:42:18 INFO Utils: Fetching spark://192.168.8.166:51992/jars/arrow-format-12.0.1.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp18126054389766158065.tmp
		24/08/05 15:42:18 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/arrow-format-12.0.1.jar to class loader default
		24/08/05 15:42:18 INFO Executor: Fetching spark://192.168.8.166:51992/jars/flatbuffers-java-1.12.0.jar with timestamp 1722865335909
		24/08/05 15:42:18 INFO Utils: Fetching spark://192.168.8.166:51992/jars/flatbuffers-java-1.12.0.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp4069565251626316695.tmp
		24/08/05 15:42:18 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/flatbuffers-java-1.12.0.jar to class loader default
		24/08/05 15:42:18 INFO Executor: Fetching spark://192.168.8.166:51992/jars/spire-macros_2.12-0.17.0.jar with timestamp 1722865335909
		24/08/05 15:42:18 INFO Utils: Fetching spark://192.168.8.166:51992/jars/spire-macros_2.12-0.17.0.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp8437470583082472262.tmp
		24/08/05 15:42:18 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/spire-macros_2.12-0.17.0.jar to class loader default
		24/08/05 15:42:18 INFO Executor: Fetching spark://192.168.8.166:51992/jars/xbean-asm9-shaded-4.23.jar with timestamp 1722865335909
		24/08/05 15:42:18 INFO Utils: Fetching spark://192.168.8.166:51992/jars/xbean-asm9-shaded-4.23.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp2022823484874725174.tmp
		24/08/05 15:42:18 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/xbean-asm9-shaded-4.23.jar to class loader default
		24/08/05 15:42:18 INFO Executor: Fetching spark://192.168.8.166:51992/jars/spark-streaming_2.12-3.5.1.jar with timestamp 1722865335909
		24/08/05 15:42:18 INFO Utils: Fetching spark://192.168.8.166:51992/jars/spark-streaming_2.12-3.5.1.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp4191921783214245571.tmp
		24/08/05 15:42:18 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/spark-streaming_2.12-3.5.1.jar to class loader default
		24/08/05 15:42:18 INFO Executor: Fetching spark://192.168.8.166:51992/jars/spark-sql_2.12-3.5.1.jar with timestamp 1722865335909
		24/08/05 15:42:18 INFO Utils: Fetching spark://192.168.8.166:51992/jars/spark-sql_2.12-3.5.1.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp18013725964816709237.tmp
		24/08/05 15:42:18 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/spark-sql_2.12-3.5.1.jar to class loader default
		24/08/05 15:42:18 INFO Executor: Fetching spark://192.168.8.166:51992/jars/metrics-core-4.2.19.jar with timestamp 1722865335909
		24/08/05 15:42:18 INFO Utils: Fetching spark://192.168.8.166:51992/jars/metrics-core-4.2.19.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp2931504402559131820.tmp
		24/08/05 15:42:18 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/metrics-core-4.2.19.jar to class loader default
		24/08/05 15:42:18 INFO Executor: Fetching spark://192.168.8.166:51992/jars/minlog-1.3.0.jar with timestamp 1722865335909
		24/08/05 15:42:18 INFO Utils: Fetching spark://192.168.8.166:51992/jars/minlog-1.3.0.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp9887958678102569770.tmp
		24/08/05 15:42:18 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/minlog-1.3.0.jar to class loader default
		24/08/05 15:42:18 INFO Executor: Fetching spark://192.168.8.166:51992/jars/gson-2.10.1.jar with timestamp 1722865335909
		24/08/05 15:42:18 INFO Utils: Fetching spark://192.168.8.166:51992/jars/gson-2.10.1.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp2264532018183695426.tmp
		24/08/05 15:42:18 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/gson-2.10.1.jar to class loader default
		24/08/05 15:42:18 INFO Executor: Fetching spark://192.168.8.166:51992/jars/arpack-3.0.3.jar with timestamp 1722865335909
		24/08/05 15:42:18 INFO Utils: Fetching spark://192.168.8.166:51992/jars/arpack-3.0.3.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp11747322070100250150.tmp
		24/08/05 15:42:18 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/arpack-3.0.3.jar to class loader default
		24/08/05 15:42:18 INFO Executor: Fetching spark://192.168.8.166:51992/jars/activation-1.1.1.jar with timestamp 1722865335909
		24/08/05 15:42:18 INFO Utils: Fetching spark://192.168.8.166:51992/jars/activation-1.1.1.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp15305845601879482780.tmp
		24/08/05 15:42:18 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/activation-1.1.1.jar to class loader default
		24/08/05 15:42:18 INFO Executor: Fetching spark://192.168.8.166:51992/jars/commons-logging-1.1.3.jar with timestamp 1722865335909
		24/08/05 15:42:18 INFO Utils: Fetching spark://192.168.8.166:51992/jars/commons-logging-1.1.3.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp17827255395532008945.tmp
		24/08/05 15:42:18 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/commons-logging-1.1.3.jar to class loader default
		24/08/05 15:42:18 INFO Executor: Fetching spark://192.168.8.166:51992/jars/javassist-3.29.2-GA.jar with timestamp 1722865335909
		24/08/05 15:42:18 INFO Utils: Fetching spark://192.168.8.166:51992/jars/javassist-3.29.2-GA.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp16971621314884461828.tmp
		24/08/05 15:42:18 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/javassist-3.29.2-GA.jar to class loader default
		24/08/05 15:42:18 INFO Executor: Fetching spark://192.168.8.166:51992/jars/jackson-databind-2.15.2.jar with timestamp 1722865335909
		24/08/05 15:42:18 INFO Utils: Fetching spark://192.168.8.166:51992/jars/jackson-databind-2.15.2.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp4052883760322418672.tmp
		24/08/05 15:42:18 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/jackson-databind-2.15.2.jar to class loader default
		24/08/05 15:42:18 INFO Executor: Fetching spark://192.168.8.166:51992/jars/metrics-jmx-4.2.19.jar with timestamp 1722865335909
		24/08/05 15:42:18 INFO Utils: Fetching spark://192.168.8.166:51992/jars/metrics-jmx-4.2.19.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp6199358854685727399.tmp
		24/08/05 15:42:18 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/metrics-jmx-4.2.19.jar to class loader default
		24/08/05 15:42:18 INFO Executor: Fetching spark://192.168.8.166:51992/jars/log4j-api-2.20.0.jar with timestamp 1722865335909
		24/08/05 15:42:18 INFO Utils: Fetching spark://192.168.8.166:51992/jars/log4j-api-2.20.0.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp460973257845271942.tmp
		24/08/05 15:42:18 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/log4j-api-2.20.0.jar to class loader default
		24/08/05 15:42:18 INFO Executor: Fetching spark://192.168.8.166:51992/jars/arrow-memory-netty-12.0.1.jar with timestamp 1722865335909
		24/08/05 15:42:18 INFO Utils: Fetching spark://192.168.8.166:51992/jars/arrow-memory-netty-12.0.1.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp9762619152277872918.tmp
		24/08/05 15:42:18 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/arrow-memory-netty-12.0.1.jar to class loader default
		24/08/05 15:42:18 INFO Executor: Fetching spark://192.168.8.166:51992/jars/spark-core_2.12-3.5.1.jar with timestamp 1722865335909
		24/08/05 15:42:18 INFO Utils: Fetching spark://192.168.8.166:51992/jars/spark-core_2.12-3.5.1.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp966822458130405171.tmp
		24/08/05 15:42:18 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/spark-core_2.12-3.5.1.jar to class loader default
		24/08/05 15:42:18 INFO Executor: Fetching spark://192.168.8.166:51992/jars/netty-codec-socks-4.1.96.Final.jar with timestamp 1722865335909
		24/08/05 15:42:18 INFO Utils: Fetching spark://192.168.8.166:51992/jars/netty-codec-socks-4.1.96.Final.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp7792814147818288269.tmp
		24/08/05 15:42:18 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/netty-codec-socks-4.1.96.Final.jar to class loader default
		24/08/05 15:42:18 INFO Executor: Fetching spark://192.168.8.166:51992/jars/metrics-json-4.2.19.jar with timestamp 1722865335909
		24/08/05 15:42:18 INFO Utils: Fetching spark://192.168.8.166:51992/jars/metrics-json-4.2.19.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp3786084848787614791.tmp
		24/08/05 15:42:18 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/metrics-json-4.2.19.jar to class loader default
		24/08/05 15:42:18 INFO Executor: Fetching spark://192.168.8.166:51992/jars/spark-unsafe_2.12-3.5.1.jar with timestamp 1722865335909
		24/08/05 15:42:18 INFO Utils: Fetching spark://192.168.8.166:51992/jars/spark-unsafe_2.12-3.5.1.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp12020923660161457283.tmp
		24/08/05 15:42:18 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/spark-unsafe_2.12-3.5.1.jar to class loader default
		24/08/05 15:42:18 INFO Executor: Fetching spark://192.168.8.166:51992/jars/spark-common-utils_2.12-3.5.1.jar with timestamp 1722865335909
		24/08/05 15:42:18 INFO Utils: Fetching spark://192.168.8.166:51992/jars/spark-common-utils_2.12-3.5.1.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp9056018402172062784.tmp
		24/08/05 15:42:18 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/spark-common-utils_2.12-3.5.1.jar to class loader default
		24/08/05 15:42:18 INFO Executor: Fetching spark://192.168.8.166:51992/jars/curator-client-2.13.0.jar with timestamp 1722865335909
		24/08/05 15:42:18 INFO Utils: Fetching spark://192.168.8.166:51992/jars/curator-client-2.13.0.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp14261368317987105061.tmp
		24/08/05 15:42:18 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/curator-client-2.13.0.jar to class loader default
		24/08/05 15:42:18 INFO Executor: Fetching spark://192.168.8.166:51992/jars/parquet-encoding-1.13.1.jar with timestamp 1722865335909
		24/08/05 15:42:18 INFO Utils: Fetching spark://192.168.8.166:51992/jars/parquet-encoding-1.13.1.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp10746341467909696725.tmp
		24/08/05 15:42:18 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/parquet-encoding-1.13.1.jar to class loader default
		24/08/05 15:42:18 INFO Executor: Fetching spark://192.168.8.166:51992/jars/netty-handler-4.1.96.Final.jar with timestamp 1722865335909
		24/08/05 15:42:18 INFO Utils: Fetching spark://192.168.8.166:51992/jars/netty-handler-4.1.96.Final.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp710907283875371045.tmp
		24/08/05 15:42:18 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/netty-handler-4.1.96.Final.jar to class loader default
		24/08/05 15:42:18 INFO Executor: Fetching spark://192.168.8.166:51992/jars/jackson-datatype-jsr310-2.15.2.jar with timestamp 1722865335909
		24/08/05 15:42:18 INFO Utils: Fetching spark://192.168.8.166:51992/jars/jackson-datatype-jsr310-2.15.2.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp14869485950663036811.tmp
		24/08/05 15:42:18 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/jackson-datatype-jsr310-2.15.2.jar to class loader default
		24/08/05 15:42:18 INFO Executor: Fetching spark://192.168.8.166:51992/jars/joda-time-2.12.5.jar with timestamp 1722865335909
		24/08/05 15:42:18 INFO Utils: Fetching spark://192.168.8.166:51992/jars/joda-time-2.12.5.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp7545207415823267948.tmp
		24/08/05 15:42:18 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/joda-time-2.12.5.jar to class loader default
		24/08/05 15:42:18 INFO Executor: Fetching spark://192.168.8.166:51992/jars/log4j-slf4j2-impl-2.20.0.jar with timestamp 1722865335909
		24/08/05 15:42:18 INFO Utils: Fetching spark://192.168.8.166:51992/jars/log4j-slf4j2-impl-2.20.0.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp11905357140918781259.tmp
		24/08/05 15:42:18 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/log4j-slf4j2-impl-2.20.0.jar to class loader default
		24/08/05 15:42:18 INFO Executor: Fetching spark://192.168.8.166:51992/jars/arpack_combined_all-0.1.jar with timestamp 1722865335909
		24/08/05 15:42:18 INFO Utils: Fetching spark://192.168.8.166:51992/jars/arpack_combined_all-0.1.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp8711904682072078747.tmp
		24/08/05 15:42:18 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/arpack_combined_all-0.1.jar to class loader default
		24/08/05 15:42:18 INFO Executor: Fetching spark://192.168.8.166:51992/jars/spire-platform_2.12-0.17.0.jar with timestamp 1722865335909
		24/08/05 15:42:18 INFO Utils: Fetching spark://192.168.8.166:51992/jars/spire-platform_2.12-0.17.0.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp17934533926612384384.tmp
		24/08/05 15:42:18 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/spire-platform_2.12-0.17.0.jar to class loader default
		24/08/05 15:42:18 INFO Executor: Fetching spark://192.168.8.166:51992/jars/arrow-memory-core-12.0.1.jar with timestamp 1722865335909
		24/08/05 15:42:18 INFO Utils: Fetching spark://192.168.8.166:51992/jars/arrow-memory-core-12.0.1.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp6725420352971256547.tmp
		24/08/05 15:42:18 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/arrow-memory-core-12.0.1.jar to class loader default
		24/08/05 15:42:18 INFO Executor: Fetching spark://192.168.8.166:51992/jars/orc-shims-1.9.2.jar with timestamp 1722865335909
		24/08/05 15:42:18 INFO Utils: Fetching spark://192.168.8.166:51992/jars/orc-shims-1.9.2.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp262309569003152738.tmp
		24/08/05 15:42:18 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/orc-shims-1.9.2.jar to class loader default
		24/08/05 15:42:18 INFO Executor: Fetching spark://192.168.8.166:51992/jars/aopalliance-repackaged-2.6.1.jar with timestamp 1722865335909
		24/08/05 15:42:18 INFO Utils: Fetching spark://192.168.8.166:51992/jars/aopalliance-repackaged-2.6.1.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp3611460036723988997.tmp
		24/08/05 15:42:18 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/aopalliance-repackaged-2.6.1.jar to class loader default
		24/08/05 15:42:18 INFO Executor: Fetching spark://192.168.8.166:51992/jars/jakarta.annotation-api-1.3.5.jar with timestamp 1722865335909
		24/08/05 15:42:18 INFO Utils: Fetching spark://192.168.8.166:51992/jars/jakarta.annotation-api-1.3.5.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp913191105560644459.tmp
		24/08/05 15:42:18 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/jakarta.annotation-api-1.3.5.jar to class loader default
		24/08/05 15:42:18 INFO Executor: Fetching spark://192.168.8.166:51992/jars/xz-1.9.jar with timestamp 1722865335909
		24/08/05 15:42:18 INFO Utils: Fetching spark://192.168.8.166:51992/jars/xz-1.9.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp6835908377516911542.tmp
		24/08/05 15:42:18 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/xz-1.9.jar to class loader default
		24/08/05 15:42:18 INFO Executor: Fetching spark://192.168.8.166:51992/jars/cats-kernel_2.12-2.1.1.jar with timestamp 1722865335909
		24/08/05 15:42:18 INFO Utils: Fetching spark://192.168.8.166:51992/jars/cats-kernel_2.12-2.1.1.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp18348536087133940088.tmp
		24/08/05 15:42:18 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/cats-kernel_2.12-2.1.1.jar to class loader default
		24/08/05 15:42:18 INFO Executor: Fetching spark://192.168.8.166:51992/jars/netty-transport-native-epoll-4.1.96.Final-linux-aarch_64.jar with timestamp 1722865335909
		24/08/05 15:42:18 INFO Utils: Fetching spark://192.168.8.166:51992/jars/netty-transport-native-epoll-4.1.96.Final-linux-aarch_64.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp5950425934673547765.tmp
		24/08/05 15:42:18 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/netty-transport-native-epoll-4.1.96.Final-linux-aarch_64.jar to class loader default
		24/08/05 15:42:18 INFO Executor: Fetching spark://192.168.8.166:51992/jars/slf4j-api-2.0.7.jar with timestamp 1722865335909
		24/08/05 15:42:18 INFO Utils: Fetching spark://192.168.8.166:51992/jars/slf4j-api-2.0.7.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp8858727341303627101.tmp
		24/08/05 15:42:18 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/slf4j-api-2.0.7.jar to class loader default
		24/08/05 15:42:18 INFO Executor: Fetching spark://192.168.8.166:51992/jars/netty-buffer-4.1.96.Final.jar with timestamp 1722865335909
		24/08/05 15:42:18 INFO Utils: Fetching spark://192.168.8.166:51992/jars/netty-buffer-4.1.96.Final.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp6764004280391766161.tmp
		24/08/05 15:42:18 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/netty-buffer-4.1.96.Final.jar to class loader default
		24/08/05 15:42:18 INFO Executor: Fetching spark://192.168.8.166:51992/jars/stream-2.9.6.jar with timestamp 1722865335909
		24/08/05 15:42:18 INFO Utils: Fetching spark://192.168.8.166:51992/jars/stream-2.9.6.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp1651229707745932029.tmp
		24/08/05 15:42:18 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/stream-2.9.6.jar to class loader default
		24/08/05 15:42:18 INFO Executor: Fetching spark://192.168.8.166:51992/jars/curator-framework-2.13.0.jar with timestamp 1722865335909
		24/08/05 15:42:18 INFO Utils: Fetching spark://192.168.8.166:51992/jars/curator-framework-2.13.0.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp5179396911890577138.tmp
		24/08/05 15:42:18 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/curator-framework-2.13.0.jar to class loader default
		24/08/05 15:42:18 INFO Executor: Fetching spark://192.168.8.166:51992/jars/istack-commons-runtime-3.0.8.jar with timestamp 1722865335909
		24/08/05 15:42:18 INFO Utils: Fetching spark://192.168.8.166:51992/jars/istack-commons-runtime-3.0.8.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp6231127909216132220.tmp
		24/08/05 15:42:18 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/istack-commons-runtime-3.0.8.jar to class loader default
		24/08/05 15:42:18 INFO Executor: Fetching spark://192.168.8.166:51992/jars/lapack-3.0.3.jar with timestamp 1722865335909
		24/08/05 15:42:18 INFO Utils: Fetching spark://192.168.8.166:51992/jars/lapack-3.0.3.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp1523436789160678322.tmp
		24/08/05 15:42:18 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/lapack-3.0.3.jar to class loader default
		24/08/05 15:42:18 INFO Executor: Fetching spark://192.168.8.166:51992/jars/zookeeper-3.6.3.jar with timestamp 1722865335909
		24/08/05 15:42:18 INFO Utils: Fetching spark://192.168.8.166:51992/jars/zookeeper-3.6.3.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp1015735934868346609.tmp
		24/08/05 15:42:18 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/zookeeper-3.6.3.jar to class loader default
		24/08/05 15:42:18 INFO Executor: Fetching spark://192.168.8.166:51992/jars/spark-sketch_2.12-3.5.1.jar with timestamp 1722865335909
		24/08/05 15:42:18 INFO Utils: Fetching spark://192.168.8.166:51992/jars/spark-sketch_2.12-3.5.1.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp11675097800168613049.tmp
		24/08/05 15:42:18 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/spark-sketch_2.12-3.5.1.jar to class loader default
		24/08/05 15:42:18 INFO Executor: Fetching spark://192.168.8.166:51992/jars/jackson-module-scala_2.12-2.15.2.jar with timestamp 1722865335909
		24/08/05 15:42:18 INFO Utils: Fetching spark://192.168.8.166:51992/jars/jackson-module-scala_2.12-2.15.2.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp5778595800939574255.tmp
		24/08/05 15:42:18 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/jackson-module-scala_2.12-2.15.2.jar to class loader default
		24/08/05 15:42:18 INFO Executor: Fetching spark://192.168.8.166:51992/jars/rocksdbjni-8.3.2.jar with timestamp 1722865335909
		24/08/05 15:42:18 INFO Utils: Fetching spark://192.168.8.166:51992/jars/rocksdbjni-8.3.2.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp14313189749356771481.tmp
		24/08/05 15:42:19 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/rocksdbjni-8.3.2.jar to class loader default
		24/08/05 15:42:19 INFO Executor: Fetching spark://192.168.8.166:51992/jars/parquet-format-structures-1.13.1.jar with timestamp 1722865335909
		24/08/05 15:42:19 INFO Utils: Fetching spark://192.168.8.166:51992/jars/parquet-format-structures-1.13.1.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp15469959310005942992.tmp
		24/08/05 15:42:19 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/parquet-format-structures-1.13.1.jar to class loader default
		24/08/05 15:42:19 INFO Executor: Fetching spark://192.168.8.166:51992/jars/netty-resolver-4.1.96.Final.jar with timestamp 1722865335909
		24/08/05 15:42:19 INFO Utils: Fetching spark://192.168.8.166:51992/jars/netty-resolver-4.1.96.Final.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp15638270213843118081.tmp
		24/08/05 15:42:19 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/netty-resolver-4.1.96.Final.jar to class loader default
		24/08/05 15:42:19 INFO Executor: Fetching spark://192.168.8.166:51992/jars/netty-transport-native-unix-common-4.1.96.Final.jar with timestamp 1722865335909
		24/08/05 15:42:19 INFO Utils: Fetching spark://192.168.8.166:51992/jars/netty-transport-native-unix-common-4.1.96.Final.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp7112546083292064232.tmp
		24/08/05 15:42:19 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/netty-transport-native-unix-common-4.1.96.Final.jar to class loader default
		24/08/05 15:42:19 INFO Executor: Fetching spark://192.168.8.166:51992/jars/commons-collections4-4.4.jar with timestamp 1722865335909
		24/08/05 15:42:19 INFO Utils: Fetching spark://192.168.8.166:51992/jars/commons-collections4-4.4.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp17951320300546055606.tmp
		24/08/05 15:42:19 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/commons-collections4-4.4.jar to class loader default
		24/08/05 15:42:19 INFO Executor: Fetching spark://192.168.8.166:51992/jars/netty-transport-native-kqueue-4.1.96.Final-osx-aarch_64.jar with timestamp 1722865335909
		24/08/05 15:42:19 INFO Utils: Fetching spark://192.168.8.166:51992/jars/netty-transport-native-kqueue-4.1.96.Final-osx-aarch_64.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp12225317800278499411.tmp
		24/08/05 15:42:19 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/netty-transport-native-kqueue-4.1.96.Final-osx-aarch_64.jar to class loader default
		24/08/05 15:42:19 INFO Executor: Fetching spark://192.168.8.166:51992/jars/datasketches-java-3.3.0.jar with timestamp 1722865335909
		24/08/05 15:42:19 INFO Utils: Fetching spark://192.168.8.166:51992/jars/datasketches-java-3.3.0.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp5452919764934079914.tmp
		24/08/05 15:42:19 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/datasketches-java-3.3.0.jar to class loader default
		24/08/05 15:42:19 INFO Executor: Fetching spark://192.168.8.166:51992/jars/breeze_2.12-2.1.0.jar with timestamp 1722865335909
		24/08/05 15:42:19 INFO Utils: Fetching spark://192.168.8.166:51992/jars/breeze_2.12-2.1.0.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp1032167151559711870.tmp
		24/08/05 15:42:19 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/breeze_2.12-2.1.0.jar to class loader default
		24/08/05 15:42:19 INFO Executor: Fetching spark://192.168.8.166:51992/jars/json4s-scalap_2.12-3.7.0-M11.jar with timestamp 1722865335909
		24/08/05 15:42:19 INFO Utils: Fetching spark://192.168.8.166:51992/jars/json4s-scalap_2.12-3.7.0-M11.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp11060570827997429448.tmp
		24/08/05 15:42:19 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/json4s-scalap_2.12-3.7.0-M11.jar to class loader default
		24/08/05 15:42:19 INFO Executor: Fetching spark://192.168.8.166:51992/jars/hk2-api-2.6.1.jar with timestamp 1722865335909
		24/08/05 15:42:19 INFO Utils: Fetching spark://192.168.8.166:51992/jars/hk2-api-2.6.1.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp16430622539464707462.tmp
		24/08/05 15:42:19 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/hk2-api-2.6.1.jar to class loader default
		24/08/05 15:42:19 INFO Executor: Fetching spark://192.168.8.166:51992/jars/threeten-extra-1.7.1.jar with timestamp 1722865335909
		24/08/05 15:42:19 INFO Utils: Fetching spark://192.168.8.166:51992/jars/threeten-extra-1.7.1.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp4685188789953081159.tmp
		24/08/05 15:42:19 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/threeten-extra-1.7.1.jar to class loader default
		24/08/05 15:42:19 INFO Executor: Fetching spark://192.168.8.166:51992/jars/jaxb-runtime-2.3.2.jar with timestamp 1722865335909
		24/08/05 15:42:19 INFO Utils: Fetching spark://192.168.8.166:51992/jars/jaxb-runtime-2.3.2.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp4477006875990502039.tmp
		24/08/05 15:42:19 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/jaxb-runtime-2.3.2.jar to class loader default
		24/08/05 15:42:19 INFO Executor: Fetching spark://192.168.8.166:51992/jars/ClientExample.jar with timestamp 1722865335909
		24/08/05 15:42:19 INFO Utils: Fetching spark://192.168.8.166:51992/jars/ClientExample.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp2130946939244166320.tmp
		24/08/05 15:42:19 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/ClientExample.jar to class loader default
		24/08/05 15:42:19 INFO Executor: Fetching spark://192.168.8.166:51992/jars/jersey-hk2-2.40.jar with timestamp 1722865335909
		24/08/05 15:42:19 INFO Utils: Fetching spark://192.168.8.166:51992/jars/jersey-hk2-2.40.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp11507879998602549192.tmp
		24/08/05 15:42:19 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/jersey-hk2-2.40.jar to class loader default
		24/08/05 15:42:19 INFO Executor: Fetching spark://192.168.8.166:51992/jars/parquet-jackson-1.13.1.jar with timestamp 1722865335909
		24/08/05 15:42:19 INFO Utils: Fetching spark://192.168.8.166:51992/jars/parquet-jackson-1.13.1.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp17725700871678799799.tmp
		24/08/05 15:42:19 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/parquet-jackson-1.13.1.jar to class loader default
		24/08/05 15:42:19 INFO Executor: Fetching spark://192.168.8.166:51992/jars/avro-1.11.2.jar with timestamp 1722865335909
		24/08/05 15:42:19 INFO Utils: Fetching spark://192.168.8.166:51992/jars/avro-1.11.2.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp10403647276308560089.tmp
		24/08/05 15:42:19 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/avro-1.11.2.jar to class loader default
		24/08/05 15:42:19 INFO Executor: Fetching spark://192.168.8.166:51992/jars/spire_2.12-0.17.0.jar with timestamp 1722865335909
		24/08/05 15:42:19 INFO Utils: Fetching spark://192.168.8.166:51992/jars/spire_2.12-0.17.0.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp11666824037589446970.tmp
		24/08/05 15:42:19 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/spire_2.12-0.17.0.jar to class loader default
		24/08/05 15:42:19 INFO Executor: Fetching spark://192.168.8.166:51992/jars/compress-lzf-1.1.2.jar with timestamp 1722865335909
		24/08/05 15:42:19 INFO Utils: Fetching spark://192.168.8.166:51992/jars/compress-lzf-1.1.2.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp8454452157736114162.tmp
		24/08/05 15:42:19 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/compress-lzf-1.1.2.jar to class loader default
		24/08/05 15:42:19 INFO Executor: Fetching spark://192.168.8.166:51992/jars/avro-mapred-1.11.2.jar with timestamp 1722865335909
		24/08/05 15:42:19 INFO Utils: Fetching spark://192.168.8.166:51992/jars/avro-mapred-1.11.2.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp10158892679494046959.tmp
		24/08/05 15:42:19 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/avro-mapred-1.11.2.jar to class loader default
		24/08/05 15:42:19 INFO Executor: Fetching spark://192.168.8.166:51992/jars/jakarta.validation-api-2.0.2.jar with timestamp 1722865335909
		24/08/05 15:42:19 INFO Utils: Fetching spark://192.168.8.166:51992/jars/jakarta.validation-api-2.0.2.jar to /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/fetchFileTemp4889745357795793579.tmp
		24/08/05 15:42:19 INFO Executor: Adding file:/private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840/userFiles-7768f9c4-bd44-455a-9806-338acac501f2/jakarta.validation-api-2.0.2.jar to class loader default
		24/08/05 15:42:19 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 51996.
		24/08/05 15:42:19 INFO NettyBlockTransferService: Server created on 192.168.8.166:51996
		24/08/05 15:42:19 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
		24/08/05 15:42:19 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.8.166, 51996, None)
		24/08/05 15:42:19 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.8.166:51996 with 2.2 GiB RAM, BlockManagerId(driver, 192.168.8.166, 51996, None)
		24/08/05 15:42:19 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 192.168.8.166, 51996, None)
		24/08/05 15:42:19 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 192.168.8.166, 51996, None)
		24/08/05 15:42:19 INFO log: Logging initialized @6150ms to org.eclipse.jetty.util.log.Slf4jLog
		24/08/05 15:42:19 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
		24/08/05 15:42:19 INFO SharedState: Warehouse path is 'file:/Users/folkol/code/spark/spark-warehouse'.
		24/08/05 15:42:20 INFO InMemoryFileIndex: It took 44 ms to list leaf files for 1 paths.
		24/08/05 15:42:21 INFO SparkContext: Starting job: parquet at ClientExample.java:15
		24/08/05 15:42:21 INFO DAGScheduler: Got job 0 (parquet at ClientExample.java:15) with 1 output partitions
		24/08/05 15:42:21 INFO DAGScheduler: Final stage: ResultStage 0 (parquet at ClientExample.java:15)
		24/08/05 15:42:21 INFO DAGScheduler: Parents of final stage: List()
		24/08/05 15:42:21 INFO DAGScheduler: Missing parents: List()
		24/08/05 15:42:21 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[1] at parquet at ClientExample.java:15), which has no missing parents
		24/08/05 15:42:21 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 143.0 KiB, free 2.2 GiB)
		24/08/05 15:42:21 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 46.3 KiB, free 2.2 GiB)
		24/08/05 15:42:21 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 192.168.8.166:51996 (size: 46.3 KiB, free: 2.2 GiB)
		24/08/05 15:42:21 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1585
		24/08/05 15:42:21 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[1] at parquet at ClientExample.java:15) (first 15 tasks are for partitions Vector(0))
		24/08/05 15:42:21 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
		24/08/05 15:42:21 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (192.168.8.166, executor driver, partition 0, PROCESS_LOCAL, 20767 bytes) 
		24/08/05 15:42:21 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
		24/08/05 15:42:21 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 2478 bytes result sent to driver
		24/08/05 15:42:21 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 429 ms on 192.168.8.166 (executor driver) (1/1)
		24/08/05 15:42:21 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
		24/08/05 15:42:21 INFO DAGScheduler: ResultStage 0 (parquet at ClientExample.java:15) finished in 0,593 s
		24/08/05 15:42:21 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
		24/08/05 15:42:21 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
		24/08/05 15:42:21 INFO DAGScheduler: Job 0 finished: parquet at ClientExample.java:15, took 0,650136 s
		24/08/05 15:42:22 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 192.168.8.166:51996 in memory (size: 46.3 KiB, free: 2.2 GiB)
		24/08/05 15:42:22 INFO InMemoryFileIndex: It took 1 ms to list leaf files for 1 paths.
		24/08/05 15:42:22 INFO InMemoryFileIndex: It took 1 ms to list leaf files for 1 paths.
		24/08/05 15:42:24 INFO FileSourceStrategy: Pushed Filters: 
		24/08/05 15:42:24 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#38, None)) > 0)
		24/08/05 15:42:24 INFO CodeGenerator: Code generated in 189.30322 ms
		24/08/05 15:42:24 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 376.0 B, free 2.2 GiB)
		24/08/05 15:42:24 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 43.3 KiB, free 2.2 GiB)
		24/08/05 15:42:24 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 192.168.8.166:51996 (size: 43.3 KiB, free: 2.2 GiB)
		24/08/05 15:42:24 INFO SparkContext: Created broadcast 1 from csv at ClientExample.java:16
		24/08/05 15:42:24 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
		24/08/05 15:42:24 INFO SparkContext: Starting job: csv at ClientExample.java:16
		24/08/05 15:42:24 INFO DAGScheduler: Got job 1 (csv at ClientExample.java:16) with 1 output partitions
		24/08/05 15:42:24 INFO DAGScheduler: Final stage: ResultStage 1 (csv at ClientExample.java:16)
		24/08/05 15:42:24 INFO DAGScheduler: Parents of final stage: List()
		24/08/05 15:42:24 INFO DAGScheduler: Missing parents: List()
		24/08/05 15:42:24 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[5] at csv at ClientExample.java:16), which has no missing parents
		24/08/05 15:42:24 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 13.5 KiB, free 2.2 GiB)
		24/08/05 15:42:24 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 2.2 GiB)
		24/08/05 15:42:24 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 192.168.8.166:51996 (size: 6.4 KiB, free: 2.2 GiB)
		24/08/05 15:42:24 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1585
		24/08/05 15:42:24 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at csv at ClientExample.java:16) (first 15 tasks are for partitions Vector(0))
		24/08/05 15:42:24 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
		24/08/05 15:42:24 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (192.168.8.166, executor driver, partition 0, PROCESS_LOCAL, 21245 bytes) 
		24/08/05 15:42:24 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
		24/08/05 15:42:24 INFO CodeGenerator: Code generated in 49.167295 ms
		24/08/05 15:42:24 INFO FileScanRDD: Reading File path: file:///tmp/names.csv, range: 0-43, partition values: [empty row]
		24/08/05 15:42:24 INFO CodeGenerator: Code generated in 11.42227 ms
		24/08/05 15:42:24 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1633 bytes result sent to driver
		24/08/05 15:42:24 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 137 ms on 192.168.8.166 (executor driver) (1/1)
		24/08/05 15:42:24 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
		24/08/05 15:42:24 INFO DAGScheduler: ResultStage 1 (csv at ClientExample.java:16) finished in 0,155 s
		24/08/05 15:42:24 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
		24/08/05 15:42:24 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
		24/08/05 15:42:24 INFO DAGScheduler: Job 1 finished: csv at ClientExample.java:16, took 0,159522 s
		24/08/05 15:42:24 INFO CodeGenerator: Code generated in 9.49962 ms
		24/08/05 15:42:24 INFO FileSourceStrategy: Pushed Filters: 
		24/08/05 15:42:24 INFO FileSourceStrategy: Post-Scan Filters: 
		24/08/05 15:42:24 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 376.0 B, free 2.2 GiB)
		24/08/05 15:42:24 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 192.168.8.166:51996 in memory (size: 6.4 KiB, free: 2.2 GiB)
		24/08/05 15:42:24 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 43.3 KiB, free 2.2 GiB)
		24/08/05 15:42:24 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 192.168.8.166:51996 (size: 43.3 KiB, free: 2.2 GiB)
		24/08/05 15:42:24 INFO SparkContext: Created broadcast 3 from csv at ClientExample.java:16
		24/08/05 15:42:24 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
		24/08/05 15:42:24 INFO FileSourceStrategy: Pushed Filters: 
		24/08/05 15:42:24 INFO FileSourceStrategy: Post-Scan Filters: 
		24/08/05 15:42:24 INFO FileSourceStrategy: Pushed Filters: IsNotNull(VendorID)
		24/08/05 15:42:24 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(VendorID#55)
		24/08/05 15:42:25 INFO CodeGenerator: Code generated in 10.735336 ms
		24/08/05 15:42:25 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 376.0 B, free 2.2 GiB)
		24/08/05 15:42:25 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 43.3 KiB, free 2.2 GiB)
		24/08/05 15:42:25 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 192.168.8.166:51996 (size: 43.3 KiB, free: 2.2 GiB)
		24/08/05 15:42:25 INFO SparkContext: Created broadcast 4 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
		24/08/05 15:42:25 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
		24/08/05 15:42:25 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
		24/08/05 15:42:25 INFO DAGScheduler: Got job 2 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
		24/08/05 15:42:25 INFO DAGScheduler: Final stage: ResultStage 2 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
		24/08/05 15:42:25 INFO DAGScheduler: Parents of final stage: List()
		24/08/05 15:42:25 INFO DAGScheduler: Missing parents: List()
		24/08/05 15:42:25 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[15] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
		24/08/05 15:42:25 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 15.4 KiB, free 2.2 GiB)
		24/08/05 15:42:25 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 7.5 KiB, free 2.2 GiB)
		24/08/05 15:42:25 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 192.168.8.166:51996 (size: 7.5 KiB, free: 2.2 GiB)
		24/08/05 15:42:25 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1585
		24/08/05 15:42:25 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[15] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
		24/08/05 15:42:25 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
		24/08/05 15:42:25 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (192.168.8.166, executor driver, partition 0, PROCESS_LOCAL, 21245 bytes) 
		24/08/05 15:42:25 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
		24/08/05 15:42:25 INFO CodeGenerator: Code generated in 9.214182 ms
		24/08/05 15:42:25 INFO FileScanRDD: Reading File path: file:///tmp/names.csv, range: 0-43, partition values: [empty row]
		24/08/05 15:42:25 INFO CodeGenerator: Code generated in 8.523699 ms
		24/08/05 15:42:25 INFO CodeGenerator: Code generated in 7.235645 ms
		24/08/05 15:42:25 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1662 bytes result sent to driver
		24/08/05 15:42:25 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 81 ms on 192.168.8.166 (executor driver) (1/1)
		24/08/05 15:42:25 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
		24/08/05 15:42:25 INFO DAGScheduler: ResultStage 2 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0,087 s
		24/08/05 15:42:25 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
		24/08/05 15:42:25 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
		24/08/05 15:42:25 INFO DAGScheduler: Job 2 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0,091443 s
		24/08/05 15:42:25 INFO CodeGenerator: Code generated in 11.846102 ms
		24/08/05 15:42:25 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 1024.1 KiB, free 2.2 GiB)
		24/08/05 15:42:25 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 286.0 B, free 2.2 GiB)
		24/08/05 15:42:25 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 192.168.8.166:51996 (size: 286.0 B, free: 2.2 GiB)
		24/08/05 15:42:25 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 192.168.8.166:51996 in memory (size: 43.3 KiB, free: 2.2 GiB)
		24/08/05 15:42:25 INFO SparkContext: Created broadcast 6 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
		24/08/05 15:42:25 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 192.168.8.166:51996 in memory (size: 7.5 KiB, free: 2.2 GiB)
		24/08/05 15:42:25 INFO FileSourceStrategy: Pushed Filters: 
		24/08/05 15:42:25 INFO FileSourceStrategy: Post-Scan Filters: 
		24/08/05 15:42:25 INFO CodeGenerator: Code generated in 70.142302 ms
		24/08/05 15:42:25 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 376.0 B, free 2.2 GiB)
		24/08/05 15:42:25 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 44.0 KiB, free 2.2 GiB)
		24/08/05 15:42:25 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 192.168.8.166:51996 (size: 44.0 KiB, free: 2.2 GiB)
		24/08/05 15:42:25 INFO SparkContext: Created broadcast 7 from show at ClientExample.java:24
		24/08/05 15:42:25 INFO FileSourceScanExec: Planning scan with bin packing, max size: 13587441 bytes, open cost is considered as scanning 4194304 bytes.
		24/08/05 15:42:25 INFO DAGScheduler: Registering RDD 19 (show at ClientExample.java:24) as input to shuffle 0
		24/08/05 15:42:25 INFO DAGScheduler: Got map stage job 3 (show at ClientExample.java:24) with 8 output partitions
		24/08/05 15:42:25 INFO DAGScheduler: Final stage: ShuffleMapStage 3 (show at ClientExample.java:24)
		24/08/05 15:42:25 INFO DAGScheduler: Parents of final stage: List()
		24/08/05 15:42:25 INFO DAGScheduler: Missing parents: List()
		24/08/05 15:42:25 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[19] at show at ClientExample.java:24), which has no missing parents
		24/08/05 15:42:25 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 51.3 KiB, free 2.2 GiB)
		24/08/05 15:42:25 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 23.2 KiB, free 2.2 GiB)
		24/08/05 15:42:25 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 192.168.8.166:51996 (size: 23.2 KiB, free: 2.2 GiB)
		24/08/05 15:42:25 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1585
		24/08/05 15:42:25 INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[19] at show at ClientExample.java:24) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
		24/08/05 15:42:25 INFO TaskSchedulerImpl: Adding task set 3.0 with 8 tasks resource profile 0
		24/08/05 15:42:25 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3) (192.168.8.166, executor driver, partition 0, PROCESS_LOCAL, 21263 bytes) 
		24/08/05 15:42:25 INFO TaskSetManager: Starting task 1.0 in stage 3.0 (TID 4) (192.168.8.166, executor driver, partition 1, PROCESS_LOCAL, 21263 bytes) 
		24/08/05 15:42:25 INFO TaskSetManager: Starting task 2.0 in stage 3.0 (TID 5) (192.168.8.166, executor driver, partition 2, PROCESS_LOCAL, 21263 bytes) 
		24/08/05 15:42:25 INFO TaskSetManager: Starting task 3.0 in stage 3.0 (TID 6) (192.168.8.166, executor driver, partition 3, PROCESS_LOCAL, 21263 bytes) 
		24/08/05 15:42:25 INFO TaskSetManager: Starting task 4.0 in stage 3.0 (TID 7) (192.168.8.166, executor driver, partition 4, PROCESS_LOCAL, 21263 bytes) 
		24/08/05 15:42:25 INFO TaskSetManager: Starting task 5.0 in stage 3.0 (TID 8) (192.168.8.166, executor driver, partition 5, PROCESS_LOCAL, 21263 bytes) 
		24/08/05 15:42:25 INFO TaskSetManager: Starting task 6.0 in stage 3.0 (TID 9) (192.168.8.166, executor driver, partition 6, PROCESS_LOCAL, 21263 bytes) 
		24/08/05 15:42:25 INFO TaskSetManager: Starting task 7.0 in stage 3.0 (TID 10) (192.168.8.166, executor driver, partition 7, PROCESS_LOCAL, 21263 bytes) 
		24/08/05 15:42:25 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
		24/08/05 15:42:25 INFO Executor: Running task 1.0 in stage 3.0 (TID 4)
		24/08/05 15:42:25 INFO Executor: Running task 2.0 in stage 3.0 (TID 5)
		24/08/05 15:42:25 INFO Executor: Running task 3.0 in stage 3.0 (TID 6)
		24/08/05 15:42:25 INFO Executor: Running task 4.0 in stage 3.0 (TID 7)
		24/08/05 15:42:25 INFO Executor: Running task 5.0 in stage 3.0 (TID 8)
		24/08/05 15:42:25 INFO Executor: Running task 6.0 in stage 3.0 (TID 9)
		24/08/05 15:42:25 INFO Executor: Running task 7.0 in stage 3.0 (TID 10)
		24/08/05 15:42:25 INFO CodeGenerator: Code generated in 46.654791 ms
		24/08/05 15:42:25 INFO CodeGenerator: Code generated in 9.937439 ms
		24/08/05 15:42:25 INFO CodeGenerator: Code generated in 7.785307 ms
		24/08/05 15:42:25 INFO CodeGenerator: Code generated in 9.367044 ms
		24/08/05 15:42:25 INFO FileScanRDD: Reading File path: file:///tmp/yellow/yellow_tripdata_2024-02.parquet, range: 0-13587441, partition values: [empty row]
		24/08/05 15:42:25 INFO FileScanRDD: Reading File path: file:///tmp/yellow/yellow_tripdata_2024-01.parquet, range: 0-13587441, partition values: [empty row]
		24/08/05 15:42:25 INFO FileScanRDD: Reading File path: file:///tmp/yellow/yellow_tripdata_2024-01.parquet, range: 27174882-40762323, partition values: [empty row]
		24/08/05 15:42:25 INFO FileScanRDD: Reading File path: file:///tmp/yellow/yellow_tripdata_2024-02.parquet, range: 27174882-40762323, partition values: [empty row]
		24/08/05 15:42:25 INFO FileScanRDD: Reading File path: file:///tmp/yellow/yellow_tripdata_2024-01.parquet, range: 40762323-49961641, partition values: [empty row]
		24/08/05 15:42:25 INFO FileScanRDD: Reading File path: file:///tmp/yellow/yellow_tripdata_2024-01.parquet, range: 13587441-27174882, partition values: [empty row]
		24/08/05 15:42:25 INFO FileScanRDD: Reading File path: file:///tmp/yellow/yellow_tripdata_2024-02.parquet, range: 40762323-50349284, partition values: [empty row]
		24/08/05 15:42:25 INFO FileScanRDD: Reading File path: file:///tmp/yellow/yellow_tripdata_2024-02.parquet, range: 13587441-27174882, partition values: [empty row]
		24/08/05 15:42:25 INFO Executor: Finished task 5.0 in stage 3.0 (TID 8). 3574 bytes result sent to driver
		24/08/05 15:42:25 INFO Executor: Finished task 2.0 in stage 3.0 (TID 5). 3574 bytes result sent to driver
		24/08/05 15:42:25 INFO TaskSetManager: Finished task 5.0 in stage 3.0 (TID 8) in 311 ms on 192.168.8.166 (executor driver) (1/8)
		24/08/05 15:42:25 INFO TaskSetManager: Finished task 2.0 in stage 3.0 (TID 5) in 315 ms on 192.168.8.166 (executor driver) (2/8)
		24/08/05 15:42:25 INFO CodecPool: Got brand-new decompressor [.zstd]
		24/08/05 15:42:25 INFO CodecPool: Got brand-new decompressor [.zstd]
		24/08/05 15:42:25 INFO CodecPool: Got brand-new decompressor [.zstd]
		24/08/05 15:42:25 INFO CodecPool: Got brand-new decompressor [.zstd]
		24/08/05 15:42:25 INFO CodecPool: Got brand-new decompressor [.zstd]
		24/08/05 15:42:25 INFO CodecPool: Got brand-new decompressor [.zstd]
		24/08/05 15:42:25 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 192.168.8.166:51996 in memory (size: 43.3 KiB, free: 2.2 GiB)
		24/08/05 15:42:26 INFO Executor: Finished task 7.0 in stage 3.0 (TID 10). 3746 bytes result sent to driver
		24/08/05 15:42:26 INFO TaskSetManager: Finished task 7.0 in stage 3.0 (TID 10) in 997 ms on 192.168.8.166 (executor driver) (3/8)
		24/08/05 15:42:26 INFO Executor: Finished task 6.0 in stage 3.0 (TID 9). 3703 bytes result sent to driver
		24/08/05 15:42:26 INFO TaskSetManager: Finished task 6.0 in stage 3.0 (TID 9) in 1091 ms on 192.168.8.166 (executor driver) (4/8)
		24/08/05 15:42:26 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 3746 bytes result sent to driver
		24/08/05 15:42:26 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 1152 ms on 192.168.8.166 (executor driver) (5/8)
		24/08/05 15:42:26 INFO Executor: Finished task 3.0 in stage 3.0 (TID 6). 3703 bytes result sent to driver
		24/08/05 15:42:26 INFO TaskSetManager: Finished task 3.0 in stage 3.0 (TID 6) in 1152 ms on 192.168.8.166 (executor driver) (6/8)
		24/08/05 15:42:26 INFO Executor: Finished task 1.0 in stage 3.0 (TID 4). 3703 bytes result sent to driver
		24/08/05 15:42:26 INFO TaskSetManager: Finished task 1.0 in stage 3.0 (TID 4) in 1161 ms on 192.168.8.166 (executor driver) (7/8)
		24/08/05 15:42:26 INFO Executor: Finished task 4.0 in stage 3.0 (TID 7). 3703 bytes result sent to driver
		24/08/05 15:42:26 INFO TaskSetManager: Finished task 4.0 in stage 3.0 (TID 7) in 1166 ms on 192.168.8.166 (executor driver) (8/8)
		24/08/05 15:42:26 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
		24/08/05 15:42:26 INFO DAGScheduler: ShuffleMapStage 3 (show at ClientExample.java:24) finished in 1,185 s
		24/08/05 15:42:26 INFO DAGScheduler: looking for newly runnable stages
		24/08/05 15:42:26 INFO DAGScheduler: running: Set()
		24/08/05 15:42:26 INFO DAGScheduler: waiting: Set()
		24/08/05 15:42:26 INFO DAGScheduler: failed: Set()
		24/08/05 15:42:26 INFO ShufflePartitionsUtil: For shuffle(0), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
		24/08/05 15:42:26 INFO CodeGenerator: Code generated in 16.405102 ms
		24/08/05 15:42:26 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
		24/08/05 15:42:26 INFO CodeGenerator: Code generated in 21.109193 ms
		24/08/05 15:42:26 INFO SparkContext: Starting job: show at ClientExample.java:24
		24/08/05 15:42:26 INFO DAGScheduler: Got job 4 (show at ClientExample.java:24) with 1 output partitions
		24/08/05 15:42:26 INFO DAGScheduler: Final stage: ResultStage 5 (show at ClientExample.java:24)
		24/08/05 15:42:26 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 4)
		24/08/05 15:42:26 INFO DAGScheduler: Missing parents: List()
		24/08/05 15:42:26 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[23] at show at ClientExample.java:24), which has no missing parents
		24/08/05 15:42:26 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 50.4 KiB, free 2.2 GiB)
		24/08/05 15:42:26 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 23.5 KiB, free 2.2 GiB)
		24/08/05 15:42:26 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 192.168.8.166:51996 (size: 23.5 KiB, free: 2.2 GiB)
		24/08/05 15:42:26 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1585
		24/08/05 15:42:26 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[23] at show at ClientExample.java:24) (first 15 tasks are for partitions Vector(0))
		24/08/05 15:42:26 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0
		24/08/05 15:42:26 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 11) (192.168.8.166, executor driver, partition 0, NODE_LOCAL, 20661 bytes) 
		24/08/05 15:42:26 INFO Executor: Running task 0.0 in stage 5.0 (TID 11)
		24/08/05 15:42:26 INFO CodeGenerator: Code generated in 8.774843 ms
		24/08/05 15:42:26 INFO ShuffleBlockFetcherIterator: Getting 6 (992.0 B) non-empty blocks including 6 (992.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
		24/08/05 15:42:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 10 ms
		24/08/05 15:42:26 INFO CodeGenerator: Code generated in 16.676874 ms
		24/08/05 15:42:27 INFO Executor: Finished task 0.0 in stage 5.0 (TID 11). 6153 bytes result sent to driver
		24/08/05 15:42:27 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 11) in 107 ms on 192.168.8.166 (executor driver) (1/1)
		24/08/05 15:42:27 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
		24/08/05 15:42:27 INFO DAGScheduler: ResultStage 5 (show at ClientExample.java:24) finished in 0,116 s
		24/08/05 15:42:27 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
		24/08/05 15:42:27 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished
		24/08/05 15:42:27 INFO DAGScheduler: Job 4 finished: show at ClientExample.java:24, took 0,128490 s
		24/08/05 15:42:27 INFO CodeGenerator: Code generated in 9.932587 ms
		24/08/05 15:42:27 INFO CodeGenerator: Code generated in 7.434795 ms
		24/08/05 15:42:27 INFO SparkContext: SparkContext is stopping with exitCode 0.
		+------+--------+
		|vendor|priciest|
		+------+--------+
		| Apple|  9792.0|
		|   IBM|  2221.3|
		|FooBar|  100.73|
		+------+--------+

		24/08/05 15:42:27 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
		24/08/05 15:42:27 INFO MemoryStore: MemoryStore cleared
		24/08/05 15:42:27 INFO BlockManager: BlockManager stopped
		24/08/05 15:42:27 INFO BlockManagerMaster: BlockManagerMaster stopped
		24/08/05 15:42:27 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
		24/08/05 15:42:27 INFO SparkContext: Successfully stopped SparkContext
		24/08/05 15:42:27 INFO ShutdownHookManager: Shutdown hook called
		24/08/05 15:42:27 INFO ShutdownHookManager: Deleting directory /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-c26d0e75-1514-4ff1-9407-4f05d70bb840
		24/08/05 15:42:27 INFO ShutdownHookManager: Deleting directory /private/var/folders/sn/pr23sfmj305695dfj3m4p2lw0000gn/T/spark-3340b41e-2b3d-4fb1-a91f-fe2d6c19a03c

		Process finished with exit code 0


	- Will start Spark Connect server with `spark.sql.catalogImplementation=in-memory`, some tests that rely on Hive will be ignored. If you don't want to skip them:

	- start removing stuff, commit (or at least add) after every run
		- run is start master + start worker + submit task

	- Submit:
    // In standalone cluster mode, there are two submission gateways:
    //   (1) The traditional RPC gateway using o.a.s.deploy.Client as a wrapper
    //   (2) The new REST-based gateway introduced in Spark 1.3
    // The latter is the default behavior as of Spark 1.3, but Spark submit will fail over
    // to use the legacy gateway if the master endpoint turns out to be not a REST server.

    - make sure options are before .jar
    - The spark-protobuf module is external and not included in spark-submit or spark-shell by default.

    - Modules
	   [INFO] Reactor Build Order:
		[INFO]
		[INFO] Spark Project Parent POM                                           [pom]
		[INFO] Spark Project Tags                                                 [jar]
		[INFO] Spark Project Sketch                                               [jar]
		[INFO] Spark Project Local DB                                             [jar]
		[INFO] Spark Project Common Utils                                         [jar]
		[INFO] Spark Project Networking                                           [jar]
		[INFO] Spark Project Shuffle Streaming Service                            [jar]
		[INFO] Spark Project Unsafe                                               [jar]
		[INFO] Spark Project Launcher                                             [jar]
		[INFO] Spark Project Core                                                 [jar]
		[INFO] Spark Project Tools                                                [jar]
		[INFO] Spark Project Streaming                                            [jar]
		[INFO] Spark Project SQL API                                              [jar]
		[INFO] Spark Project Catalyst                                             [jar]
		[INFO] Spark Project SQL                                                  [jar]
		[INFO] Spark Project Hive                                                 [jar]
		[INFO] Spark Project Assembly                                             [pom]
		[INFO] Kafka 0.10+ Token Provider for Streaming                           [jar]
		[INFO] Spark Integration for Kafka 0.10                                   [jar]
		[INFO] Spark Integration for Kafka 0.10 Assembly                          [jar]
		[INFO] Kafka 0.10+ Source for Structured Streaming                        [jar]
		[INFO] Spark Avro                                                         [jar]
		[INFO] Spark Project Connect Common                                       [jar]
		[INFO] Spark Protobuf                                                     [jar]
		[INFO] Spark Project Connect Server                                       [jar]
		[INFO] Spark Project Connect Client                                       [jar]

		We could probably remove everything after assembly.

		- /Users/folkol/code/spark/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/optimizer/Optimizer.scala:1889: warning: Could not find any member to link for "Filter".
			- etc, many warnings
			- seems to be scaladoc warnings
		- 


		-Dmaven.scaladoc.skip=true?


		[INFO] ------------------------------------------------------------------------
		[INFO] Reactor Summary for Spark Project Parent POM 3.5.1:
		[INFO]
		[INFO] Spark Project Parent POM ........................... SUCCESS [  4.854 s]
		[INFO] Spark Project Tags ................................. SUCCESS [  8.678 s]
		[INFO] Spark Project Sketch ............................... SUCCESS [  7.262 s]
		[INFO] Spark Project Local DB ............................. SUCCESS [  8.848 s]
		[INFO] Spark Project Common Utils ......................... SUCCESS [ 20.020 s]
		[INFO] Spark Project Networking ........................... SUCCESS [ 16.066 s]
		[INFO] Spark Project Shuffle Streaming Service ............ SUCCESS [ 11.770 s]
		[INFO] Spark Project Unsafe ............................... SUCCESS [  8.120 s]
		[INFO] Spark Project Launcher ............................. SUCCESS [  8.523 s]
		[INFO] Spark Project Core ................................. SUCCESS [02:13 min]
		[INFO] Spark Project Tools ................................ SUCCESS [  9.239 s]
		[INFO] Spark Project Streaming ............................ SUCCESS [ 47.237 s]
		[INFO] Spark Project SQL API .............................. SUCCESS [ 57.345 s]
		[INFO] Spark Project Catalyst ............................. SUCCESS [05:10 min]
		[INFO] Spark Project SQL .................................. SUCCESS [03:24 min]
		[INFO] Spark Project Hive ................................. SUCCESS [ 50.004 s]
		[INFO] Spark Project Assembly ............................. SUCCESS [ 16.379 s]
		[INFO] Kafka 0.10+ Token Provider for Streaming ........... SUCCESS [ 12.748 s]
		[INFO] Spark Integration for Kafka 0.10 ................... SUCCESS [ 20.437 s]
		[INFO] Spark Integration for Kafka 0.10 Assembly .......... SUCCESS [  4.167 s]
		[INFO] Kafka 0.10+ Source for Structured Streaming ........ SUCCESS [ 25.589 s]
		[INFO] Spark Avro ......................................... SUCCESS [ 21.957 s]
		[INFO] Spark Project Connect Common ....................... SUCCESS [01:13 min]
		[INFO] Spark Protobuf ..................................... SUCCESS [ 19.410 s]
		[INFO] Spark Project Connect Server ....................... SUCCESS [ 58.800 s]
		[INFO] Spark Project Connect Client ....................... SUCCESS [ 49.810 s]
		[INFO] ------------------------------------------------------------------------
		[INFO] BUILD SUCCESS
		[INFO] ------------------------------------------------------------------------
		[INFO] Total time:  20:11 min
		[INFO] Finished at: 2024-08-06T00:10:46+02:00
		[INFO] ------------------------------------------------------------------------

		- java serialization issues, 'java.io.InvalidClassException: org.apache.spark.storage.BlockManagerId; local class incompatible: stream classdesc serialVersionUID = 8760323731857918296, local class serialVersionUID = -1330592639851569261'
		- probably mix of maven-class and intellij-class?
		- yup, removed --jars from Submit and added vm options -cp instead




### simpler test?

/**
 * Used when running a local version of Spark where the executor, backend, and master all run in
 * the same JVM. It sits behind a [[TaskSchedulerImpl]] and handles launching tasks on a single
 * Executor (created by the [[LocalSchedulerBackend]]) running locally.
 */

Removed: --master spark://192.168.8.166:7077

setContextClassLoader


'local mode' still uses rpc, but 'local'
RcpCallContext
	NettyRpcCallContext
		LocalNettyRpcCallContext
			// If the sender and the receiver are in the same process, the reply can be sent back via `Promise`.
		RemoteNettyRpcCallContext


/**
 * Main entry point for Spark functionality. A SparkContext represents the connection to a Spark
 * cluster, and can be used to create RDDs, accumulators and broadcast variables on that cluster.
 *
 * @note Only one `SparkContext` should be active per JVM. You must `stop()` the
 *   active `SparkContext` before creating a new one.
 * @param config a Spark Config object describing the application configuration. Any settings in
 *   this config overrides the default configs as well as system properties.
 */
class SparkContext(config: SparkConf) extends Logging {
	...
	RpcEndpoints







SparkSubmit::main
	doSubmit(args)
		doRunMain
			mainClass.getConstructor().newInstance()
			app.start(...)
				ClientExample::main
					SparkSession::getOrCreate
						SparkContext::getOrCreate
							'Spark listener bus'
							new ResourceProfileManager
							AppStatusSource.createSource(conf) / metrics
							createSparkEnv(_conf, isLocal, listenerBus)
								// Create the Spark execution environment (cache, map output tracker, etc)
								SparkEnv.createDriverEnv
									bindAddr
									advertiseAddr
									create
										// Helper method to create a SparkEnv for a driver or an executor.
										securityManager
										rpcEnv = RpcEnv.create(...)
										new NettyRpcEnvFactory().create(config)
											new JavaSerializer
											new NettyRpcEnv
												role = Some(driver)
												SparkTransportConf.fromSparkConf(...)
													spark.TransformConf
													spark.netty.Dispatcher
														// A message dispatcher, responsible for routing RPC messages to the appropriate endpoint(s).
														new NettyStreamManager(this)
															// StreamManager implementation for serving files from a NettyRpcEnv.
														TransportContext
															// Contains the context to create a {@link TransportServer}, {@link TransportClientFactory}, and to setup Netty Channel pipelines with a {@link org.apache.spark.network.server.TransportChannelHandler}.
															new NettyRpcHandler
															transportContext.createClientFactory
															clientConnectionExecutor = ThreadUtils.newDaemonCachedThreadPool
															outboxes = new ConcurrentHashMap
															startNettyRpcEnv
															Utils.startServiceOnPort(config.port, startNettyRpcEnv, sparkConf, config.name)._1
																NettyRpcENv::startServer
																	dispatcher.registerRpcEndpoint(RpcEndpointVerifier.NAME, new RpcEndpointVerifier(this, dispatcher))
																		// ping-endpoint
										serializer = Utils.instantiateSerializerFromConf
										new SerializerManager(serializer, conf, ioEncryptionKey)
										closureSerializer = new JavaSerializer(conf)
										new BroadcastManager(isDriver, conf)
										new MapOutputTrackerMaster(conf, broadcastManager, isLocal)
											// Driver-side class that keeps track of the location of the map output of a stage.
											private val PoisonPill = GetMapOutputMessage(-99, null)
											mapOutputTracker.trackerEndpoint = registerOrLookupEndpoint(MapOutputTracker.ENDPOINT_NAME,
											rpcEnv.setupEndpoint(name, endpointCreator)
												dispatcher.registerRpcEndpoint(name, endpoint)
												val shuffleManager = Utils.instantiateSerializerOrShuffleManager
												memoryManager: MemoryManager = UnifiedMemoryManager(conf, numUsableCores)
												externalShuffleClient
												blockManagerMaster = new BlockManagerMaster
													rpcEnv.setupEndpoint(name, endpointCreator)
														// BlockManagerMasterEndpoint is an [[IsolatedThreadSafeRpcEndpoint]] on the master node to track statuses of all the storage endpoints' block managers.
												blockTransferService = new NettyBlockTransferService
													// Provides an interface for reading both shuffle files and RDD blocks, either from an Executor or external service.
													blockManager = new BlockManager(
														// Manager running on every node (driver and executors) which provides interfaces for putting and retrieving blocks both locally and remotely into various stores (memory, disk, and off-heap).
														new DiskBlockManager
														new BlockInfoManager (block metadata)
														futureExecutionContext = ExecutionContext.fromExecutorService
														memoryManager.setMemoryStore(mem or disk)
														blockStoreClient = externalBlockStoreClient.getOrElse(blockTransferService)
														storageEndpoint = rpcEnv.setupEndpoint(...)
														remoteBlockTempFileManager = new BlockManager.RemoteBlockDownloadFileManager
												metricSystem (wait for app id from task scheduler before starting)
												val outputCommitCoordinatorRef = registerOrLookupEndpoint("OutputCommitCoordinator",
								new SparkEnv(...)
							_statusTracker = new SparkStatusTracker(this, _statusStore)
							_progressBar
							_ui
							_hadoopConfiguration = SparkHadoopUtil.get.newConfiguration(_conf)
							add all jars (spark://..../foo.jar)
							_executorMemory = SparkContext.executorMemoryInMb(_conf)
							_heartbeatReceiver = env.rpcEnv.setupEndpoint(
							_plugins = PluginContainer(this, _resources.asJava)
							val (_schedulerBackend, _taskScheduler) = SparkContext.createTaskScheduler(this, master)
								// Clients should first call initialize() and start(), then submit task sets through the submitTasks method.
								new TaskSchedulerImpl
								new LocalScheduleBackend
									// Used when running a local version of Spark where the executor, backend, and master all run in the same JVM. It sits behind a [[TaskSchedulerImpl]] and handles launching tasks on a single Executor (created by the [[LocalSchedulerBackend]]) running locally.
								initialize
									new FIFOSchedulableBuilder(rootPool)
							_dagScheduler = new DAGScheduler(this)
								// The high-level scheduling layer that implements stage-oriented scheduling. It computes a DAG of stages for each job, keeps track of which RDDs and stage outputs are materialized, and finds a minimal schedule to run the job.
								// It then submits stages as TaskSets to an underlying TaskScheduler implementation that runs them on the cluster.
								// A TaskSet contains fully independent tasks that can run right away based on the data that's already on the cluster.
								// Spark stages are created by breaking the RDD graph at shuffle boundaries.
								// RDD operations with "narrow" dependencies, like map() and filter(), are pipelined together into one set of tasks in each stage, but operations with shuffle dependencies require multiple stages (one to write a set of map output files, and another to read those files after a barrier).
 								// In the end, every stage will have only shuffle dependencies on other stages, and may compute multiple operations inside it.
 								// The actual pipelining of these operations happens in the RDD.compute() functions of various RDDs.
 								// In addition to coming up with a DAG of stages, the DAGScheduler also determines the preferred locations to run each task on, based on the current cache status, and passes these to the low-level TaskScheduler.
 								// Failures *within* a stage that are not caused by shuffle file loss are handled by the TaskScheduler, which will retry each task a small number of times before cancelling the whole stage.
 								// DAGScheduler Key concepts
 								//	- Jobs (represented by [[ActiveJob]]) are the top-level work items submitted to the scheduler. For example, when the user calls an action, like count(), a job will be submitted through submitJob. Each Job may require the execution of multiple stages to build intermediate data.
 								// - Stages ([[Stage]]) are sets of tasks that compute intermediate results in jobs, where each task computes the same function on partitions of the same RDD. Stages are separated at shuffle boundaries, which introduce a barrier (where we must wait for the previous stage to finish to fetch outputs). There are two types of stages: [[ResultStage]], for the final stage that executes an action, and [[ShuffleMapStage]], which writes map output files for a shuffle. Stages are often shared across multiple jobs, if these jobs reuse the same RDDs.
 								// - Tasks are individual units of work, each sent to one machine.
 								// - Cache tracking: the DAGScheduler figures out which RDDs are cached to avoid recomputing them and likewise remembers which shuffle map stages have already produced output files to avoid redoing the map side of a shuffle.
 								// - Preferred locations: the DAGScheduler also computes where to run each task in a stage based on the preferred locations of its underlying RDDs, or the location of cached or shuffle data.
 								// - Cleanup: all data structures are cleared when the running jobs that depend on them finish, to prevent memory leaks in a long-running application.
 								// To recover from failures, the same stage might need to run multiple times, which are called "attempts".
 								// submitJob - submit an "action" job to the scheduler
							_heartbeatReceiver.ask[Boolean](TaskSchedulerIsSet)
							_heartbeater = new Heartbeater
								// create and start the heartbeater for collecting memory metrics
							_env.metricsSystem.registerSource(_dagScheduler.metricsSource)
							_env.metricsSystem.registerSource(...)
							private val nextShuffleId = new AtomicInteger(0)
							private val nextRddId = new AtomicInteger(0)
						loadExtensions(extensions)
						applyExtensions(sparkContext, extensions)
						session = new SparkSession(sparkContext, None, None, extensions, options.toMap)
							// // If there is no active SparkSession, uses the default SQL conf. Otherwise, use the session's.
							val sqlContext: SQLContext = new SQLContext(this)

					spark.read().parquet("/tmp/yellow/")
						DataFrameReader::parquet
							DataFrameReader::load
								DataFrameReader::loadV1source
									DataSource::resolveRelation
										DataSource::getOrInferSchema
											format.inferSchema
												// globbing seems to not be a spark job?
												ParquetUtils.inferSchema(sparkSession, parameters, files)
													// Always tries the summary files first if users don't require a merged schema.
													// Metadata stored in the summary files are merged from all part-files.
													ParquetFileFormat.mergeSchemasInParallel(parameters, filesToTouch, sparkSession)
														// Figures out a merged Parquet schema with a distributed Spark job.
														// read cached or new ParquetToSparkSchemaConverter
														SchemaMergeUtils::mergeSchemasInParallel
															sparkSession.sparkContext.parallelize(...).mapPartitions.collect()
																RDD.collect
																	RDD.withScope (RDD 'scope', all RDDs created in this or child belong together)
																	sc.runJob(this, someFunc)
																		SparkContext::runJob
																			// Run a job on all partitions in an RDD and return the results in an array
																			SparkContext::runJob
																				// Run a function on a given set of partitions in an RDD and pass the results to the given handler function. This is the main entry point for all actions in Spark.
																				dagScheduler.runJob(rdd, cleanedFunc, partitions, callSite, resultHandler, localProperties.get)
																					// Run an action job on the given RDD and pass all the results to the resultHandler function as they arrive.
																					DagScheduler::submitJob
																						// Submit an action job to the scheduler.
																				progressBar.foreach(_.finishAll())
																				rdd.doCheckpoint()
					.createOrReplaceTempView("yellow");
						createView
							val catalog = sparkSession.sessionState.catalog
							catalog.createTempView(name.table, tableDefinition, overrideIfExists = replace)
								QueryExecution::eagerlyExecuteCommands
									Catalyst::TreeNode::transformDownWithPruning
									transform_func: actually execute
								
